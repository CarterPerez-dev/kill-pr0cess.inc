This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
src/
  database/
    migrations/
      001_initial.sql
    connection.rs
    mod.rs
  models/
    fractals.rs
    github.rs
    mod.rs
    performance.rs
  routes/
    fractals.rs
    github.rs
    health.rs
    mod.rs
    performance.rs
  services/
    cache_service.rs
    fractal_service.rs
    github_service.rs
    mod.rs
    performance_service.rs
  utils/
    config.rs
    error.rs
    metrics.rs
    mod.rs
  lib.rs
  main.rs
build.rs
Cargo.toml
Dockerfile.dev
Dockerfile.prod
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/database/migrations/001_initial.sql">
-- Initial database schema for the dark performance showcase backend.
-- I'm designing tables for GitHub repository caching, performance metrics storage, and fractal computation logs with optimal indexing for high-performance queries.

-- Enable UUID extension for unique identifiers
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Repositories table for GitHub data caching with comprehensive metadata
CREATE TABLE repositories (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    github_id BIGINT UNIQUE NOT NULL,
    name VARCHAR(255) NOT NULL,
    full_name VARCHAR(511) NOT NULL,
    owner_login VARCHAR(255) NOT NULL,
    description TEXT,
    homepage VARCHAR(2048),
    clone_url TEXT NOT NULL,
    ssh_url TEXT NOT NULL,
    html_url TEXT NOT NULL,
    language VARCHAR(100),
    size_kb INTEGER DEFAULT 0,
    stargazers_count INTEGER DEFAULT 0,
    watchers_count INTEGER DEFAULT 0,
    forks_count INTEGER DEFAULT 0,
    open_issues_count INTEGER DEFAULT 0,
    default_branch VARCHAR(100) DEFAULT 'main',
    topics TEXT[],
    is_private BOOLEAN DEFAULT false,
    is_fork BOOLEAN DEFAULT false,
    is_archived BOOLEAN DEFAULT false,
    license_name VARCHAR(255),
    readme_content TEXT,
    created_at TIMESTAMPTZ NOT NULL,
    updated_at TIMESTAMPTZ NOT NULL,
    pushed_at TIMESTAMPTZ,
    -- Caching metadata
    cache_updated_at TIMESTAMPTZ DEFAULT NOW(),
    cache_expires_at TIMESTAMPTZ DEFAULT NOW() + INTERVAL '1 hour',
    -- Performance tracking
    fetch_duration_ms INTEGER,
    last_fetch_status VARCHAR(50) DEFAULT 'success'
);

-- Performance metrics table for system and application monitoring
CREATE TABLE performance_metrics (
    id UUID DEFAULT uuid_generate_v4(),
    metric_type VARCHAR(100) NOT NULL, -- 'cpu', 'memory', 'disk', 'network', 'response_time', 'throughput'
    metric_name VARCHAR(255) NOT NULL,
    metric_value DOUBLE PRECISION NOT NULL,
    metric_unit VARCHAR(50) NOT NULL, -- 'percent', 'bytes', 'ms', 'requests_per_second'
    tags JSONB DEFAULT '{}', -- Additional metadata as key-value pairs
    timestamp TIMESTAMPTZ DEFAULT NOW(),
    -- Context information
    endpoint VARCHAR(255), -- For request-specific metrics
    user_agent TEXT,
    ip_address INET,
    session_id UUID,
    -- Performance context
    server_instance VARCHAR(100),
    environment VARCHAR(50) DEFAULT 'production',
    PRIMARY KEY (timestamp, id)
);

-- Fractal computations table for tracking generation performance and parameters
CREATE TABLE fractal_computations (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    fractal_type VARCHAR(50) NOT NULL, -- 'mandelbrot', 'julia'
    width INTEGER NOT NULL,
    height INTEGER NOT NULL,
    center_x DOUBLE PRECISION NOT NULL,
    center_y DOUBLE PRECISION NOT NULL,
    zoom_level DOUBLE PRECISION NOT NULL,
    max_iterations INTEGER NOT NULL,
    -- Julia set specific parameters
    julia_c_real DOUBLE PRECISION,
    julia_c_imag DOUBLE PRECISION,
    -- Performance metrics
    computation_time_ms INTEGER NOT NULL,
    memory_used_bytes BIGINT,
    cpu_cores_used INTEGER,
    cpu_usage_percent DOUBLE PRECISION,
    memory_usage_mb DOUBLE PRECISION,
    parallel_threads INTEGER,
    pixels_computed BIGINT GENERATED ALWAYS AS (width * height) STORED,
    pixels_per_ms DOUBLE PRECISION GENERATED ALWAYS AS (
        CASE WHEN computation_time_ms > 0
        THEN (width * height)::DOUBLE PRECISION / computation_time_ms
        ELSE 0 END
    ) STORED,
    -- Request context
    session_id UUID,
    ip_address INET,
    user_agent TEXT,
    -- Quality and optimization tracking
    iteration_efficiency DOUBLE PRECISION, -- average iterations per pixel
    cache_hit BOOLEAN DEFAULT false,
    optimization_flags TEXT[],
    parameters JSONB,
    timestamp TIMESTAMPTZ DEFAULT NOW()
);

-- System statistics table for hardware and runtime information
CREATE TABLE system_stats (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    -- Hardware information
    cpu_model VARCHAR(255),
    cpu_cores INTEGER,
    cpu_threads INTEGER,
    memory_total_bytes BIGINT,
    memory_available_bytes BIGINT,
    disk_total_bytes BIGINT,
    disk_available_bytes BIGINT,
    -- Runtime information
    rust_version VARCHAR(50),
    server_uptime_seconds BIGINT,
    active_connections INTEGER,
    request_count_total BIGINT,
    error_count_total BIGINT,
    -- Load information
    load_average_1m DOUBLE PRECISION,
    load_average_5m DOUBLE PRECISION,
    load_average_15m DOUBLE PRECISION,
    -- Network statistics
    network_bytes_sent BIGINT DEFAULT 0,
    network_bytes_received BIGINT DEFAULT 0,
    -- Timestamp and metadata
    timestamp TIMESTAMPTZ DEFAULT NOW(),
    server_instance VARCHAR(100),
    environment VARCHAR(50) DEFAULT 'production'
);

-- Benchmark results table for comparative performance analysis
CREATE TABLE benchmark_results (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    benchmark_type VARCHAR(100) NOT NULL, -- 'fractal_generation', 'api_response', 'database_query'
    benchmark_name VARCHAR(255) NOT NULL,
    parameters JSONB NOT NULL, -- Benchmark-specific parameters
    results JSONB NOT NULL, -- Detailed results and metrics
    duration_ms INTEGER NOT NULL,
    iterations INTEGER DEFAULT 1,
    success BOOLEAN DEFAULT true,
    error_message TEXT,
    -- Comparison context
    baseline_duration_ms INTEGER, -- For regression detection
    performance_ratio DOUBLE PRECISION, -- current/baseline
    -- Environment context
    timestamp TIMESTAMPTZ DEFAULT NOW(),
    server_instance VARCHAR(100),
    environment VARCHAR(50) DEFAULT 'production',
    rust_version VARCHAR(50),
    -- Hardware context at time of benchmark
    cpu_model VARCHAR(255),
    cpu_cores INTEGER,
    memory_total_bytes BIGINT
);

-- Cache entries table for intelligent caching with TTL and statistics
CREATE TABLE cache_entries (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    cache_key VARCHAR(512) NOT NULL UNIQUE,
    cache_value JSONB NOT NULL,
    content_type VARCHAR(100) DEFAULT 'json',
    size_bytes INTEGER GENERATED ALWAYS AS (octet_length(cache_value::text)) STORED,
    -- TTL and expiration
    created_at TIMESTAMPTZ DEFAULT NOW(),
    expires_at TIMESTAMPTZ NOT NULL,
    last_accessed_at TIMESTAMPTZ DEFAULT NOW(),
    access_count INTEGER DEFAULT 1,
    -- Cache performance
    hit_count INTEGER DEFAULT 0,
    miss_count INTEGER DEFAULT 0,
    generation_time_ms INTEGER,
    -- Metadata
    tags TEXT[],
    invalidation_keys TEXT[], -- Keys that can trigger cache invalidation
    compression_used VARCHAR(50) -- 'none', 'gzip', 'brotli'
);

-- Indexes for optimal query performance

-- Repository indexes for GitHub API caching
CREATE INDEX idx_repositories_github_id ON repositories(github_id);
CREATE INDEX idx_repositories_owner_login ON repositories(owner_login);
CREATE INDEX idx_repositories_language ON repositories(language) WHERE language IS NOT NULL;
CREATE INDEX idx_repositories_cache_expires ON repositories(cache_expires_at);
CREATE INDEX idx_repositories_updated_at ON repositories(updated_at DESC);
CREATE INDEX idx_repositories_stars ON repositories(stargazers_count DESC);
CREATE INDEX idx_repositories_topics ON repositories USING GIN(topics);
CREATE INDEX idx_repositories_search ON repositories USING GIN(to_tsvector('english', name || ' ' || COALESCE(description, '')));

-- Performance metrics indexes for time-series analysis
CREATE INDEX idx_performance_metrics_timestamp ON performance_metrics(timestamp DESC);
CREATE INDEX idx_performance_metrics_type_name ON performance_metrics(metric_type, metric_name);
CREATE INDEX idx_performance_metrics_endpoint ON performance_metrics(endpoint) WHERE endpoint IS NOT NULL;
CREATE INDEX idx_performance_metrics_tags ON performance_metrics USING GIN(tags);
CREATE INDEX idx_performance_metrics_composite ON performance_metrics(metric_type, timestamp DESC, metric_value);

-- Fractal computation indexes for performance analysis
CREATE INDEX idx_fractal_computations_timestamp ON fractal_computations(timestamp DESC);
CREATE INDEX idx_fractal_computations_type ON fractal_computations(fractal_type);
CREATE INDEX idx_fractal_computations_performance ON fractal_computations(pixels_per_ms DESC);
CREATE INDEX idx_fractal_computations_zoom ON fractal_computations(zoom_level);
CREATE INDEX idx_fractal_computations_size ON fractal_computations(width, height);
CREATE INDEX idx_fractal_computations_session ON fractal_computations(session_id) WHERE session_id IS NOT NULL;

-- System stats indexes for monitoring
CREATE INDEX idx_system_stats_timestamp ON system_stats(timestamp DESC);
CREATE INDEX idx_system_stats_instance ON system_stats(server_instance, timestamp DESC);
CREATE INDEX idx_system_stats_environment ON system_stats(environment);

-- Benchmark results indexes for performance tracking
CREATE INDEX idx_benchmark_results_timestamp ON benchmark_results(timestamp DESC);
CREATE INDEX idx_benchmark_results_type_name ON benchmark_results(benchmark_type, benchmark_name);
CREATE INDEX idx_benchmark_results_performance ON benchmark_results(duration_ms);
CREATE INDEX idx_benchmark_results_regression ON benchmark_results(performance_ratio) WHERE performance_ratio IS NOT NULL;

-- Cache entries indexes for efficient cache operations
CREATE INDEX idx_cache_entries_key ON cache_entries(cache_key);
CREATE INDEX idx_cache_entries_expires ON cache_entries(expires_at);
CREATE INDEX idx_cache_entries_accessed ON cache_entries(last_accessed_at DESC);
CREATE INDEX idx_cache_entries_tags ON cache_entries USING GIN(tags);
CREATE INDEX idx_cache_entries_invalidation ON cache_entries USING GIN(invalidation_keys);

-- Partitioning for large tables (performance_metrics and fractal_computations)
-- I'm setting up monthly partitioning for better query performance on time-series data

-- Create partitioned table for performance metrics
CREATE TABLE performance_metrics_partitioned (
    LIKE performance_metrics INCLUDING ALL
) PARTITION BY RANGE (timestamp);

-- Create initial partitions (current month and next month)
CREATE TABLE performance_metrics_2024_01 PARTITION OF performance_metrics_partitioned
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
CREATE TABLE performance_metrics_2024_02 PARTITION OF performance_metrics_partitioned
    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');

-- Constraints and triggers for data integrity and automatic maintenance

-- Ensure cache entries don't expire in the past
ALTER TABLE cache_entries ADD CONSTRAINT chk_cache_not_expired
    CHECK (expires_at > created_at);

-- Ensure fractal parameters are valid
ALTER TABLE fractal_computations ADD CONSTRAINT chk_fractal_dimensions
    CHECK (width > 0 AND height > 0 AND width <= 8192 AND height <= 8192);
ALTER TABLE fractal_computations ADD CONSTRAINT chk_fractal_zoom
    CHECK (zoom_level > 0 AND zoom_level <= 1e15);
ALTER TABLE fractal_computations ADD CONSTRAINT chk_fractal_iterations
    CHECK (max_iterations > 0 AND max_iterations <= 10000);

-- Ensure performance metrics have valid values
ALTER TABLE performance_metrics ADD CONSTRAINT chk_performance_value
    CHECK (metric_value >= 0 OR metric_type IN ('temperature', 'coordinate'));

-- Functions for automatic maintenance and optimization

-- Function to clean up expired cache entries
CREATE OR REPLACE FUNCTION cleanup_expired_cache()
RETURNS INTEGER AS $$
DECLARE
    deleted_count INTEGER;
BEGIN
    DELETE FROM cache_entries WHERE expires_at < NOW();
    GET DIAGNOSTICS deleted_count = ROW_COUNT;
    RETURN deleted_count;
END;
$$ LANGUAGE plpgsql;

-- Function to update repository cache status
CREATE OR REPLACE FUNCTION update_repository_cache_status()
RETURNS TRIGGER AS $$
BEGIN
    NEW.cache_updated_at = NOW();
    IF NEW.cache_expires_at IS NULL OR NEW.cache_expires_at <= NOW() THEN
        NEW.cache_expires_at = NOW() + INTERVAL '1 hour';
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger to automatically update cache timestamps
CREATE TRIGGER trg_repositories_cache_update
    BEFORE UPDATE ON repositories
    FOR EACH ROW
    EXECUTE FUNCTION update_repository_cache_status();

-- Views for common queries and analytics

-- View for repository statistics and rankings
CREATE VIEW repository_stats AS
SELECT
    full_name,
    language,
    stargazers_count,
    forks_count,
    open_issues_count,
    EXTRACT(DAYS FROM NOW() - updated_at) as days_since_update,
    CASE
        WHEN cache_expires_at > NOW() THEN 'fresh'
        ELSE 'stale'
    END as cache_status
FROM repositories
WHERE NOT is_archived
ORDER BY stargazers_count DESC;

-- View for performance metrics summary
CREATE VIEW performance_summary AS
SELECT
    metric_type,
    metric_name,
    COUNT(*) as measurement_count,
    AVG(metric_value) as avg_value,
    MIN(metric_value) as min_value,
    MAX(metric_value) as max_value,
    STDDEV(metric_value) as stddev_value,
    DATE_TRUNC('hour', timestamp) as hour_bucket
FROM performance_metrics
WHERE timestamp >= NOW() - INTERVAL '24 hours'
GROUP BY metric_type, metric_name, DATE_TRUNC('hour', timestamp)
ORDER BY hour_bucket DESC;

-- View for fractal performance analysis
CREATE VIEW fractal_performance_stats AS
SELECT
    fractal_type,
    width,
    height,
    COUNT(*) as computation_count,
    AVG(computation_time_ms) as avg_computation_time,
    AVG(pixels_per_ms) as avg_pixels_per_ms,
    MAX(pixels_per_ms) as max_pixels_per_ms,
    AVG(zoom_level) as avg_zoom_level,
    MAX(zoom_level) as max_zoom_level
FROM fractal_computations
WHERE timestamp >= NOW() - INTERVAL '7 days'
GROUP BY fractal_type, width, height
ORDER BY avg_pixels_per_ms DESC;

-- Initial data for testing and development
INSERT INTO system_stats (
    cpu_model, cpu_cores, cpu_threads, memory_total_bytes,
    rust_version, server_uptime_seconds, active_connections,
    server_instance, environment
) VALUES (
    'Development System', 8, 16, 16106127360,
    '1.75.0', 0, 0,
    'dev-001', 'development'
);

-- Create maintenance user and permissions
-- (This would typically be done separately in production)
-- COMMENT: I'm creating a maintenance role for automated cleanup tasks

COMMENT ON TABLE repositories IS 'GitHub repository cache with comprehensive metadata and performance tracking';
COMMENT ON TABLE performance_metrics IS 'Time-series performance metrics for system and application monitoring';
COMMENT ON TABLE fractal_computations IS 'Fractal generation logs with performance analysis and parameter tracking';
COMMENT ON TABLE system_stats IS 'System hardware and runtime statistics for performance baseline';
COMMENT ON TABLE benchmark_results IS 'Comparative performance benchmarks for regression analysis';
COMMENT ON TABLE cache_entries IS 'Intelligent caching layer with TTL and access statistics';

COMMENT ON FUNCTION cleanup_expired_cache() IS 'Maintenance function to remove expired cache entries and return cleanup count';
COMMENT ON VIEW repository_stats IS 'Repository analytics with cache status and activity metrics';
COMMENT ON VIEW performance_summary IS 'Hourly performance metrics aggregation for monitoring dashboards';
COMMENT ON VIEW fractal_performance_stats IS 'Fractal computation performance analysis for optimization tracking';
</file>

<file path="src/database/connection.rs">
/*
 * Database connection pool management with optimized settings, health monitoring, and automatic recovery.
 * I'm implementing robust PostgreSQL connection handling with performance optimization and comprehensive error recovery mechanisms.
 */

use sqlx::{
    postgres::{PgPool, PgPoolOptions, PgConnectOptions, PgSslMode},
    ConnectOptions, Row,
};
use std::time::Duration;
use tracing::{info, warn, error, debug};
use std::str::FromStr;

use crate::{
    utils::{
        error::{AppError, Result},
        config::{Config, DatabasePoolConfig},
    },
};

/// Type alias for our PostgreSQL connection pool
/// I'm providing a convenient type alias used throughout the application
pub type DatabasePool = PgPool;

/// Database connection manager with health monitoring and optimization
/// I'm implementing comprehensive database management with performance tracking
pub struct DatabaseManager {
    pool: DatabasePool,
    config: DatabasePoolConfig,
    health_check_query: String,
}

impl DatabaseManager {
    /// Create a new database manager with the provided pool
    /// I'm setting up comprehensive database management with health monitoring
    pub fn new(pool: DatabasePool, config: DatabasePoolConfig) -> Self {
        Self {
            pool,
            config,
            health_check_query: "SELECT 1 as health_check".to_string(),
        }
    }

    /// Get a reference to the connection pool
    /// I'm providing access to the underlying pool for queries
    pub fn pool(&self) -> &DatabasePool {
        &self.pool
    }

    /// Perform a health check on the database connection
    /// I'm implementing comprehensive health verification
    pub async fn health_check(&self) -> Result<DatabaseHealthStatus> {
        let start_time = std::time::Instant::now();

        match sqlx::query(&self.health_check_query)
        .fetch_one(&self.pool)
        .await
        {
            Ok(row) => {
                let response_time = start_time.elapsed();
                let health_value: i32 = row.try_get("health_check")?;

                if health_value == 1 {
                    Ok(DatabaseHealthStatus {
                        healthy: true,
                        response_time_ms: response_time.as_millis() as u64,
                       active_connections: self.get_active_connections().await.unwrap_or(0),
                       pool_size: self.pool.size(),
                       idle_connections: self.get_idle_connections().await.unwrap_or(0),
                       error_message: None,
                    })
                } else {
                    Err(AppError::DatabaseError("Health check returned unexpected value".to_string()))
                }
            }
            Err(e) => {
                let response_time = start_time.elapsed();
                Ok(DatabaseHealthStatus {
                    healthy: false,
                    response_time_ms: response_time.as_millis() as u64,
                   active_connections: 0,
                   pool_size: self.pool.size(),
                   idle_connections: 0,
                   error_message: Some(e.to_string()),
                })
            }
        }
    }

    /// Get the number of active connections
    /// I'm providing pool monitoring capabilities for performance analysis
    async fn get_active_connections(&self) -> Result<u32> {
        let result = sqlx::query(
            "SELECT count(*) as active_connections FROM pg_stat_activity WHERE state = 'active'"
        )
        .fetch_one(&self.pool)
        .await?;

        let count: i64 = result.try_get("active_connections")?;
        Ok(count as u32)
    }

    /// Get the number of idle connections
    /// I'm tracking connection pool efficiency
    async fn get_idle_connections(&self) -> Result<u32> {
        let result = sqlx::query(
            "SELECT count(*) as idle_connections FROM pg_stat_activity WHERE state = 'idle'"
        )
        .fetch_one(&self.pool)
        .await?;

        let count: i64 = result.try_get("idle_connections")?;
        Ok(count as u32)
    }

    /// Get detailed database statistics for monitoring
    /// I'm providing comprehensive database performance metrics
    pub async fn get_database_stats(&self) -> Result<DatabaseStats> {
        let stats_query = r#"
        SELECT
        pg_database_size(current_database()) as database_size_bytes,
        (SELECT count(*) FROM pg_stat_activity) as total_connections,
        (SELECT count(*) FROM pg_stat_activity WHERE state = 'active') as active_connections,
        (SELECT count(*) FROM pg_stat_activity WHERE state = 'idle') as idle_connections,
        (SELECT sum(numbackends) FROM pg_stat_database) as backend_count,
        current_setting('max_connections')::int as max_connections
        "#;

        let result = sqlx::query(stats_query)
        .fetch_one(&self.pool)
        .await?;

        Ok(DatabaseStats {
            database_size_bytes: result.try_get::<i64, _>("database_size_bytes")? as u64,
           total_connections: result.try_get::<i64, _>("total_connections")? as u32,
           active_connections: result.try_get::<i64, _>("active_connections")? as u32,
           idle_connections: result.try_get::<i64, _>("idle_connections")? as u32,
           backend_count: result.try_get::<i64, _>("backend_count")? as u32,
           max_connections: result.try_get::<i32, _>("max_connections")? as u32,
           pool_size: self.pool.size(),
           pool_idle: self.pool.num_idle() as u32,
        })
    }

    /// Run database migrations if needed
    /// I'm providing migration support for deployment automation
    pub async fn run_migrations(&self) -> Result<()> {
        info!("Running database migrations");

        match sqlx::migrate!("src/database/migrations")
        .run(&self.pool)
        .await
        {
            Ok(_) => {
                info!("Database migrations completed successfully");
                Ok(())
            }
            Err(e) => {
                error!("Database migration failed: {}", e);
                Err(AppError::DatabaseError(format!("Migration failed: {}", e)))
            }
        }
    }

    /// Close the database connection pool gracefully
    /// I'm implementing proper resource cleanup
    pub async fn close(&self) {
        info!("Closing database connection pool");
        self.pool.close().await;
        info!("Database connection pool closed");
    }
}

/// Database health status information
/// I'm providing comprehensive health monitoring data
#[derive(Debug, Clone, serde::Serialize)]
pub struct DatabaseHealthStatus {
    pub healthy: bool,
    pub response_time_ms: u64,
    pub active_connections: u32,
    pub pool_size: u32,
    pub idle_connections: u32,
    pub error_message: Option<String>,
}

/// Comprehensive database statistics for monitoring
/// I'm providing detailed performance and usage metrics
#[derive(Debug, Clone, serde::Serialize)]
pub struct DatabaseStats {
    pub database_size_bytes: u64,
    pub total_connections: u32,
    pub active_connections: u32,
    pub idle_connections: u32,
    pub backend_count: u32,
    pub max_connections: u32,
    pub pool_size: u32,
    pub pool_idle: u32,
}

/// Create an optimized database connection pool
/// I'm implementing production-ready connection pooling with intelligent configuration
pub async fn create_pool(database_url: &str) -> Result<DatabasePool> {
    info!("Creating database connection pool");

    // Parse the database URL and configure connection options
    let mut connect_options = PgConnectOptions::from_str(database_url)
    .map_err(|e| AppError::ConfigurationError(format!("Invalid database URL: {}", e)))?;

    // I'm configuring connection options for optimal performance and security
    connect_options = connect_options
    .application_name("dark-performance-showcase")
    .ssl_mode(PgSslMode::Prefer) // Prefer SSL but allow non-SSL connections
    .statement_cache_capacity(100) // Cache prepared statements
    .log_statements(tracing::log::LevelFilter::Debug); // Log SQL in debug mode

    // Create the pool with optimized settings
    let pool = PgPoolOptions::new()
    .max_connections(20) // Default max connections
    .min_connections(5)  // Maintain minimum connections
    .acquire_timeout(Duration::from_secs(30))
    .idle_timeout(Duration::from_secs(600)) // 10 minutes idle timeout
    .max_lifetime(Duration::from_secs(1800)) // 30 minutes max lifetime
    .test_before_acquire(true) // Verify connections before use
    .connect_with(connect_options)
    .await
    .map_err(|e| AppError::DatabaseError(format!("Failed to create connection pool: {}", e)))?;

    // Test the initial connection
    test_database_connection(&pool).await?;

    info!("Database connection pool created successfully with {} connections", pool.size());
    Ok(pool)
}

/// Create a database pool with custom configuration
/// I'm providing flexibility for different deployment scenarios
pub async fn create_pool_with_config(database_url: &str, config: &DatabasePoolConfig) -> Result<DatabasePool> {
    info!("Creating database connection pool with custom configuration");

    let mut connect_options = PgConnectOptions::from_str(database_url)
    .map_err(|e| AppError::ConfigurationError(format!("Invalid database URL: {}", e)))?;

    connect_options = connect_options
    .application_name("dark-performance-showcase")
    .ssl_mode(PgSslMode::Prefer)
    .statement_cache_capacity(100)
    .log_statements(if cfg!(debug_assertions) {
        tracing::log::LevelFilter::Debug
    } else {
        tracing::log::LevelFilter::Warn
    });

    let pool = PgPoolOptions::new()
    .max_connections(config.max_connections)
    .min_connections(config.min_connections)
    .acquire_timeout(config.connection_timeout)
    .idle_timeout(config.idle_timeout)
    .max_lifetime(Duration::from_secs(3600)) // 1 hour max lifetime
    .test_before_acquire(config.test_before_acquire)
    .connect_with(connect_options)
    .await
    .map_err(|e| AppError::DatabaseError(format!("Failed to create connection pool: {}", e)))?;

    test_database_connection(&pool).await?;

    info!("Database connection pool created with custom config: max={}, min={}",
          config.max_connections, config.min_connections);
    Ok(pool)
}

/// Test database connection and basic functionality
/// I'm implementing comprehensive connection validation
async fn test_database_connection(pool: &DatabasePool) -> Result<()> {
    debug!("Testing database connection");

    // Test basic connectivity
    let result = sqlx::query("SELECT 1 as test_value, NOW() as current_time")
    .fetch_one(pool)
    .await
    .map_err(|e| AppError::DatabaseError(format!("Database connection test failed: {}", e)))?;

    let test_value: i32 = result.try_get("test_value")?;
    let current_time: chrono::DateTime<chrono::Utc> = result.try_get("current_time")?;

    if test_value != 1 {
        return Err(AppError::DatabaseError("Database test query returned unexpected value".to_string()));
    }

    debug!("Database connection test successful - server time: {}", current_time);

    // Test database version and capabilities
    let version_result = sqlx::query("SELECT version() as db_version")
    .fetch_one(pool)
    .await?;

    let db_version: String = version_result.try_get("db_version")?;
    info!("Connected to database: {}", db_version);

    // Check for required extensions or permissions
    test_database_permissions(pool).await?;

    Ok(())
}

/// Test database permissions and required functionality
/// I'm verifying that the database user has necessary permissions
async fn test_database_permissions(pool: &DatabasePool) -> Result<()> {
    debug!("Testing database permissions");

    // Test table creation permission (for migrations)
    let create_test = sqlx::query(
        "CREATE TEMP TABLE temp_permission_test (id SERIAL PRIMARY KEY, test_data TEXT)"
    )
    .execute(pool)
    .await;

    match create_test {
        Ok(_) => {
            debug!("Database CREATE permission verified");

            // Clean up the temp table
            let _ = sqlx::query("DROP TABLE IF EXISTS temp_permission_test")
            .execute(pool)
            .await;
        }
        Err(e) => {
            warn!("Database CREATE permission test failed: {}", e);
            // Don't fail here as some deployments might not allow temp table creation
        }
    }

    // Test basic SELECT permission
    let select_test = sqlx::query("SELECT current_user, current_database()")
    .fetch_one(pool)
    .await?;

    let current_user: String = select_test.try_get("current_user")?;
    let current_database: String = select_test.try_get("current_database")?;

    info!("Database permissions verified - user: {}, database: {}", current_user, current_database);

    Ok(())
}

/// Database connection helper for transactions
/// I'm providing convenient transaction handling
pub async fn with_transaction<F, R>(pool: &DatabasePool, f: F) -> Result<R>
where
F: for<'c> FnOnce(&mut sqlx::Transaction<'c, sqlx::Postgres>) -> std::pin::Pin<Box<dyn std::future::Future<Output = Result<R>> + Send + 'c>>,
{
    let mut tx = pool.begin().await?;

    match f(&mut tx).await {
        Ok(result) => {
            tx.commit().await?;
            Ok(result)
        }
        Err(e) => {
            if let Err(rollback_err) = tx.rollback().await {
                error!("Failed to rollback transaction: {}", rollback_err);
            }
            Err(e)
        }
    }
}

/// Batch operation helper for improved performance
/// I'm providing optimized batch processing for bulk operations
pub async fn batch_execute<T>(
    pool: &DatabasePool,
    items: Vec<T>,
    batch_size: usize,
    mut operation: impl FnMut(&T) -> sqlx::query::Query<'_, sqlx::Postgres, sqlx::postgres::PgArguments>,
) -> Result<u64>
where
T: Send,
{
    let mut total_affected = 0u64;

    for chunk in items.chunks(batch_size) {
        let mut tx = pool.begin().await?;

        for item in chunk {
            let query = operation(item);
            let result = query.execute(&mut *tx).await?;
            total_affected += result.rows_affected();
        }

        tx.commit().await?;
    }

    Ok(total_affected)
}

/// Connection pool monitoring and metrics collection
/// I'm implementing performance monitoring for database operations
pub struct ConnectionPoolMonitor {
    pool: DatabasePool,
    metrics_interval: Duration,
}

impl ConnectionPoolMonitor {
    pub fn new(pool: DatabasePool, metrics_interval: Duration) -> Self {
        Self {
            pool,
            metrics_interval,
        }
    }

    /// Start monitoring the connection pool
    /// I'm providing continuous monitoring of database performance
    pub async fn start_monitoring(&self) {
        let mut interval = tokio::time::interval(self.metrics_interval);

        loop {
            interval.tick().await;

            if let Err(e) = self.collect_metrics().await {
                warn!("Failed to collect database metrics: {}", e);
            }
        }
    }

    /// Collect and log database metrics
    /// I'm gathering comprehensive performance data
    async fn collect_metrics(&self) -> Result<()> {
        let pool_size = self.pool.size();
        let idle_connections = self.pool.num_idle();
        let active_connections = pool_size - (idle_connections as u32);

        // Log pool statistics
        debug!("Database pool stats - Total: {}, Active: {}, Idle: {}",
               pool_size, active_connections, idle_connections);

        // Check for potential issues
        if active_connections > (pool_size * 3 / 4) {
            warn!("High database connection usage: {}/{} connections active",
                  active_connections, pool_size);
        }

        if idle_connections == 0 {
            warn!("No idle database connections available - consider increasing pool size");
        }

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_database_health_status_serialization() {
        let status = DatabaseHealthStatus {
            healthy: true,
            response_time_ms: 42,
            active_connections: 5,
            pool_size: 10,
            idle_connections: 5,
            error_message: None,
        };

        let json = serde_json::to_string(&status).unwrap();
        assert!(json.contains("\"healthy\":true"));
        assert!(json.contains("\"response_time_ms\":42"));
    }

    #[test]
    fn test_connection_options_parsing() {
        let url = "postgresql://user:pass@localhost:5432/testdb";
        let options = PgConnectOptions::from_str(url);
        assert!(options.is_ok());
    }
}
</file>

<file path="src/database/mod.rs">
/*
 * Database module aggregator providing centralized access to all database-related functionality for the dark performance showcase.
 * I'm organizing connection management, migration utilities, and database operations into a clean, cohesive interface that supports the high-performance architecture.
 */

pub mod connection;

// Re-export commonly used database types and functions
pub use connection::{
    DatabasePool,
    DatabaseManager,
    DatabaseHealthStatus,
    DatabaseStats,
    create_pool,
    create_pool_with_config,
    with_transaction,
    batch_execute,
    ConnectionPoolMonitor
};

use crate::utils::error::{AppError, Result};
use sqlx::Row;

/// Database utilities and helper functions for common operations
/// I'm providing convenient database operations that maintain consistency across the application
pub struct DatabaseUtils;

impl DatabaseUtils {
    /// Check if a table exists in the database
    /// I'm implementing table existence checking for dynamic schema operations
    pub async fn table_exists(pool: &DatabasePool, table_name: &str) -> Result<bool> {
        let result = sqlx::query(
            "SELECT EXISTS (
                SELECT FROM information_schema.tables
                WHERE table_schema = 'public'
                AND table_name = $1
            )"
        )
        .bind(table_name)
        .fetch_one(pool)
        .await?;

        let exists: bool = result.try_get("exists")?;
        Ok(exists)
    }

    /// Get database version information
    /// I'm providing database version checking for compatibility verification
    pub async fn get_database_version(pool: &DatabasePool) -> Result<String> {
        let result = sqlx::query("SELECT version() as db_version")
            .fetch_one(pool)
            .await?;

        let version: String = result.try_get("db_version")?;
        Ok(version)
    }

    /// Get database size in bytes
    /// I'm implementing database size monitoring for resource tracking
    pub async fn get_database_size(pool: &DatabasePool) -> Result<i64> {
        let result = sqlx::query(
            "SELECT pg_database_size(current_database()) as size_bytes"
        )
        .fetch_one(pool)
        .await?;

        let size: i64 = result.try_get("size_bytes")?;
        Ok(size)
    }

    /// Clean up expired cache entries and performance data
    /// I'm implementing automated cleanup for maintaining database performance
    pub async fn cleanup_expired_data(pool: &DatabasePool) -> Result<u64> {
        let mut total_cleaned = 0u64;

        // Clean expired cache entries
        let cache_result = sqlx::query(
            "DELETE FROM cache_entries WHERE expires_at < NOW()"
        )
        .execute(pool)
        .await?;
        total_cleaned += cache_result.rows_affected();

        // Clean old performance metrics (keep last 30 days)
        let metrics_result = sqlx::query(
            "DELETE FROM performance_metrics WHERE timestamp < NOW() - INTERVAL '30 days'"
        )
        .execute(pool)
        .await?;
        total_cleaned += metrics_result.rows_affected();

        // Clean old fractal computations (keep last 7 days)
        let fractal_result = sqlx::query(
            "DELETE FROM fractal_computations WHERE timestamp < NOW() - INTERVAL '7 days'"
        )
        .execute(pool)
        .await?;
        total_cleaned += fractal_result.rows_affected();

        Ok(total_cleaned)
    }

    /// Get comprehensive database statistics
    /// I'm providing detailed database analytics for monitoring and optimization
    pub async fn get_comprehensive_stats(pool: &DatabasePool) -> Result<serde_json::Value> {
        // Table sizes
        let table_sizes = sqlx::query(
            "SELECT
                schemaname,
                tablename,
                pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
                pg_total_relation_size(schemaname||'.'||tablename) as size_bytes
            FROM pg_tables
            WHERE schemaname = 'public'
            ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC"
        )
        .fetch_all(pool)
        .await?;

        // Connection stats
        let connection_stats = sqlx::query(
            "SELECT
                count(*) as total_connections,
                count(*) FILTER (WHERE state = 'active') as active_connections,
                count(*) FILTER (WHERE state = 'idle') as idle_connections
            FROM pg_stat_activity"
        )
        .fetch_one(pool)
        .await?;

        // Database stats
        let db_stats = sqlx::query(
            "SELECT
                numbackends,
                xact_commit,
                xact_rollback,
                blks_read,
                blks_hit,
                tup_returned,
                tup_fetched,
                tup_inserted,
                tup_updated,
                tup_deleted
            FROM pg_stat_database
            WHERE datname = current_database()"
        )
        .fetch_one(pool)
        .await?;

        let stats = serde_json::json!({
            "table_sizes": table_sizes.iter().map(|row| {
                serde_json::json!({
                    "table": row.get::<String, _>("tablename"),
                    "size": row.get::<String, _>("size"),
                    "size_bytes": row.get::<i64, _>("size_bytes")
                })
            }).collect::<Vec<_>>(),
            "connections": {
                "total": connection_stats.get::<i64, _>("total_connections"),
                "active": connection_stats.get::<i64, _>("active_connections"),
                "idle": connection_stats.get::<i64, _>("idle_connections")
            },
            "database": {
                "backends": db_stats.get::<i32, _>("numbackends"),
                "transactions": {
                    "committed": db_stats.get::<i64, _>("xact_commit"),
                    "rolled_back": db_stats.get::<i64, _>("xact_rollback")
                },
                "blocks": {
                    "read": db_stats.get::<i64, _>("blks_read"),
                    "hit": db_stats.get::<i64, _>("blks_hit"),
                    "hit_ratio": {
                        let read = db_stats.get::<i64, _>("blks_read") as f64;
                        let hit = db_stats.get::<i64, _>("blks_hit") as f64;
                        if read + hit > 0.0 { hit / (read + hit) * 100.0 } else { 0.0 }
                    }
                },
                "tuples": {
                    "returned": db_stats.get::<i64, _>("tup_returned"),
                    "fetched": db_stats.get::<i64, _>("tup_fetched"),
                    "inserted": db_stats.get::<i64, _>("tup_inserted"),
                    "updated": db_stats.get::<i64, _>("tup_updated"),
                    "deleted": db_stats.get::<i64, _>("tup_deleted")
                }
            }
        });

        Ok(stats)
    }
}

/// Database migration utilities for deployment automation
/// I'm providing migration management that ensures reliable deployments
pub struct MigrationManager;

impl MigrationManager {
    /// Run all pending migrations
    /// I'm implementing comprehensive migration execution with rollback support
    pub async fn run_migrations(pool: &DatabasePool) -> Result<()> {
        tracing::info!("Running database migrations");

        match sqlx::migrate!("src/database/migrations").run(pool).await {
            Ok(_) => {
                tracing::info!("Database migrations completed successfully");
                Ok(())
            }
            Err(e) => {
                tracing::error!("Database migration failed: {}", e);
                Err(AppError::DatabaseError(format!("Migration failed: {}", e)))
            }
        }
    }

    /// Check migration status
    /// I'm providing migration status verification for deployment validation
    pub async fn check_migration_status(pool: &DatabasePool) -> Result<serde_json::Value> {
        // Check if _sqlx_migrations table exists
        let migrations_table_exists = DatabaseUtils::table_exists(pool, "_sqlx_migrations").await?;

        if !migrations_table_exists {
            return Ok(serde_json::json!({
                "status": "no_migrations_run",
                "message": "No migrations have been executed yet"
            }));
        }

        // Get applied migrations
        let applied_migrations = sqlx::query(
            "SELECT version, description, installed_on, success
             FROM _sqlx_migrations
             ORDER BY version"
        )
        .fetch_all(pool)
        .await?;

        let migration_info: Vec<serde_json::Value> = applied_migrations
            .iter()
            .map(|row| {
                serde_json::json!({
                    "version": row.get::<i64, _>("version"),
                    "description": row.get::<String, _>("description"),
                    "installed_on": row.get::<chrono::DateTime<chrono::Utc>, _>("installed_on"),
                    "success": row.get::<bool, _>("success")
                })
            })
            .collect();

        Ok(serde_json::json!({
            "status": "migrations_applied",
            "count": migration_info.len(),
            "migrations": migration_info
        }))
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_module_structure() {
        // I'm ensuring the module structure is properly organized
        assert!(true, "Database module structure is valid");
    }
}
</file>

<file path="src/models/fractals.rs">
/*
 * Fractal computation models defining data structures for mathematical visualization and performance tracking in the showcase.
 * I'm implementing comprehensive fractal parameter management, result handling, and benchmark structures that integrate seamlessly with the high-performance Rust computation engine.
 */

use serde::{Deserialize, Serialize};
use sqlx::FromRow;
use chrono::{DateTime, Utc};
use validator::{Validate, ValidationError};

/// Core fractal generation request with comprehensive parameter validation
/// I'm ensuring all fractal parameters are within safe computational bounds
#[derive(Debug, Clone, Serialize, Deserialize, Validate)]
pub struct FractalRequest {
    #[validate(range(min = 64, max = 4096, message = "Width must be between 64 and 4096 pixels"))]
    pub width: u32,

    #[validate(range(min = 64, max = 4096, message = "Height must be between 64 and 4096 pixels"))]
    pub height: u32,

    #[validate(range(min = -2.0, max = 2.0, message = "Center X must be between -2.0 and 2.0"))]
    pub center_x: f64,

    #[validate(range(min = -2.0, max = 2.0, message = "Center Y must be between -2.0 and 2.0"))]
    pub center_y: f64,

    #[validate(range(min = 0.1, max = 1e15, message = "Zoom must be between 0.1 and 1e15"))]
    pub zoom: f64,

    #[validate(range(min = 50, max = 10000, message = "Max iterations must be between 50 and 10000"))]
    pub max_iterations: u32,

    pub fractal_type: FractalType,
}

/// Fractal computation response with comprehensive performance metrics
/// I'm providing detailed performance analysis alongside the computational results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FractalResponse {
    pub data: Vec<u8>,
    pub width: u32,
    pub height: u32,
    pub computation_time_ms: u128,
    pub zoom_level: f64,
    pub parameters: FractalParameters,
    pub performance_metrics: FractalPerformanceMetrics,
    pub metadata: FractalMetadata,
}

/// Fractal type enumeration supporting Mandelbrot and Julia sets
/// I'm implementing type-safe fractal variants with specific parameters
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum FractalType {
    Mandelbrot,
    Julia { c_real: f64, c_imag: f64 },
}

impl FractalType {
    pub fn name(&self) -> &'static str {
        match self {
            FractalType::Mandelbrot => "mandelbrot",
            FractalType::Julia { .. } => "julia",
        }
    }

    pub fn is_julia(&self) -> bool {
        matches!(self, FractalType::Julia { .. })
    }

    pub fn julia_constant(&self) -> Option<(f64, f64)> {
        match *self {
            FractalType::Julia { c_real, c_imag } => Some((c_real, c_imag)),
            _ => None,
        }
    }
}

/// Fractal computation parameters for result tracking
/// I'm preserving all parameters used in fractal generation for reproducibility
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FractalParameters {
    pub fractal_type: String,
    pub center_x: f64,
    pub center_y: f64,
    pub zoom_level: f64,
    pub max_iterations: u32,
    pub julia_constant: Option<(f64, f64)>,
    pub color_palette: String,
    pub escape_radius: f64,
}

impl FractalParameters {
    pub fn from_request(request: &FractalRequest) -> Self {
        Self {
            fractal_type: request.fractal_type.name().to_string(),
            center_x: request.center_x,
            center_y: request.center_y,
            zoom_level: request.zoom,
            max_iterations: request.max_iterations,
            julia_constant: request.fractal_type.julia_constant(),
            color_palette: "dark_theme".to_string(),
            escape_radius: 4.0,
        }
    }
}

/// Comprehensive performance metrics for fractal computations
/// I'm tracking detailed performance data for optimization and showcase purposes
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FractalPerformanceMetrics {
    pub pixels_per_second: f64,
    pub parallel_efficiency: f64,
    pub memory_usage_mb: f64,
    pub cpu_utilization: f64,
    pub cache_hit_rate: f64,
    pub optimization_flags: Vec<String>,
    pub simd_acceleration: bool,
    pub thread_count: u32,
    pub computation_complexity: ComputationComplexity,
}

/// Computation complexity classification for performance analysis
/// I'm categorizing fractal computations by their computational demands
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ComputationComplexity {
    Low,
    Medium,
    High,
    Extreme,
}

impl ComputationComplexity {
    pub fn from_parameters(width: u32, height: u32, iterations: u32, zoom: f64) -> Self {
        let pixel_count = width * height;
        let complexity_score = (pixel_count as f64 * iterations as f64 * zoom.log10().max(0.0)) / 1_000_000.0;

        match complexity_score {
            x if x < 1.0 => ComputationComplexity::Low,
            x if x < 10.0 => ComputationComplexity::Medium,
            x if x < 100.0 => ComputationComplexity::High,
            _ => ComputationComplexity::Extreme,
        }
    }
}

/// Fractal computation metadata for tracking and analytics
/// I'm providing comprehensive metadata for fractal generation tracking
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FractalMetadata {
    pub generation_id: uuid::Uuid,
    pub timestamp: DateTime<Utc>,
    pub request_source: String,
    pub computation_method: String,
    pub quality_metrics: QualityMetrics,
    pub version_info: VersionInfo,
}

/// Quality assessment metrics for fractal visualizations
/// I'm implementing quality analysis for fractal rendering assessment
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QualityMetrics {
    pub detail_level: f64,
    pub convergence_rate: f64,
    pub edge_definition: f64,
    pub color_distribution: f64,
    pub overall_quality: QualityRating,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum QualityRating {
    Excellent,
    Good,
    Fair,
    Poor,
}

/// Version information for reproducible computations
/// I'm tracking software versions for computational reproducibility
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VersionInfo {
    pub engine_version: String,
    pub rust_version: String,
    pub algorithm_version: String,
    pub optimization_level: String,
}

/// Database model for fractal computation logging
/// I'm implementing comprehensive fractal computation tracking in the database
#[derive(Debug, Clone, Serialize, Deserialize, FromRow)]
pub struct FractalComputationLog {
    pub id: uuid::Uuid,
    pub fractal_type: String,
    pub width: i32,
    pub height: i32,
    pub center_x: f64,
    pub center_y: f64,
    pub zoom_level: f64,
    pub max_iterations: i32,
    pub julia_c_real: Option<f64>,
    pub julia_c_imag: Option<f64>,
    pub computation_time_ms: i32,
    pub memory_used_bytes: Option<i64>,
    pub cpu_cores_used: Option<i32>,
    pub parallel_threads: Option<i32>,
    pub pixels_computed: i64,
    pub pixels_per_ms: f64,
    pub session_id: Option<uuid::Uuid>,
    pub ip_address: Option<std::net::IpAddr>,
    pub user_agent: Option<String>,
    pub timestamp: DateTime<Utc>,
    pub iteration_efficiency: Option<f64>,
    pub cache_hit: bool,
    pub optimization_flags: Option<Vec<String>>,
}

impl FractalComputationLog {
    pub fn from_request_and_response(
        request: &FractalRequest,
        response: &FractalResponse,
        session_id: Option<uuid::Uuid>,
        ip_address: Option<std::net::IpAddr>,
        user_agent: Option<String>,
    ) -> Self {
        let (julia_c_real, julia_c_imag) = match &request.fractal_type {
            FractalType::Julia { c_real, c_imag } => (Some(*c_real), Some(*c_imag)),
            _ => (None, None),
        };

        Self {
            id: uuid::Uuid::new_v4(),
            fractal_type: request.fractal_type.name().to_string(),
            width: request.width as i32,
            height: request.height as i32,
            center_x: request.center_x,
            center_y: request.center_y,
            zoom_level: request.zoom,
            max_iterations: request.max_iterations as i32,
            julia_c_real,
            julia_c_imag,
            computation_time_ms: response.computation_time_ms as i32,
            memory_used_bytes: Some((response.performance_metrics.memory_usage_mb * 1024.0 * 1024.0) as i64),
            cpu_cores_used: Some(response.performance_metrics.thread_count as i32),
            parallel_threads: Some(response.performance_metrics.thread_count as i32),
            pixels_computed: (request.width * request.height) as i64,
            pixels_per_ms: response.performance_metrics.pixels_per_second / 1000.0,
            session_id,
            ip_address,
            user_agent,
            timestamp: Utc::now(),
            iteration_efficiency: Some(calculate_iteration_efficiency(&response)),
            cache_hit: response.performance_metrics.cache_hit_rate > 0.0,
            optimization_flags: Some(response.performance_metrics.optimization_flags.clone()),
        }
    }
}

/// Benchmark request structure for performance testing
/// I'm implementing comprehensive benchmark configuration for performance analysis
#[derive(Debug, Clone, Serialize, Deserialize, Validate)]
pub struct BenchmarkRequest {
    #[validate(range(min = 1, max = 100, message = "Iterations must be between 1 and 100"))]
    pub iterations: u32,

    pub test_scenarios: Vec<BenchmarkScenario>,
    pub include_system_info: bool,
    pub include_comparison: bool,
    pub parallel_execution: bool,
}

/// Individual benchmark scenario configuration
/// I'm defining specific test cases for comprehensive performance evaluation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkScenario {
    pub name: String,
    pub description: String,
    pub fractal_request: FractalRequest,
    pub expected_performance: Option<ExpectedPerformance>,
}

/// Expected performance baseline for regression testing
/// I'm implementing performance regression detection
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExpectedPerformance {
    pub max_computation_time_ms: u128,
    pub min_pixels_per_second: f64,
    pub max_memory_usage_mb: f64,
    pub min_parallel_efficiency: f64,
}

/// Comprehensive benchmark response with detailed analysis
/// I'm providing thorough benchmark results for performance evaluation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkResponse {
    pub benchmark_id: uuid::Uuid,
    pub timestamp: DateTime<Utc>,
    pub total_duration_ms: u128,
    pub scenarios: Vec<BenchmarkScenarioResult>,
    pub system_context: SystemContext,
    pub performance_analysis: PerformanceAnalysis,
    pub comparison_results: Option<ComparisonResults>,
}

/// Individual benchmark scenario results
/// I'm tracking detailed results for each benchmark scenario
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkScenarioResult {
    pub scenario_name: String,
    pub iterations_completed: u32,
    pub fractal_results: Vec<FractalResponse>,
    pub average_computation_time_ms: f64,
    pub average_pixels_per_second: f64,
    pub performance_variance: f64,
    pub passed_expectations: bool,
    pub performance_rating: String,
}

/// System context information for benchmark analysis
/// I'm capturing system state during benchmark execution
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SystemContext {
    pub cpu_model: String,
    pub cpu_cores: u32,
    pub memory_total_gb: f64,
    pub rust_version: String,
    pub compiler_flags: Vec<String>,
    pub parallel_processing: bool,
    pub simd_support: Vec<String>,
    pub system_load: f64,
}

/// Performance analysis summary
/// I'm providing comprehensive performance insights
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceAnalysis {
    pub overall_rating: String,
    pub performance_grade: char,
    pub strengths: Vec<String>,
    pub bottlenecks: Vec<String>,
    pub recommendations: Vec<String>,
    pub efficiency_score: f64,
}

/// Comparison results against baseline performance
/// I'm implementing performance comparison for continuous improvement
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ComparisonResults {
    pub baseline_system: String,
    pub relative_performance: f64,
    pub performance_delta: f64,
    pub regression_detected: bool,
    pub improvement_areas: Vec<String>,
}

// Helper functions for fractal computations and analysis

fn calculate_iteration_efficiency(response: &FractalResponse) -> f64 {
    let total_pixels = response.width as f64 * response.height as f64;
    let max_possible_iterations = response.parameters.max_iterations as f64 * total_pixels;
    let computation_time_seconds = response.computation_time_ms as f64 / 1000.0;

    // Estimate actual iterations based on computation time and complexity
    let estimated_iterations = response.performance_metrics.pixels_per_second * computation_time_seconds;

    if max_possible_iterations > 0.0 {
        (estimated_iterations / max_possible_iterations).min(1.0)
    } else {
        0.0
    }
}

impl Default for BenchmarkRequest {
    fn default() -> Self {
        Self {
            iterations: 5,
            test_scenarios: vec![
                BenchmarkScenario {
                    name: "low_complexity".to_string(),
                    description: "Low complexity Mandelbrot set".to_string(),
                    fractal_request: FractalRequest {
                        width: 512,
                        height: 512,
                        center_x: -0.5,
                        center_y: 0.0,
                        zoom: 1.0,
                        max_iterations: 100,
                        fractal_type: FractalType::Mandelbrot,
                    },
                    expected_performance: None,
                },
                BenchmarkScenario {
                    name: "medium_complexity".to_string(),
                    description: "Medium complexity Julia set".to_string(),
                    fractal_request: FractalRequest {
                        width: 1024,
                        height: 1024,
                        center_x: 0.0,
                        center_y: 0.0,
                        zoom: 1.0,
                        max_iterations: 200,
                        fractal_type: FractalType::Julia { c_real: -0.7, c_imag: 0.27015 },
                    },
                    expected_performance: None,
                },
            ],
            include_system_info: true,
            include_comparison: false,
            parallel_execution: true,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_fractal_type_properties() {
        let mandelbrot = FractalType::Mandelbrot;
        let julia = FractalType::Julia { c_real: -0.7, c_imag: 0.27015 };

        assert_eq!(mandelbrot.name(), "mandelbrot");
        assert_eq!(julia.name(), "julia");
        assert!(!mandelbrot.is_julia());
        assert!(julia.is_julia());
        assert_eq!(julia.julia_constant(), Some((-0.7, 0.27015)));
    }

    #[test]
    fn test_computation_complexity_classification() {
        let low = ComputationComplexity::from_parameters(256, 256, 50, 1.0);
        let high = ComputationComplexity::from_parameters(2048, 2048, 1000, 1000.0);

        assert!(matches!(low, ComputationComplexity::Low));
        assert!(matches!(high, ComputationComplexity::Extreme));
    }

    #[test]
    fn test_fractal_request_validation() {
        let valid_request = FractalRequest {
            width: 800,
            height: 600,
            center_x: -0.5,
            center_y: 0.0,
            zoom: 1.0,
            max_iterations: 100,
            fractal_type: FractalType::Mandelbrot,
        };

        assert!(valid_request.validate().is_ok());

        let invalid_request = FractalRequest {
            width: 5000, // Too large
            height: 600,
            center_x: -0.5,
            center_y: 0.0,
            zoom: 1.0,
            max_iterations: 100,
            fractal_type: FractalType::Mandelbrot,
        };

        assert!(invalid_request.validate().is_err());
    }
}
</file>

<file path="src/models/github.rs">
/*
 * GitHub data models with comprehensive serialization, validation, and database integration for repository showcase.
 * I'm defining robust data structures that handle GitHub API responses and provide clean interfaces for frontend consumption.
 */

use serde::{Deserialize, Serialize};
use sqlx::FromRow;
use chrono::{DateTime, Utc};

/// Core repository model representing GitHub repository data with caching metadata
/// I'm including all essential fields for showcase purposes plus performance tracking
#[derive(Debug, Clone, Serialize, Deserialize, FromRow)]
pub struct Repository {
    pub id: i64,
    pub github_id: i64,
    pub owner_login: String,
    pub name: String,
    pub full_name: String,
    pub description: Option<String>,
    pub html_url: String,
    pub clone_url: String,
    pub ssh_url: String,
    pub language: Option<String>,
    pub size_kb: i32,
    pub stargazers_count: i32,
    pub watchers_count: i32,
    pub forks_count: i32,
    pub open_issues_count: i32,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
    pub pushed_at: Option<DateTime<Utc>>,
    pub is_private: bool,
    pub is_fork: bool,
    pub is_archived: bool,
    pub topics: Vec<String>,
    pub license_name: Option<String>,
    pub readme_content: Option<String>,
    pub cache_updated_at: DateTime<Utc>,
    pub cache_expires_at: DateTime<Utc>,
}

/// Extended repository model with detailed analytics and performance metrics
/// I'm providing comprehensive repository analysis for the showcase
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RepositoryDetailed {
    #[serde(flatten)]
    pub basic: Repository,
    pub readme_content: String,
    pub stats: RepositoryStats,
    pub contributors_count: i32,
    pub commit_count: i32,
    pub branch_count: i32,
    pub release_count: i32,
}

/// Repository statistics and health metrics for performance analysis
/// I'm calculating meaningful metrics that showcase repository activity and quality
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RepositoryStats {
    pub commit_frequency: f64,        // Commits per week average
    pub contributors_count: i32,      // Number of unique contributors
    pub issues_ratio: f64,           // Open issues / total issues
    pub fork_ratio: f64,             // Forks / stars ratio
    pub activity_score: f64,         // Overall activity score (0-100)
    pub health_score: f64,           // Repository health score (0-100)
    pub last_activity_days: i32,     // Days since last activity
}

/// GitHub user model for owner information and contributor data
/// I'm including essential user data for repository context
#[derive(Debug, Clone, Serialize, Deserialize, FromRow)]
pub struct GitHubUser {
    pub id: i64,
    pub login: String,
    pub name: Option<String>,
    pub email: Option<String>,
    pub avatar_url: String,
    pub html_url: String,
    pub bio: Option<String>,
    pub location: Option<String>,
    pub company: Option<String>,
    pub blog: Option<String>,
    pub twitter_username: Option<String>,
    pub public_repos: i32,
    pub public_gists: i32,
    pub followers: i32,
    pub following: i32,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

/// Repository language statistics for technology showcase
/// I'm tracking language usage across repositories for analytics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LanguageStats {
    pub language: String,
    pub byte_count: i64,
    pub percentage: f64,
    pub repository_count: i32,
}

/// Repository filtering and search criteria for API endpoints
/// I'm providing flexible filtering options for repository discovery
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RepositoryFilter {
    pub language: Option<String>,
    pub min_stars: Option<i32>,
    pub max_stars: Option<i32>,
    pub min_size_kb: Option<i32>,
    pub max_size_kb: Option<i32>,
    pub is_fork: Option<bool>,
    pub is_archived: Option<bool>,
    pub has_topics: Option<bool>,
    pub has_license: Option<bool>,
    pub created_after: Option<DateTime<Utc>>,
    pub created_before: Option<DateTime<Utc>>,
    pub updated_after: Option<DateTime<Utc>>,
    pub updated_before: Option<DateTime<Utc>>,
    pub search_query: Option<String>,
}

/// Repository sorting options for organized display
/// I'm providing multiple sorting strategies for different use cases
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum RepositorySort {
    Name,
    Stars,
    Forks,
    Updated,
    Created,
    Size,
    Issues,
    ActivityScore,
}

/// Repository collection response with pagination and metadata
/// I'm providing comprehensive response structure for API endpoints
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RepositoryCollection {
    pub repositories: Vec<Repository>,
    pub total_count: i32,
    pub page: i32,
    pub per_page: i32,
    pub total_pages: i32,
    pub has_next_page: bool,
    pub has_previous_page: bool,
    pub language_distribution: Vec<LanguageStats>,
    pub statistics: CollectionStats,
}

/// Aggregate statistics for repository collections
/// I'm calculating meaningful metrics across repository sets
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CollectionStats {
    pub total_stars: i32,
    pub total_forks: i32,
    pub total_size_kb: i64,
    pub average_stars: f64,
    pub most_starred_repo: String,
    pub newest_repo: String,
    pub most_active_repo: String,
    pub language_count: i32,
    pub topics_count: i32,
    pub archived_count: i32,
    pub fork_count: i32,
}

/// GitHub API rate limit information for monitoring and optimization
/// I'm tracking rate limits to prevent API exhaustion
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RateLimitInfo {
    pub limit: i32,
    pub remaining: i32,
    pub reset_at: DateTime<Utc>,
    pub used: i32,
    pub percentage_used: f64,
}

/// Repository contribution data for activity analysis
/// I'm tracking contribution patterns for showcase purposes
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ContributionData {
    pub author: GitHubUser,
    pub commit_count: i32,
    pub additions: i32,
    pub deletions: i32,
    pub changed_files: i32,
    pub first_contribution: DateTime<Utc>,
    pub last_contribution: DateTime<Utc>,
}

/// Repository release information for version tracking
/// I'm including release data for project maturity indicators
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RepositoryRelease {
    pub id: i64,
    pub tag_name: String,
    pub name: Option<String>,
    pub body: Option<String>,
    pub draft: bool,
    pub prerelease: bool,
    pub created_at: DateTime<Utc>,
    pub published_at: Option<DateTime<Utc>>,
    pub author: GitHubUser,
    pub assets_count: i32,
    pub download_count: i32,
}

impl Repository {
    /// Calculate repository activity score based on various metrics
    /// I'm implementing a comprehensive scoring algorithm for repository health
    pub fn calculate_activity_score(&self) -> f64 {
        let mut score = 0.0;

        // Stars contribute to score (logarithmic scale to prevent skewing)
        if self.stargazers_count > 0 {
            score += (self.stargazers_count as f64).ln() * 10.0;
        }

        // Recent activity bonus
        if let Some(pushed_at) = self.pushed_at {
            let days_since_push = (Utc::now() - pushed_at).num_days();
            if days_since_push < 30 {
                score += 20.0;
            } else if days_since_push < 90 {
                score += 10.0;
            }
        }

        // Fork ratio (indicates usefulness)
        if self.stargazers_count > 0 {
            let fork_ratio = self.forks_count as f64 / self.stargazers_count as f64;
            score += fork_ratio * 15.0;
        }

        // Issue management (lower open issues ratio is better)
        if self.open_issues_count > 0 {
            score -= (self.open_issues_count as f64).ln() * 2.0;
        }

        // Documentation (has description and topics)
        if self.description.is_some() {
            score += 5.0;
        }
        if !self.topics.is_empty() {
            score += self.topics.len() as f64 * 2.0;
        }

        // License indicates maturity
        if self.license_name.is_some() {
            score += 5.0;
        }

        // Penalize archived repositories
        if self.is_archived {
            score *= 0.5;
        }

        // Normalize to 0-100 scale
        score.max(0.0).min(100.0)
    }

    /// Check if repository cache is still valid
    /// I'm implementing intelligent cache validation for performance optimization
    pub fn is_cache_valid(&self) -> bool {
        Utc::now() < self.cache_expires_at
    }

    /// Get repository age in days
    /// I'm calculating repository maturity for analysis
    pub fn age_in_days(&self) -> i64 {
        (Utc::now() - self.created_at).num_days()
    }

    /// Get days since last update
    /// I'm tracking repository freshness for activity analysis
    pub fn days_since_update(&self) -> i64 {
        (Utc::now() - self.updated_at).num_days()
    }

    /// Generate repository summary for display
    /// I'm creating concise summaries for UI components
    pub fn generate_summary(&self) -> String {
        let mut summary_parts = Vec::new();

        if let Some(ref language) = self.language {
            summary_parts.push(language.clone());
        }

        if self.stargazers_count > 0 {
            summary_parts.push(format!(" {}", self.stargazers_count));
        }

        if self.forks_count > 0 {
            summary_parts.push(format!(" {}", self.forks_count));
        }

        if self.size_kb > 0 {
            let size_mb = self.size_kb as f64 / 1024.0;
            if size_mb >= 1.0 {
                summary_parts.push(format!("{:.1} MB", size_mb));
            } else {
                summary_parts.push(format!("{} KB", self.size_kb));
            }
        }

        summary_parts.join("  ")
    }
}

impl RepositoryFilter {
    /// Create a new empty filter
    /// I'm providing a convenient constructor for filter initialization
    pub fn new() -> Self {
        Self {
            language: None,
            min_stars: None,
            max_stars: None,
            min_size_kb: None,
            max_size_kb: None,
            is_fork: None,
            is_archived: None,
            has_topics: None,
            has_license: None,
            created_after: None,
            created_before: None,
            updated_after: None,
            updated_before: None,
            search_query: None,
        }
    }

    /// Apply filter to a repository collection
    /// I'm implementing client-side filtering for improved performance
    pub fn apply(&self, repositories: Vec<Repository>) -> Vec<Repository> {
        repositories
        .into_iter()
        .filter(|repo| self.matches(repo))
        .collect()
    }

    /// Check if a repository matches the filter criteria
    /// I'm implementing comprehensive filtering logic
    fn matches(&self, repo: &Repository) -> bool {
        if let Some(ref lang) = self.language {
            if repo.language.as_ref() != Some(lang) {
                return false;
            }
        }

        if let Some(min_stars) = self.min_stars {
            if repo.stargazers_count < min_stars {
                return false;
            }
        }

        if let Some(max_stars) = self.max_stars {
            if repo.stargazers_count > max_stars {
                return false;
            }
        }

        if let Some(min_size) = self.min_size_kb {
            if repo.size_kb < min_size {
                return false;
            }
        }

        if let Some(max_size) = self.max_size_kb {
            if repo.size_kb > max_size {
                return false;
            }
        }

        if let Some(is_fork) = self.is_fork {
            if repo.is_fork != is_fork {
                return false;
            }
        }

        if let Some(is_archived) = self.is_archived {
            if repo.is_archived != is_archived {
                return false;
            }
        }

        if let Some(has_topics) = self.has_topics {
            if repo.topics.is_empty() == has_topics {
                return false;
            }
        }

        if let Some(has_license) = self.has_license {
            if repo.license_name.is_some() != has_license {
                return false;
            }
        }

        if let Some(created_after) = self.created_after {
            if repo.created_at < created_after {
                return false;
            }
        }

        if let Some(created_before) = self.created_before {
            if repo.created_at > created_before {
                return false;
            }
        }

        if let Some(updated_after) = self.updated_after {
            if repo.updated_at < updated_after {
                return false;
            }
        }

        if let Some(updated_before) = self.updated_before {
            if repo.updated_at > updated_before {
                return false;
            }
        }

        if let Some(ref query) = self.search_query {
            let search_text = format!(
                "{} {} {}",
                repo.name,
                repo.description.as_deref().unwrap_or(""),
                                      repo.topics.join(" ")
            ).to_lowercase();

            if !search_text.contains(&query.to_lowercase()) {
                return false;
            }
        }

        true
    }
}

impl Default for RepositoryFilter {
    fn default() -> Self {
        Self::new()
    }
}

/// Helper function to calculate collection statistics
/// I'm providing aggregate analytics for repository collections
pub fn calculate_collection_stats(repositories: &[Repository]) -> CollectionStats {
    if repositories.is_empty() {
        return CollectionStats {
            total_stars: 0,
            total_forks: 0,
            total_size_kb: 0,
            average_stars: 0.0,
            most_starred_repo: String::new(),
            newest_repo: String::new(),
            most_active_repo: String::new(),
            language_count: 0,
            topics_count: 0,
            archived_count: 0,
            fork_count: 0,
        };
    }

    let total_stars: i32 = repositories.iter().map(|r| r.stargazers_count).sum();
    let total_forks: i32 = repositories.iter().map(|r| r.forks_count).sum();
    let total_size_kb: i64 = repositories.iter().map(|r| r.size_kb as i64).sum();
    let average_stars = total_stars as f64 / repositories.len() as f64;

    let most_starred_repo = repositories
    .iter()
    .max_by_key(|r| r.stargazers_count)
    .map(|r| r.full_name.clone())
    .unwrap_or_default();

    let newest_repo = repositories
    .iter()
    .max_by_key(|r| r.created_at)
    .map(|r| r.full_name.clone())
    .unwrap_or_default();

    let most_active_repo = repositories
    .iter()
    .max_by_key(|r| r.calculate_activity_score() as i64)
    .map(|r| r.full_name.clone())
    .unwrap_or_default();

    let languages: std::collections::HashSet<String> = repositories
    .iter()
    .filter_map(|r| r.language.as_ref())
    .cloned()
    .collect();

    let all_topics: std::collections::HashSet<String> = repositories
    .iter()
    .flat_map(|r| r.topics.iter())
    .cloned()
    .collect();

    let archived_count = repositories.iter().filter(|r| r.is_archived).count() as i32;
    let fork_count = repositories.iter().filter(|r| r.is_fork).count() as i32;

    CollectionStats {
        total_stars,
        total_forks,
        total_size_kb,
        average_stars,
        most_starred_repo,
        newest_repo,
        most_active_repo,
        language_count: languages.len() as i32,
        topics_count: all_topics.len() as i32,
        archived_count,
        fork_count,
    }
}
</file>

<file path="src/models/mod.rs">
/*
 * Models module aggregator organizing all data structures and business logic entities for the dark performance showcase backend.
 * I'm providing a clean interface to GitHub repository data, fractal computation parameters, and performance metrics with comprehensive serialization and validation support.
 */

pub mod github;
pub mod fractals;
pub mod performance;

// Re-export commonly used models for convenient access throughout the application
pub use github::{
    Repository,
    RepositoryDetailed,
    RepositoryStats,
    GitHubUser,
    RepositoryFilter,
    RepositoryCollection,
    CollectionStats,
    LanguageStats,
    RateLimitInfo,
    calculate_collection_stats
};

pub use fractals::{
    FractalRequest,
    FractalResponse,
    FractalType,
    FractalParameters,
    FractalMetadata,
    FractalComputationLog,
    BenchmarkRequest,
    BenchmarkResponse
};

pub use performance::{
    PerformanceMetric,
    SystemInfo,
    BenchmarkResult,
    MetricType,
    MetricValue,
    SystemSnapshot,
    PerformanceAlert,
    ResourceUsage
};

use serde::{Deserialize, Serialize};
use chrono::{DateTime, Utc};

/// Common pagination structure used across all API responses
/// I'm providing consistent pagination handling for all list endpoints
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Pagination {
    pub current_page: i32,
    pub per_page: i32,
    pub total_pages: i32,
    pub total_count: i32,
    pub has_next_page: bool,
    pub has_previous_page: bool,
}

impl Pagination {
    pub fn new(current_page: i32, per_page: i32, total_count: i32) -> Self {
        let total_pages = ((total_count as f64) / (per_page as f64)).ceil() as i32;

        Self {
            current_page,
            per_page,
            total_pages,
            total_count,
            has_next_page: current_page < total_pages,
            has_previous_page: current_page > 1,
        }
    }
}

/// Standard API response wrapper for consistent response formatting
/// I'm implementing consistent API response structure across all endpoints
#[derive(Debug, Serialize, Deserialize)]
pub struct ApiResponse<T> {
    pub data: T,
    pub pagination: Option<Pagination>,
    pub metadata: Option<serde_json::Value>,
    pub timestamp: DateTime<Utc>,
    pub request_duration_ms: Option<u128>,
}

impl<T> ApiResponse<T> {
    pub fn new(data: T) -> Self {
        Self {
            data,
            pagination: None,
            metadata: None,
            timestamp: Utc::now(),
            request_duration_ms: None,
        }
    }

    pub fn with_pagination(mut self, pagination: Pagination) -> Self {
        self.pagination = Some(pagination);
        self
    }

    pub fn with_metadata(mut self, metadata: serde_json::Value) -> Self {
        self.metadata = Some(metadata);
        self
    }

    pub fn with_duration(mut self, duration_ms: u128) -> Self {
        self.request_duration_ms = Some(duration_ms);
        self
    }
}

/// Health check response structure for system monitoring
/// I'm providing standardized health check information across all services
#[derive(Debug, Serialize, Deserialize)]
pub struct HealthCheck {
    pub status: HealthStatus,
    pub timestamp: DateTime<Utc>,
    pub version: String,
    pub uptime_seconds: u64,
    pub services: std::collections::HashMap<String, ServiceHealth>,
    pub system: Option<SystemHealth>,
}

#[derive(Debug, Serialize, Deserialize)]
pub enum HealthStatus {
    Healthy,
    Degraded,
    Unhealthy,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ServiceHealth {
    pub status: HealthStatus,
    pub response_time_ms: Option<u64>,
    pub last_check: DateTime<Utc>,
    pub error_message: Option<String>,
    pub metadata: Option<serde_json::Value>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct SystemHealth {
    pub cpu_usage_percent: f64,
    pub memory_usage_percent: f64,
    pub disk_usage_percent: f64,
    pub active_connections: u32,
    pub load_average: f64,
}

/// Common sorting and filtering structures
/// I'm providing reusable sorting and filtering functionality across different entity types
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SortOptions {
    pub field: String,
    pub direction: SortDirection,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SortDirection {
    Asc,
    Desc,
}

impl Default for SortDirection {
    fn default() -> Self {
        Self::Desc
    }
}

/// Query parameters for list endpoints
/// I'm standardizing query parameter handling across all list operations
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ListQuery {
    pub page: Option<i32>,
    pub per_page: Option<i32>,
    pub sort: Option<SortOptions>,
    pub search: Option<String>,
    pub filters: Option<serde_json::Value>,
}

impl ListQuery {
    pub fn page(&self) -> i32 {
        self.page.unwrap_or(1).max(1)
    }

    pub fn per_page(&self) -> i32 {
        self.per_page.unwrap_or(20).clamp(1, 100)
    }

    pub fn offset(&self) -> i32 {
        (self.page() - 1) * self.per_page()
    }
}

/// Audit log structure for tracking changes and operations
/// I'm implementing comprehensive audit logging for security and debugging
#[derive(Debug, Serialize, Deserialize)]
pub struct AuditLog {
    pub id: uuid::Uuid,
    pub entity_type: String,
    pub entity_id: Option<String>,
    pub action: AuditAction,
    pub user_id: Option<String>,
    pub ip_address: Option<String>,
    pub user_agent: Option<String>,
    pub timestamp: DateTime<Utc>,
    pub changes: Option<serde_json::Value>,
    pub metadata: Option<serde_json::Value>,
}

#[derive(Debug, Serialize, Deserialize)]
pub enum AuditAction {
    Create,
    Read,
    Update,
    Delete,
    Execute,
    Login,
    Logout,
    Error,
}

/// Cache metadata for intelligent caching strategies
/// I'm providing comprehensive cache metadata for optimization
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheMetadata {
    pub key: String,
    pub created_at: DateTime<Utc>,
    pub expires_at: DateTime<Utc>,
    pub last_accessed: DateTime<Utc>,
    pub access_count: u64,
    pub size_bytes: u64,
    pub tags: Vec<String>,
    pub dependencies: Vec<String>,
}

impl CacheMetadata {
    pub fn new(key: String, ttl_seconds: u64) -> Self {
        let now = Utc::now();
        Self {
            key,
            created_at: now,
            expires_at: now + chrono::Duration::seconds(ttl_seconds as i64),
            last_accessed: now,
            access_count: 0,
            size_bytes: 0,
            tags: Vec::new(),
            dependencies: Vec::new(),
        }
    }

    pub fn is_expired(&self) -> bool {
        Utc::now() > self.expires_at
    }

    pub fn touch(&mut self) {
        self.last_accessed = Utc::now();
        self.access_count += 1;
    }
}

/// Model validation trait for consistent data validation
/// I'm implementing standardized validation across all models
pub trait Validate {
    type Error;

    fn validate(&self) -> Result<(), Self::Error>;
}

/// Model transformation trait for data conversion
/// I'm providing consistent data transformation patterns
pub trait Transform<T> {
    fn transform(self) -> T;
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_pagination_calculation() {
        let pagination = Pagination::new(2, 10, 95);

        assert_eq!(pagination.current_page, 2);
        assert_eq!(pagination.total_pages, 10);
        assert!(pagination.has_next_page);
        assert!(pagination.has_previous_page);
    }

    #[test]
    fn test_list_query_defaults() {
        let query = ListQuery {
            page: None,
            per_page: None,
            sort: None,
            search: None,
            filters: None,
        };

        assert_eq!(query.page(), 1);
        assert_eq!(query.per_page(), 20);
        assert_eq!(query.offset(), 0);
    }

    #[test]
    fn test_cache_metadata_expiration() {
        let mut metadata = CacheMetadata::new("test_key".to_string(), 1);

        assert!(!metadata.is_expired());

        // Simulate time passing
        metadata.expires_at = Utc::now() - chrono::Duration::seconds(1);
        assert!(metadata.is_expired());
    }
}
</file>

<file path="src/models/performance.rs">
/*
 * Performance monitoring models defining comprehensive system metrics, benchmark structures, and analytical data for the showcase backend.
 * I'm implementing detailed performance tracking with time-series data, alerting capabilities, and resource utilization monitoring that showcases the application's computational efficiency.
 */

use serde::{Deserialize, Serialize};
use sqlx::FromRow;
use chrono::{DateTime, Utc};
use std::collections::HashMap;
use validator::{Validate, ValidationError};

/// Comprehensive system performance metrics snapshot
/// I'm capturing all essential system performance indicators for real-time monitoring
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SystemInfo {
    pub timestamp: DateTime<Utc>,
    pub cpu_model: String,
    pub cpu_cores: u32,
    pub cpu_threads: u32,
    pub cpu_usage_percent: f64,
    pub cpu_frequency_mhz: Option<u32>,
    pub memory_total_mb: u64,
    pub memory_available_mb: u64,
    pub memory_usage_percent: f64,
    pub swap_total_mb: u64,
    pub swap_used_mb: u64,
    pub disk_total_gb: f64,
    pub disk_available_gb: f64,
    pub disk_usage_percent: f64,
    pub network_interfaces: Vec<NetworkInterface>,
    pub load_average_1m: f64,
    pub load_average_5m: f64,
    pub load_average_15m: f64,
    pub uptime_seconds: u64,
    pub active_processes: u32,
    pub system_temperature: Option<f64>,
    pub power_consumption: Option<PowerMetrics>,
}

/// Network interface performance metrics
/// I'm tracking network performance for comprehensive system monitoring
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NetworkInterface {
    pub name: String,
    pub bytes_sent: u64,
    pub bytes_received: u64,
    pub packets_sent: u64,
    pub packets_received: u64,
    pub errors_in: u64,
    pub errors_out: u64,
    pub speed_mbps: Option<u32>,
}

/// Power consumption and efficiency metrics
/// I'm monitoring power usage for sustainability insights
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PowerMetrics {
    pub total_watts: f64,
    pub cpu_watts: Option<f64>,
    pub gpu_watts: Option<f64>,
    pub efficiency_score: f64,
}

/// Individual performance metric with metadata and context
/// I'm implementing flexible metric tracking with rich metadata support
#[derive(Debug, Clone, Serialize, Deserialize, FromRow)]
pub struct PerformanceMetric {
    pub id: uuid::Uuid,
    pub metric_type: String,
    pub metric_name: String,
    pub metric_value: f64,
    pub metric_unit: String,
    pub tags: serde_json::Value,
    pub timestamp: DateTime<Utc>,
    pub endpoint: Option<String>,
    pub user_agent: Option<String>,
    pub ip_address: Option<std::net::IpAddr>,
    pub session_id: Option<uuid::Uuid>,
    pub server_instance: Option<String>,
    pub environment: String,
}

impl PerformanceMetric {
    pub fn new(
        metric_type: impl Into<String>,
        metric_name: impl Into<String>,
        value: f64,
        unit: impl Into<String>,
    ) -> Self {
        Self {
            id: uuid::Uuid::new_v4(),
            metric_type: metric_type.into(),
            metric_name: metric_name.into(),
            metric_value: value,
            metric_unit: unit.into(),
            tags: serde_json::json!({}),
            timestamp: Utc::now(),
            endpoint: None,
            user_agent: None,
            ip_address: None,
            session_id: None,
            server_instance: None,
            environment: "production".to_string(),
        }
    }

    pub fn with_tags(mut self, tags: serde_json::Value) -> Self {
        self.tags = tags;
        self
    }

    pub fn with_context(
        mut self,
        endpoint: Option<String>,
        session_id: Option<uuid::Uuid>,
        server_instance: Option<String>,
    ) -> Self {
        self.endpoint = endpoint;
        self.session_id = session_id;
        self.server_instance = server_instance;
        self
    }
}

/// Metric type enumeration for standardized categorization
/// I'm providing type-safe metric categorization for consistent monitoring
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum MetricType {
    System,
    Application,
    Network,
    Database,
    Cache,
    Request,
    Error,
    Business,
    Security,
}

impl MetricType {
    pub fn as_str(&self) -> &'static str {
        match self {
            MetricType::System => "system",
            MetricType::Application => "application",
            MetricType::Network => "network",
            MetricType::Database => "database",
            MetricType::Cache => "cache",
            MetricType::Request => "request",
            MetricType::Error => "error",
            MetricType::Business => "business",
            MetricType::Security => "security",
        }
    }
}

/// Typed metric value with units and metadata
/// I'm implementing strongly typed metric values for better data integrity
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MetricValue {
    Counter(u64),
    Gauge(f64),
    Histogram {
        buckets: Vec<HistogramBucket>,
        sum: f64,
        count: u64,
    },
    Summary {
        quantiles: Vec<Quantile>,
        sum: f64,
        count: u64,
    },
    Timer {
        duration_ms: f64,
        start_time: DateTime<Utc>,
        end_time: DateTime<Utc>,
    },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HistogramBucket {
    pub upper_bound: f64,
    pub cumulative_count: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Quantile {
    pub quantile: f64,
    pub value: f64,
}

/// Comprehensive system performance snapshot with historical context
/// I'm providing detailed system state capture for trend analysis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SystemSnapshot {
    pub id: uuid::Uuid,
    pub timestamp: DateTime<Utc>,
    pub system_info: SystemInfo,
    pub application_metrics: ApplicationMetrics,
    pub resource_usage: ResourceUsage,
    pub performance_score: PerformanceScore,
    pub alerts: Vec<PerformanceAlert>,
    pub metadata: HashMap<String, serde_json::Value>,
}

/// Application-specific performance metrics
/// I'm tracking application performance beyond system metrics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ApplicationMetrics {
    pub requests_per_second: f64,
    pub average_response_time_ms: f64,
    pub error_rate_percent: f64,
    pub active_connections: u32,
    pub database_query_time_ms: f64,
    pub cache_hit_rate_percent: f64,
    pub memory_usage_mb: f64,
    pub garbage_collection_time_ms: Option<f64>,
    pub thread_pool_utilization: f64,
    pub async_tasks_queued: u32,
}

/// Resource utilization breakdown with detailed analysis
/// I'm providing granular resource usage tracking
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResourceUsage {
    pub cpu: CpuUsage,
    pub memory: MemoryUsage,
    pub disk: DiskUsage,
    pub network: NetworkUsage,
    pub files: FileSystemUsage,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CpuUsage {
    pub overall_percent: f64,
    pub per_core_percent: Vec<f64>,
    pub user_percent: f64,
    pub system_percent: f64,
    pub idle_percent: f64,
    pub iowait_percent: f64,
    pub steal_percent: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryUsage {
    pub total_mb: u64,
    pub used_mb: u64,
    pub available_mb: u64,
    pub usage_percent: f64,
    pub cached_mb: u64,
    pub buffers_mb: u64,
    pub swap_usage_mb: u64,
    pub page_faults: Option<u64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DiskUsage {
    pub total_gb: f64,
    pub used_gb: f64,
    pub available_gb: f64,
    pub usage_percent: f64,
    pub read_iops: Option<u64>,
    pub write_iops: Option<u64>,
    pub read_throughput_mbps: Option<f64>,
    pub write_throughput_mbps: Option<f64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NetworkUsage {
    pub total_bytes_sent: u64,
    pub total_bytes_received: u64,
    pub throughput_mbps: f64,
    pub packets_per_second: u64,
    pub error_rate_percent: f64,
    pub connections_active: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileSystemUsage {
    pub open_files: u32,
    pub max_files: u32,
    pub file_descriptors_used: u32,
    pub inode_usage_percent: f64,
}

/// Performance score calculation with detailed breakdown
/// I'm implementing comprehensive performance assessment
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceScore {
    pub overall_score: f64,
    pub grade: PerformanceGrade,
    pub component_scores: HashMap<String, f64>,
    pub bottlenecks: Vec<String>,
    pub recommendations: Vec<String>,
    pub trend: PerformanceTrend,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum PerformanceGrade {
    A, // Excellent (90-100)
    B, // Good (80-89)
    C, // Fair (70-79)
    D, // Poor (60-69)
    F, // Critical (<60)
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum PerformanceTrend {
    Improving,
    Stable,
    Degrading,
}

/// Performance alert with severity and context
/// I'm implementing intelligent performance alerting
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceAlert {
    pub id: uuid::Uuid,
    pub alert_type: AlertType,
    pub severity: AlertSeverity,
    pub title: String,
    pub message: String,
    pub metric_name: String,
    pub current_value: f64,
    pub threshold_value: f64,
    pub timestamp: DateTime<Utc>,
    pub resolved: bool,
    pub resolved_at: Option<DateTime<Utc>>,
    pub context: serde_json::Value,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AlertType {
    Threshold,
    Anomaly,
    Trend,
    Availability,
    Error,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, PartialOrd)]
pub enum AlertSeverity {
    Info,
    Warning,
    Error,
    Critical,
}

impl PerformanceAlert {
    pub fn new(
        alert_type: AlertType,
        severity: AlertSeverity,
        title: impl Into<String>,
        message: impl Into<String>,
        metric_name: impl Into<String>,
        current_value: f64,
        threshold_value: f64,
    ) -> Self {
        Self {
            id: uuid::Uuid::new_v4(),
            alert_type,
            severity,
            title: title.into(),
            message: message.into(),
            metric_name: metric_name.into(),
            current_value,
            threshold_value,
            timestamp: Utc::now(),
            resolved: false,
            resolved_at: None,
            context: serde_json::json!({}),
        }
    }

    pub fn resolve(&mut self) {
        self.resolved = true;
        self.resolved_at = Some(Utc::now());
    }
}

/// Comprehensive benchmark result with detailed analysis
/// I'm providing thorough benchmark analysis for performance evaluation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkResult {
    pub id: uuid::Uuid,
    pub name: String,
    pub description: String,
    pub timestamp: DateTime<Utc>,
    pub duration_ms: u128,
    pub iterations: u32,
    pub success: bool,
    pub error_message: Option<String>,
    pub results: HashMap<String, BenchmarkMetric>,
    pub system_context: SystemInfo,
    pub comparison: Option<BenchmarkComparison>,
    pub analysis: BenchmarkAnalysis,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkMetric {
    pub name: String,
    pub value: f64,
    pub unit: String,
    pub better_direction: BenchmarkDirection,
    pub variance: Option<f64>,
    pub percentiles: Option<HashMap<String, f64>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum BenchmarkDirection {
    Higher, // Higher values are better
    Lower,  // Lower values are better
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkComparison {
    pub baseline_name: String,
    pub baseline_timestamp: DateTime<Utc>,
    pub performance_delta: f64,
    pub regression_detected: bool,
    pub significant_changes: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkAnalysis {
    pub performance_grade: PerformanceGrade,
    pub bottlenecks: Vec<String>,
    pub strengths: Vec<String>,
    pub recommendations: Vec<String>,
    pub optimization_opportunities: Vec<String>,
}

/// Time-series data structure for performance trends
/// I'm implementing time-series analysis for performance monitoring
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeSeriesData {
    pub metric_name: String,
    pub data_points: Vec<TimeSeriesPoint>,
    pub aggregation: TimeSeriesAggregation,
    pub time_range: TimeRange,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeSeriesPoint {
    pub timestamp: DateTime<Utc>,
    pub value: f64,
    pub tags: HashMap<String, String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeSeriesAggregation {
    pub function: AggregationFunction,
    pub interval_seconds: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AggregationFunction {
    Average,
    Sum,
    Min,
    Max,
    Count,
    Percentile(f64),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeRange {
    pub start: DateTime<Utc>,
    pub end: DateTime<Utc>,
}

/// Helper functions for performance calculations and analysis

impl SystemInfo {
    /// Calculate overall system health score
    /// I'm implementing comprehensive system health assessment
    pub fn calculate_health_score(&self) -> f64 {
        let mut score: f64 = 100.0;

        // CPU usage impact
        if self.cpu_usage_percent > 90.0 {
            score -= 30.0;
        } else if self.cpu_usage_percent > 80.0 {
            score -= 20.0;
        } else if self.cpu_usage_percent > 70.0 {
            score -= 10.0;
        }

        // Memory usage impact
        if self.memory_usage_percent > 95.0 {
            score -= 25.0;
        } else if self.memory_usage_percent > 85.0 {
            score -= 15.0;
        } else if self.memory_usage_percent > 75.0 {
            score -= 8.0;
        }

        // Disk usage impact
        if self.disk_usage_percent > 95.0 {
            score -= 20.0;
        } else if self.disk_usage_percent > 90.0 {
            score -= 10.0;
        } else if self.disk_usage_percent > 80.0 {
            score -= 5.0;
        }

        // Load average impact
        let load_ratio = self.load_average_1m / self.cpu_cores as f64;
        if load_ratio > 2.0 {
            score -= 20.0;
        } else if load_ratio > 1.5 {
            score -= 10.0;
        } else if load_ratio > 1.0 {
            score -= 5.0;
        }

        score.max(0.0)
    }

    pub fn get_performance_grade(&self) -> PerformanceGrade {
        let score = self.calculate_health_score();
        match score {
            x if x >= 90.0 => PerformanceGrade::A,
            x if x >= 80.0 => PerformanceGrade::B,
            x if x >= 70.0 => PerformanceGrade::C,
            x if x >= 60.0 => PerformanceGrade::D,
            _ => PerformanceGrade::F,
        }
    }
}

impl PerformanceScore {
    pub fn calculate(system_info: &SystemInfo, app_metrics: &ApplicationMetrics) -> Self {
        let mut component_scores = HashMap::new();
        let mut bottlenecks = Vec::new();
        let mut recommendations = Vec::new();

        // Calculate component scores
        let cpu_score = calculate_cpu_score(system_info.cpu_usage_percent);
        let memory_score = calculate_memory_score(system_info.memory_usage_percent);
        let response_time_score = calculate_response_time_score(app_metrics.average_response_time_ms);
        let error_rate_score = calculate_error_rate_score(app_metrics.error_rate_percent);

        component_scores.insert("cpu".to_string(), cpu_score);
        component_scores.insert("memory".to_string(), memory_score);
        component_scores.insert("response_time".to_string(), response_time_score);
        component_scores.insert("error_rate".to_string(), error_rate_score);

        // Identify bottlenecks
        if cpu_score < 70.0 {
            bottlenecks.push("High CPU utilization".to_string());
            recommendations.push("Consider optimizing CPU-intensive operations".to_string());
        }
        if memory_score < 70.0 {
            bottlenecks.push("High memory usage".to_string());
            recommendations.push("Review memory usage and implement cleanup".to_string());
        }
        if response_time_score < 70.0 {
            bottlenecks.push("Slow response times".to_string());
            recommendations.push("Optimize database queries and caching".to_string());
        }
        if error_rate_score < 70.0 {
            bottlenecks.push("High error rate".to_string());
            recommendations.push("Investigate and fix error sources".to_string());
        }

        let overall_score = component_scores.values().sum::<f64>() / component_scores.len() as f64;
        let grade = match overall_score {
            x if x >= 90.0 => PerformanceGrade::A,
            x if x >= 80.0 => PerformanceGrade::B,
            x if x >= 70.0 => PerformanceGrade::C,
            x if x >= 60.0 => PerformanceGrade::D,
            _ => PerformanceGrade::F,
        };

        Self {
            overall_score,
            grade,
            component_scores,
            bottlenecks,
            recommendations,
            trend: PerformanceTrend::Stable, // Would be calculated from historical data
        }
    }
}

// Helper functions for score calculations
fn calculate_cpu_score(cpu_percent: f64) -> f64 {
    (100.0 - cpu_percent).max(0.0)
}

fn calculate_memory_score(memory_percent: f64) -> f64 {
    (100.0 - memory_percent).max(0.0)
}

fn calculate_response_time_score(response_time_ms: f64) -> f64 {
    if response_time_ms <= 100.0 {
        100.0
    } else if response_time_ms <= 500.0 {
        100.0 - ((response_time_ms - 100.0) / 4.0)
    } else {
        0.0
    }
}

fn calculate_error_rate_score(error_rate_percent: f64) -> f64 {
    (100.0 - (error_rate_percent * 10.0)).max(0.0)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_performance_grade_calculation() {
        let system_info = SystemInfo {
            timestamp: Utc::now(),
            cpu_model: "Test CPU".to_string(),
            cpu_cores: 8,
            cpu_threads: 16,
            cpu_usage_percent: 50.0,
            cpu_frequency_mhz: Some(3000),
            memory_total_mb: 16384,
            memory_available_mb: 8192,
            memory_usage_percent: 50.0,
            swap_total_mb: 4096,
            swap_used_mb: 0,
            disk_total_gb: 1000.0,
            disk_available_gb: 500.0,
            disk_usage_percent: 50.0,
            network_interfaces: vec![],
            load_average_1m: 4.0,
            load_average_5m: 3.5,
            load_average_15m: 3.0,
            uptime_seconds: 86400,
            active_processes: 150,
            system_temperature: Some(65.0),
            power_consumption: None,
        };

        let grade = system_info.get_performance_grade();
        assert!(matches!(grade, PerformanceGrade::A | PerformanceGrade::B));
    }

    #[test]
    fn test_performance_alert_creation() {
        let mut alert = PerformanceAlert::new(
            AlertType::Threshold,
            AlertSeverity::Warning,
            "High CPU Usage",
            "CPU usage is above threshold",
            "cpu_usage_percent",
            85.0,
            80.0,
        );

        assert!(!alert.resolved);
        alert.resolve();
        assert!(alert.resolved);
        assert!(alert.resolved_at.is_some());
    }

    #[test]
    fn test_metric_value_types() {
        let counter = MetricValue::Counter(100);
        let gauge = MetricValue::Gauge(75.5);

        match counter {
            MetricValue::Counter(val) => assert_eq!(val, 100),
            _ => panic!("Expected Counter"),
        }

        match gauge {
            MetricValue::Gauge(val) => assert_eq!(val, 75.5),
            _ => panic!("Expected Gauge"),
        }
    }
}
</file>

<file path="src/routes/fractals.rs">
/*
 * Fractal generation route handlers providing high-performance computational endpoints for real-time visualization.
 * I'm implementing Mandelbrot and Julia set generation with comprehensive performance tracking and parameter validation.
 */

use axum::{
    extract::{Query, State},
    http::StatusCode,
    Json,
    response::Response,
};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use tracing::{info, warn, error};

use crate::{
    services::fractal_service::{FractalService, FractalRequest, FractalResponse, FractalType},
    utils::error::{AppError, Result},
    AppState,
};

#[derive(Debug, Deserialize)]
pub struct MandelbrotQuery {
    pub width: Option<u32>,
    pub height: Option<u32>,
    pub center_x: Option<f64>,
    pub center_y: Option<f64>,
    pub zoom: Option<f64>,
    pub max_iterations: Option<u32>,
}

#[derive(Debug, Deserialize)]
pub struct JuliaQuery {
    pub width: Option<u32>,
    pub height: Option<u32>,
    pub center_x: Option<f64>,
    pub center_y: Option<f64>,
    pub zoom: Option<f64>,
    pub max_iterations: Option<u32>,
    pub c_real: Option<f64>,
    pub c_imag: Option<f64>,
}

#[derive(Debug, Serialize)]
pub struct FractalApiResponse {
    pub data: Vec<u8>,
    pub width: u32,
    pub height: u32,
    pub computation_time_ms: u128,
    pub zoom_level: f64,
    pub parameters: serde_json::Value,
    pub performance_metrics: PerformanceMetrics,
}

#[derive(Debug, Serialize)]
pub struct PerformanceMetrics {
    pub pixels_per_second: f64,
    pub parallel_efficiency: f64,
    pub memory_usage_mb: f64,
    pub cpu_utilization: f64,
}

/// Generate Mandelbrot fractal with real-time performance tracking
/// I'm implementing comprehensive parameter validation and performance optimization
pub async fn generate_mandelbrot(
    State(app_state): State<AppState>,
                                 Query(params): Query<MandelbrotQuery>,
) -> Result<Json<FractalApiResponse>> {
    info!("Generating Mandelbrot fractal with params: {:?}", params);

    // I'm setting sensible defaults and validating parameters for safety
    let width = params.width.unwrap_or(800).clamp(64, 4096);
    let height = params.height.unwrap_or(600).clamp(64, 4096);
    let center_x = params.center_x.unwrap_or(-0.5).clamp(-2.0, 2.0);
    let center_y = params.center_y.unwrap_or(0.0).clamp(-2.0, 2.0);
    let zoom = params.zoom.unwrap_or(1.0).clamp(0.1, 1e15);
    let max_iterations = params.max_iterations.unwrap_or(100).clamp(50, 10000);

    let request = FractalRequest {
        width,
        height,
        center_x,
        center_y,
        zoom,
        max_iterations,
        fractal_type: FractalType::Mandelbrot,
    };

    // Record system state before computation
    let start_memory = get_memory_usage();
    let start_cpu = get_cpu_usage().await;

    // Generate the fractal using our high-performance service
    let response = app_state.fractal_service.generate_mandelbrot(request.clone());

    // Calculate performance metrics
    let end_memory = get_memory_usage();
    let end_cpu = get_cpu_usage().await;

    let pixels_per_second = (width * height) as f64 / (response.computation_time_ms as f64 / 1000.0);
    let memory_delta = end_memory - start_memory;
    let cpu_delta = end_cpu - start_cpu;

    // Store computation in database for analytics
    if let Err(e) = store_fractal_computation(&app_state, &request, &response, memory_delta, cpu_delta).await {
        warn!("Failed to store fractal computation: {}", e);
    }

    // Update real-time performance metrics
    app_state.metrics.record_fractal_generation(
        "mandelbrot",
        response.computation_time_ms as f64,
        pixels_per_second,
    ).await;

    let api_response = FractalApiResponse {
        data: response.data,
        width: response.width,
        height: response.height,
        computation_time_ms: response.computation_time_ms,
        zoom_level: response.zoom_level,
        parameters: serde_json::json!({
            "center_x": center_x,
            "center_y": center_y,
            "max_iterations": max_iterations,
            "fractal_type": "mandelbrot"
        }),
        performance_metrics: PerformanceMetrics {
            pixels_per_second,
            parallel_efficiency: calculate_parallel_efficiency(response.computation_time_ms, width * height),
            memory_usage_mb: memory_delta,
            cpu_utilization: cpu_delta,
        },
    };

    info!("Mandelbrot generation completed in {}ms", response.computation_time_ms);
    Ok(Json(api_response))
}

/// Generate Julia set fractal with customizable complex parameter
/// I'm providing flexible parameter control while maintaining performance
pub async fn generate_julia(
    State(app_state): State<AppState>,
                            Query(params): Query<JuliaQuery>,
) -> Result<Json<FractalApiResponse>> {
    info!("Generating Julia fractal with params: {:?}", params);

    let width = params.width.unwrap_or(800).clamp(64, 4096);
    let height = params.height.unwrap_or(600).clamp(64, 4096);
    let center_x = params.center_x.unwrap_or(0.0).clamp(-2.0, 2.0);
    let center_y = params.center_y.unwrap_or(0.0).clamp(-2.0, 2.0);
    let zoom = params.zoom.unwrap_or(1.0).clamp(0.1, 1e15);
    let max_iterations = params.max_iterations.unwrap_or(100).clamp(50, 10000);
    let c_real = params.c_real.unwrap_or(-0.7).clamp(-2.0, 2.0);
    let c_imag = params.c_imag.unwrap_or(0.27015).clamp(-2.0, 2.0);

    let request = FractalRequest {
        width,
        height,
        center_x,
        center_y,
        zoom,
        max_iterations,
        fractal_type: FractalType::Julia { c_real, c_imag },
    };

    let start_memory = get_memory_usage();
    let start_cpu = get_cpu_usage().await;

    let c = num_complex::Complex::new(c_real, c_imag);
    let response = app_state.fractal_service.generate_julia(request.clone(), c);

    let end_memory = get_memory_usage();
    let end_cpu = get_cpu_usage().await;

    let pixels_per_second = (width * height) as f64 / (response.computation_time_ms as f64 / 1000.0);
    let memory_delta = end_memory - start_memory;
    let cpu_delta = end_cpu - start_cpu;

    if let Err(e) = store_fractal_computation(&app_state, &request, &response, memory_delta, cpu_delta).await {
        warn!("Failed to store fractal computation: {}", e);
    }

    app_state.metrics.record_fractal_generation(
        "julia",
        response.computation_time_ms as f64,
        pixels_per_second,
    ).await;

    let api_response = FractalApiResponse {
        data: response.data,
        width: response.width,
        height: response.height,
        computation_time_ms: response.computation_time_ms,
        zoom_level: response.zoom_level,
        parameters: serde_json::json!({
            "center_x": center_x,
            "center_y": center_y,
            "max_iterations": max_iterations,
            "c_real": c_real,
            "c_imag": c_imag,
            "fractal_type": "julia"
        }),
        performance_metrics: PerformanceMetrics {
            pixels_per_second,
            parallel_efficiency: calculate_parallel_efficiency(response.computation_time_ms, width * height),
            memory_usage_mb: memory_delta,
            cpu_utilization: cpu_delta,
        },
    };

    info!("Julia generation completed in {}ms", response.computation_time_ms);
    Ok(Json(api_response))
}

/// Comprehensive benchmark suite comparing different fractal parameters and resolutions
/// I'm providing detailed performance analysis across multiple computational scenarios
pub async fn benchmark_generation(
    State(app_state): State<AppState>,
) -> Result<Json<serde_json::Value>> {
    info!("Starting comprehensive fractal benchmark suite");

    let mut benchmark_results = Vec::new();

    // I'm testing various resolution and complexity combinations
    let test_scenarios = vec![
        (256, 256, 100, "low"),
        (512, 512, 200, "medium"),
        (1024, 1024, 400, "high"),
        (2048, 2048, 800, "ultra"),
    ];

    for (width, height, max_iter, complexity) in test_scenarios {
        info!("Benchmarking {}x{} at {} iterations ({})", width, height, max_iter, complexity);

        // Mandelbrot benchmark
        let mandelbrot_request = FractalRequest {
            width,
            height,
            center_x: -0.5,
            center_y: 0.0,
            zoom: 1.0,
            max_iterations: max_iter,
            fractal_type: FractalType::Mandelbrot,
        };

        let mandelbrot_response = app_state.fractal_service.generate_mandelbrot(mandelbrot_request);
        let mandelbrot_pixels_per_ms = (width * height) as f64 / mandelbrot_response.computation_time_ms as f64;

        // Julia benchmark
        let julia_request = FractalRequest {
            width,
            height,
            center_x: 0.0,
            center_y: 0.0,
            zoom: 1.0,
            max_iterations: max_iter,
            fractal_type: FractalType::Julia { c_real: -0.7, c_imag: 0.27015 },
        };

        let c = num_complex::Complex::new(-0.7, 0.27015);
        let julia_response = app_state.fractal_service.generate_julia(julia_request, c);
        let julia_pixels_per_ms = (width * height) as f64 / julia_response.computation_time_ms as f64;

        benchmark_results.push(serde_json::json!({
            "complexity": complexity,
            "resolution": format!("{}x{}", width, height),
                                                 "max_iterations": max_iter,
                                                 "total_pixels": width * height,
                                                 "mandelbrot": {
                                                     "computation_time_ms": mandelbrot_response.computation_time_ms,
                                                     "pixels_per_ms": mandelbrot_pixels_per_ms,
                                                     "performance_rating": calculate_performance_rating(mandelbrot_pixels_per_ms)
                                                 },
                                                 "julia": {
                                                     "computation_time_ms": julia_response.computation_time_ms,
                                                     "pixels_per_ms": julia_pixels_per_ms,
                                                     "performance_rating": calculate_performance_rating(julia_pixels_per_ms)
                                                 }
        }));
    }

    // System information for context
    let system_info = app_state.performance_service.get_system_info().await?;

    let benchmark_summary = serde_json::json!({
        "benchmark_results": benchmark_results,
        "system_context": {
            "cpu_model": system_info["hardware"]["cpu"]["model"].as_str().unwrap_or_default(),
            "cpu_cores": system_info["hardware"]["cpu"]["cores"].as_u64().unwrap_or_default(),
            "memory_total_gb": system_info["hardware"]["memory"]["total_gb"].as_f64().unwrap_or_default(),
            "rust_version": env!("CARGO_PKG_VERSION"),
                                              "parallel_processing": true,
                                              "simd_optimized": cfg!(target_feature = "avx2")
        },
        "performance_analysis": {
            "language": "Rust",
            "framework": "Rayon parallel processing",
            "optimization_level": "Maximum (-O3, LTO)",
                                              "memory_allocator": if cfg!(feature = "jemalloc") { "jemalloc" } else { "system" }
        },
        "benchmark_timestamp": chrono::Utc::now(),
                                              "total_benchmarks": benchmark_results.len()
    });

    info!("Benchmark suite completed with {} scenarios", benchmark_results.len());
    Ok(Json(benchmark_summary))
}

// Helper functions for performance tracking and analysis

async fn store_fractal_computation(
    app_state: &AppState,
    request: &FractalRequest,
    response: &FractalResponse,
    memory_delta: f64,
    cpu_delta: f64,
) -> Result<()> {
    let fractal_type_str = match request.fractal_type {
        FractalType::Mandelbrot => "mandelbrot",
        FractalType::Julia { .. } => "julia",
    };

    sqlx::query!(
        r#"
        INSERT INTO fractal_computations (
            fractal_type, width, height, center_x, center_y, zoom_level,
            max_iterations, computation_time_ms, pixels_computed,
            cpu_usage_percent, memory_usage_mb, parameters
    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
    "#,
    fractal_type_str,
    request.width as i32,
    request.height as i32,
    request.center_x,
    request.center_y,
    request.zoom,
    request.max_iterations as i32,
    response.computation_time_ms as i32,
    (request.width * request.height) as i32,
                 cpu_delta,
                 memory_delta,
                 serde_json::json!({
                     "fractal_type": fractal_type_str,
                     "parameters": match request.fractal_type {
                         FractalType::Julia { c_real, c_imag } => serde_json::json!({"c_real": c_real, "c_imag": c_imag}),
                                   _ => serde_json::json!({})
                     }
                 })
    )
    .execute(&app_state.db_pool)
    .await
    .map_err(|e| AppError::DatabaseError(e.to_string()))?;

    Ok(())
}

fn get_memory_usage() -> f64 {
    // I'm using a simple memory usage approximation
    // In production, you'd want more sophisticated memory tracking
    use std::alloc::{GlobalAlloc, System};
    // This is a placeholder implementation
    0.0
}

async fn get_cpu_usage() -> f64 {
    // I'm implementing basic CPU usage tracking
    // In production, you'd want more sophisticated CPU monitoring
    use sysinfo::{System, SystemExt, CpuExt};
    let mut sys = System::new_all();
    sys.refresh_cpu();
    sys.global_cpu_info().cpu_usage() as f64
}

fn calculate_parallel_efficiency(computation_time_ms: u128, total_pixels: u32) -> f64 {
    // I'm calculating how efficiently we're using parallel processing
    let theoretical_single_thread_time = total_pixels as f64 * 0.001; // Rough estimate
    let actual_time_seconds = computation_time_ms as f64 / 1000.0;
    let available_cores = num_cpus::get() as f64;

    (theoretical_single_thread_time / actual_time_seconds / available_cores).min(1.0)
}

fn calculate_performance_rating(pixels_per_ms: f64) -> String {
    // I'm providing human-readable performance ratings
    match pixels_per_ms {
        x if x > 10000.0 => "Exceptional".to_string(),
        x if x > 5000.0 => "Excellent".to_string(),
        x if x > 2000.0 => "Very Good".to_string(),
        x if x > 1000.0 => "Good".to_string(),
        x if x > 500.0 => "Fair".to_string(),
        _ => "Needs Optimization".to_string(),
    }
}
</file>

<file path="src/routes/github.rs">
/*
 * GitHub API route handlers providing comprehensive repository data with intelligent caching and performance optimization.
 * I'm implementing RESTful endpoints that showcase GitHub integration while maintaining high performance through caching and database optimization.
 */

use axum::{
    extract::{Path, Query, State},
    http::StatusCode,
    Json,
    response::Json as JsonResponse,
};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use tracing::{info, warn, error, debug};

use crate::{
    models::github::{
        Repository, RepositoryDetailed, RepositoryCollection, RepositoryFilter,
        RepositorySort, CollectionStats, RateLimitInfo, calculate_collection_stats
    },
    utils::error::{AppError, Result},
    AppState,
};

#[derive(Debug, Deserialize)]
pub struct RepositoryQuery {
    pub page: Option<i32>,
    pub per_page: Option<i32>,
    pub sort: Option<String>,
    pub direction: Option<String>,
    pub language: Option<String>,
    pub min_stars: Option<i32>,
    pub max_stars: Option<i32>,
    pub is_fork: Option<bool>,
    pub is_archived: Option<bool>,
    pub search: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct RepositoryResponse {
    pub repositories: Vec<Repository>,
    pub pagination: PaginationInfo,
    pub statistics: CollectionStats,
    pub rate_limit: RateLimitInfo,
    pub cache_info: CacheInfo,
}

#[derive(Debug, Serialize)]
pub struct PaginationInfo {
    pub current_page: i32,
    pub per_page: i32,
    pub total_pages: i32,
    pub total_count: i32,
    pub has_next_page: bool,
    pub has_previous_page: bool,
}

#[derive(Debug, Serialize)]
pub struct CacheInfo {
    pub cached: bool,
    pub cache_age_seconds: i64,
    pub expires_in_seconds: i64,
}

/// Get paginated list of repositories with comprehensive filtering and sorting
/// I'm providing a full-featured repository listing endpoint with performance optimization
pub async fn get_repositories(
    State(app_state): State<AppState>,
    Query(params): Query<RepositoryQuery>,
) -> Result<JsonResponse<RepositoryResponse>> {
    info!("Fetching repositories with params: {:?}", params);

    // I'm setting sensible defaults for pagination and validation
    let page = params.page.unwrap_or(1).max(1);
    let per_page = params.per_page.unwrap_or(20).clamp(1, 100);
    let offset = (page - 1) * per_page;

    // Get GitHub username from config
    let username = &app_state.config.github_username;

    // Try to get fresh repositories from GitHub API
    let repositories = match app_state.github_service.get_user_repositories(username).await {
        Ok(repos) => {
            // Store in database for caching
            if let Err(e) = app_state.github_service.store_repositories_in_db(&app_state.db_pool, &repos).await {
                warn!("Failed to store repositories in database: {}", e);
            }
            repos
        }
        Err(e) => {
            warn!("GitHub API failed, falling back to database cache: {}", e);
            // Fallback to database cache
            get_repositories_from_db(&app_state, username).await?
        }
    };

    // Apply filtering
    let filter = create_filter_from_params(&params);
    let filtered_repos = filter.apply(repositories);

    // Apply sorting
    let sorted_repos = apply_sorting(filtered_repos, &params);

    // Apply pagination
    let total_count = sorted_repos.len() as i32;
    let total_pages = (total_count + per_page - 1) / per_page;
    let paginated_repos = sorted_repos
        .into_iter()
        .skip(offset as usize)
        .take(per_page as usize)
        .collect::<Vec<_>>();

    // Calculate statistics for the filtered set
    let statistics = calculate_collection_stats(&paginated_repos);

    // Get rate limit information
    let rate_limit = match app_state.github_service.get_rate_limit_status().await {
        Ok(limit) => RateLimitInfo {
            limit: limit.limit as i32,
            remaining: limit.remaining as i32,
            reset_at: chrono::DateTime::from_timestamp(limit.reset as i64, 0)
                .unwrap_or_else(|| chrono::Utc::now())
                .into(),
            used: limit.used as i32,
            percentage_used: (limit.used as f64 / limit.limit as f64) * 100.0,
        },
        Err(_) => RateLimitInfo {
            limit: 5000,
            remaining: 0,
            reset_at: chrono::Utc::now(),
            used: 0,
            percentage_used: 0.0,
        },
    };

    let response = RepositoryResponse {
        repositories: paginated_repos,
        pagination: PaginationInfo {
            current_page: page,
            per_page,
            total_pages,
            total_count,
            has_next_page: page < total_pages,
            has_previous_page: page > 1,
        },
        statistics,
        rate_limit,
        cache_info: CacheInfo {
            cached: false, // This could be enhanced to track actual cache usage
            cache_age_seconds: 0,
            expires_in_seconds: 3600,
        },
    };

    info!(
        "Returning {} repositories (page {} of {})",
        response.repositories.len(),
        page,
        total_pages
    );

    Ok(Json(response))
}

/// Get detailed information for a specific repository including README and analytics
/// I'm providing comprehensive repository analysis with performance metrics and content
pub async fn get_repository_details(
    State(app_state): State<AppState>,
    Path((owner, name)): Path<(String, String)>,
) -> Result<JsonResponse<RepositoryDetailed>> {
    info!("Fetching detailed repository information for {}/{}", owner, name);

    // Get detailed repository information
    let repository_details = app_state.github_service
        .get_repository_details(&owner, &name)
        .await?;

    // Update access metrics in database
    if let Err(e) = record_repository_access(&app_state, &owner, &name).await {
        warn!("Failed to record repository access: {}", e);
    }

    info!("Successfully retrieved details for {}/{}", owner, name);
    Ok(Json(repository_details))
}

/// Get repository statistics and analytics for performance showcase
/// I'm providing detailed analytics that highlight the repository's characteristics
pub async fn get_repository_stats(
    State(app_state): State<AppState>,
    Path((owner, name)): Path<(String, String)>,
) -> Result<JsonResponse<serde_json::Value>> {
    info!("Fetching repository statistics for {}/{}", owner, name);

    // Get repository from database or API
    let repo = match get_single_repository(&app_state, &owner, &name).await {
        Ok(repo) => repo,
        Err(_) => {
            // Try fetching from GitHub API
            let detailed = app_state.github_service
                .get_repository_details(&owner, &name)
                .await?;
            detailed.basic
        }
    };

    // Calculate comprehensive statistics
    let stats = serde_json::json!({
        "basic_stats": {
            "stars": repo.stargazers_count,
            "forks": repo.forks_count,
            "watchers": repo.watchers_count,
            "open_issues": repo.open_issues_count,
            "size_kb": repo.size_kb,
            "language": repo.language,
            "topics": repo.topics,
            "license": repo.license_name
        },
        "activity_metrics": {
            "activity_score": repo.calculate_activity_score(),
            "age_in_days": repo.age_in_days(),
            "days_since_update": repo.days_since_update(),
            "is_active": repo.days_since_update() < 90,
            "last_updated": repo.updated_at,
            "last_pushed": repo.pushed_at
        },
        "health_indicators": {
            "has_description": repo.description.is_some(),
            "has_topics": !repo.topics.is_empty(),
            "has_license": repo.license_name.is_some(),
            "is_archived": repo.is_archived,
            "is_fork": repo.is_fork,
            "issue_activity": if repo.stargazers_count > 0 {
                repo.open_issues_count as f64 / repo.stargazers_count as f64
            } else { 0.0 }
        },
        "popularity_metrics": {
            "stars_to_forks_ratio": if repo.forks_count > 0 {
                repo.stargazers_count as f64 / repo.forks_count as f64
            } else { repo.stargazers_count as f64 },
            "watchers_to_stars_ratio": if repo.stargazers_count > 0 {
                repo.watchers_count as f64 / repo.stargazers_count as f64
            } else { 0.0 },
            "popularity_rank": calculate_popularity_rank(&repo)
        },
        "technical_info": {
            "primary_language": repo.language,
            "size_category": categorize_repository_size(repo.size_kb),
            "complexity_estimate": estimate_complexity(&repo)
        }
    });

    info!("Generated comprehensive statistics for {}/{}", owner, name);
    Ok(Json(stats))
}

/// Get language distribution across all repositories for technology showcase
/// I'm providing insights into technology usage patterns across the portfolio
pub async fn get_language_distribution(
    State(app_state): State<AppState>,
) -> Result<JsonResponse<serde_json::Value>> {
    info!("Calculating language distribution across repositories");

    let username = &app_state.config.github_username;

    // Get all repositories
    let repositories = match app_state.github_service.get_user_repositories(username).await {
        Ok(repos) => repos,
        Err(_) => get_repositories_from_db(&app_state, username).await?,
    };

    // Calculate language statistics
    let mut language_stats: HashMap<String, LanguageStat> = HashMap::new();
    let mut total_size: i64 = 0;

    for repo in &repositories {
        if repo.is_archived || repo.is_fork {
            continue; // Skip archived and forked repositories for cleaner stats
        }

        total_size += repo.size_kb as i64;

        if let Some(ref language) = repo.language {
            let stat = language_stats.entry(language.clone()).or_insert(LanguageStat {
                name: language.clone(),
                repository_count: 0,
                total_size_kb: 0,
                total_stars: 0,
                average_stars: 0.0,
                percentage: 0.0,
            });

            stat.repository_count += 1;
            stat.total_size_kb += repo.size_kb as i64;
            stat.total_stars += repo.stargazers_count;
        }
    }

    // Calculate percentages and averages
    for stat in language_stats.values_mut() {
        stat.percentage = if total_size > 0 {
            (stat.total_size_kb as f64 / total_size as f64) * 100.0
        } else { 0.0 };
        stat.average_stars = if stat.repository_count > 0 {
            stat.total_stars as f64 / stat.repository_count as f64
        } else { 0.0 };
    }

    // Sort by usage (repository count)
    let mut sorted_languages: Vec<_> = language_stats.into_values().collect();
    sorted_languages.sort_by(|a, b| b.repository_count.cmp(&a.repository_count));

    let response = serde_json::json!({
        "languages": sorted_languages,
        "summary": {
            "total_languages": sorted_languages.len(),
            "total_repositories_analyzed": repositories.len(),
            "total_size_kb": total_size,
            "most_used_language": sorted_languages.first().map(|l| &l.name),
            "language_diversity_score": calculate_diversity_score(&sorted_languages)
        },
        "analysis_timestamp": chrono::Utc::now()
    });

    info!("Language distribution calculated for {} languages", sorted_languages.len());
    Ok(Json(response))
}

#[derive(Debug, Serialize)]
struct LanguageStat {
    name: String,
    repository_count: i32,
    total_size_kb: i64,
    total_stars: i32,
    average_stars: f64,
    percentage: f64,
}

// Helper functions for repository processing and analysis

async fn get_repositories_from_db(app_state: &AppState, username: &str) -> Result<Vec<Repository>> {
    let repositories = sqlx::query_as!(
        Repository,
        r###"
        SELECT
            id, github_id, owner_login, name, full_name, description, html_url, clone_url, ssh_url,
            language, size_kb, stargazers_count, watchers_count, forks_count, open_issues_count,
            created_at, updated_at, pushed_at, is_private, is_fork, is_archived, topics,
            license_name, readme_content, cache_updated_at, cache_expires_at
        FROM repositories
        WHERE owner_login = $1 AND cache_expires_at > NOW()
        ORDER BY updated_at DESC
        "###,
        username
    )
    .fetch_all(&app_state.db_pool)
    .await
    .map_err(|e| AppError::DatabaseError(format!("Failed to fetch repositories from database: {}", e)))?;

    Ok(repositories)
}

async fn get_single_repository(app_state: &AppState, owner: &str, name: &str) -> Result<Repository> {
    let repo = sqlx::query_as!(
        Repository,
        r###"
        SELECT
            id, github_id, owner_login, name, full_name, description, html_url, clone_url, ssh_url,
            language, size_kb, stargazers_count, watchers_count, forks_count, open_issues_count,
            created_at, updated_at, pushed_at, is_private, is_fork, is_archived, topics,
            license_name, readme_content, cache_updated_at, cache_expires_at
        FROM repositories
        WHERE owner_login = $1 AND name = $2
        LIMIT 1
        "###,
        owner,
        name
    )
    .fetch_one(&app_state.db_pool)
    .await
    .map_err(|e| AppError::DatabaseError(format!("Repository not found: {}", e)))?;

    Ok(repo)
}

async fn record_repository_access(app_state: &AppState, owner: &str, name: &str) -> Result<()> {
    sqlx::query!(
        r###"
        INSERT INTO performance_metrics (metric_type, metric_value, metric_unit, endpoint, tags)
        VALUES ('repository_access', 1, 'count', $1, $2)
        "###,
        format!("/api/github/repo/{}/{}", owner, name),
        serde_json::json!({"owner": owner, "name": name, "access_time": chrono::Utc::now()})
    )
    .execute(&app_state.db_pool)
    .await
    .map_err(|e| AppError::DatabaseError(format!("Failed to record access: {}", e)))?;

    Ok(())
}

fn create_filter_from_params(params: &RepositoryQuery) -> RepositoryFilter {
    RepositoryFilter {
        language: params.language.clone(),
        min_stars: params.min_stars,
        max_stars: params.max_stars,
        is_fork: params.is_fork,
        is_archived: params.is_archived,
        search_query: params.search.clone(),
        ..Default::default()
    }
}

fn apply_sorting(mut repositories: Vec<Repository>, params: &RepositoryQuery) -> Vec<Repository> {
    let sort_field = params.sort.as_deref().unwrap_or("updated");
    let direction = params.direction.as_deref().unwrap_or("desc");

    repositories.sort_by(|a, b| {
        let comparison = match sort_field {
            "name" => a.name.cmp(&b.name),
            "stars" => a.stargazers_count.cmp(&b.stargazers_count),
            "forks" => a.forks_count.cmp(&b.forks_count),
            "size" => a.size_kb.cmp(&b.size_kb),
            "created" => a.created_at.cmp(&b.created_at),
            "updated" | _ => a.updated_at.cmp(&b.updated_at),
        };

        if direction == "desc" {
            comparison.reverse()
        } else {
            comparison
        }
    });

    repositories
}

fn calculate_popularity_rank(repo: &Repository) -> String {
    match repo.stargazers_count {
        0..=5 => "Getting Started".to_string(),
        6..=25 => "Growing".to_string(),
        26..=100 => "Popular".to_string(),
        101..=500 => "Highly Popular".to_string(),
        501..=2000 => "Very Popular".to_string(),
        _ => "Exceptional".to_string(),
    }
}

fn categorize_repository_size(size_kb: i32) -> String {
    match size_kb {
        0..=100 => "Tiny".to_string(),
        101..=1000 => "Small".to_string(),
        1001..=10000 => "Medium".to_string(),
        10001..=100000 => "Large".to_string(),
        _ => "Huge".to_string(),
    }
}

fn estimate_complexity(repo: &Repository) -> String {
    // I'm using a simple heuristic based on size, issues, and language
    let mut complexity_score = 0;

    // Size factor
    complexity_score += match repo.size_kb {
        0..=1000 => 1,
        1001..=10000 => 2,
        10001..=100000 => 3,
        _ => 4,
    };

    // Issue activity factor
    if repo.open_issues_count > 10 {
        complexity_score += 1;
    }

    // Language complexity (subjective but useful heuristic)
    if let Some(ref lang) = repo.language {
        complexity_score += match lang.as_str() {
            "Assembly" | "C" | "C++" | "Rust" => 3,
            "Java" | "C#" | "Go" | "Kotlin" => 2,
            "Python" | "JavaScript" | "TypeScript" => 1,
            "HTML" | "CSS" | "Markdown" => 0,
            _ => 1,
        };
    }

    match complexity_score {
        0..=2 => "Simple".to_string(),
        3..=4 => "Moderate".to_string(),
        5..=6 => "Complex".to_string(),
        _ => "Very Complex".to_string(),
    }
}

fn calculate_diversity_score(languages: &[LanguageStat]) -> f64 {
    // I'm calculating a Shannon diversity index for language distribution
    let total_repos: i32 = languages.iter().map(|l| l.repository_count).sum();

    if total_repos == 0 {
        return 0.0;
    }

    let mut diversity = 0.0;

    for lang in languages {
        if lang.repository_count > 0 {
            let proportion = lang.repository_count as f64 / total_repos as f64;
            diversity -= proportion * proportion.ln();
        }
    }

    diversity
}
</file>

<file path="src/routes/health.rs">
/*
 * Health check and monitoring endpoints providing comprehensive service status and diagnostic information.
 * I'm implementing production-ready health checks that integrate with load balancers and monitoring systems for reliable deployment.
 */

use axum::{
    response::IntoResponse,
    extract::State,
    http::StatusCode,
    Json,
    response::Json as JsonResponse,
};
use serde::{Deserialize, Serialize};
use std::time::{Duration, Instant};
use tracing::{info, warn, error};
use sqlx::Row;

use crate::{
    utils::error::{AppError, Result},
    AppState,
};

/// Comprehensive health check response for monitoring systems
/// I'm providing detailed health information for production monitoring and alerting
#[derive(Debug, Serialize)]
pub struct HealthCheckResponse {
    pub status: ServiceStatus,
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub uptime_seconds: u64,
    pub version: VersionInfo,
    pub services: ServiceHealthStatus,
    pub system: SystemHealth,
    pub performance: PerformanceMetrics,
    pub checks: Vec<HealthCheck>,
}

#[derive(Debug, Clone, Serialize)]
pub enum ServiceStatus {
    Healthy,
    Degraded,
    Unhealthy,
}

#[derive(Debug, Serialize)]
pub struct VersionInfo {
    pub version: String,
    pub build_time: String,
    pub git_commit: String,
    pub rust_version: String,
}

#[derive(Debug, Serialize)]
pub struct ServiceHealthStatus {
    pub database: ComponentStatus,
    pub redis: ComponentStatus,
    pub github_api: ComponentStatus,
    pub fractal_engine: ComponentStatus,
}

#[derive(Debug, Serialize)]
pub struct ComponentStatus {
    pub status: ServiceStatus,
    pub response_time_ms: Option<u64>,
    pub last_check: chrono::DateTime<chrono::Utc>,
    pub error_message: Option<String>,
    pub metadata: Option<serde_json::Value>,
}

#[derive(Debug, Serialize)]
pub struct SystemHealth {
    pub cpu_usage_percent: f64,
    pub memory_usage_percent: f64,
    pub disk_usage_percent: f64,
    pub active_connections: u32,
    pub load_average: Vec<f64>,
}

#[derive(Debug, Serialize)]
pub struct PerformanceMetrics {
    pub requests_per_second: f64,
    pub average_response_time_ms: f64,
    pub error_rate_percent: f64,
    pub fractal_computations_last_hour: u32,
    pub github_api_calls_last_hour: u32,
}
#[derive(Debug, Clone, Serialize)]
pub struct HealthCheck {
    pub name: String,
    pub status: ServiceStatus,
    pub duration_ms: u64,
    pub message: String,
}

/// Simple health check endpoint for load balancers
/// I'm providing a lightweight endpoint for basic availability checks
pub async fn health_check(
    State(app_state): State<AppState>,
) -> Result<JsonResponse<HealthCheckResponse>> {
    let start_time = Instant::now();
    info!("Performing comprehensive health check");

    // I'm collecting health information from all critical services
    let mut checks = Vec::new();
    let mut overall_status = ServiceStatus::Healthy;

    // Database health check
    let (database_status, database_check) = check_database_health(&app_state).await;
    checks.push(database_check);

    // Redis health check
    let (redis_status, redis_check) = check_redis_health(&app_state).await;
    checks.push(redis_check);

    // GitHub API health check
    let (github_status, github_check) = check_github_api_health(&app_state).await;
    checks.push(github_check);

    // Fractal engine health check
    let (fractal_status, fractal_check) = check_fractal_engine_health(&app_state).await;
    checks.push(fractal_check);

    // System resources check
    let (system_health_struct, system_check_item) = check_system_health(&app_state).await;
    checks.push(system_check_item.clone());

    // Determine overall service status
    overall_status = determine_overall_status(&[
        &database_status.status,
        &redis_status.status,
        &github_status.status,
        &fractal_status.status,
        &system_check_item.status,
    ]);

    // Collect performance metrics
    let performance_metrics = collect_performance_metrics(&app_state).await;

    let health_response = HealthCheckResponse {
        status: overall_status,
        timestamp: chrono::Utc::now(),
        uptime_seconds: get_uptime_seconds(),
        version: VersionInfo {
            version: env!("CARGO_PKG_VERSION").to_string(),
            build_time: env!("BUILD_TIME").to_string(),
            git_commit: env!("GIT_COMMIT").to_string(),
            rust_version: option_env!("BUILD_RUST_VERSION").unwrap_or("unknown").to_string(),
        },
        services: ServiceHealthStatus {
            database: database_status,
            redis: redis_status,
            github_api: github_status,
            fractal_engine: fractal_status,
        },
        system: system_status,
        performance: performance_metrics,
        checks,
    };

    let total_check_time = start_time.elapsed();
    info!("Health check completed in {}ms with status: {:?}",
        total_check_time.as_millis(), health_response.status);

    Ok(Json(health_response))
}

/// Readiness probe endpoint for Kubernetes deployments
/// I'm providing a readiness check that indicates when the service is ready to accept traffic
pub async fn readiness_check(
    State(app_state): State<AppState>,
) -> Result<JsonResponse<serde_json::Value>> {
    info!("Performing readiness check");

    // I'm checking only critical services needed for request handling
    let database_ready = check_database_readiness(&app_state).await;
    let redis_ready = check_redis_readiness(&app_state).await;
    let config_ready = check_configuration_readiness(&app_state).await;

    let is_ready = database_ready && redis_ready && config_ready;

    let readiness_response = serde_json::json!({
        "ready": is_ready,
        "timestamp": chrono::Utc::now(),
        "checks": {
            "database": database_ready,
            "redis": redis_ready,
            "configuration": config_ready
        }
    });

    if is_ready {
        info!("Service is ready to accept traffic");
        Ok(Json(readiness_response))
    } else {
        warn!("Service is not ready - some dependencies are unavailable");
        Err(AppError::ServiceUnavailableError("Service not ready".to_string()))
    }
}

/// Liveness probe endpoint for Kubernetes deployments
/// I'm providing a liveness check to detect if the service needs to be restarted
pub async fn liveness_check() -> Result<JsonResponse<serde_json::Value>> {
    // I'm implementing a simple liveness check that verifies basic service operation
    let liveness_response = serde_json::json!({
        "alive": true,
        "timestamp": chrono::Utc::now(),
        "uptime_seconds": get_uptime_seconds()
    });

    Ok(Json(liveness_response))
}

// Helper functions for individual service health checks

async fn check_database_health(app_state: &AppState) -> (ComponentStatus, HealthCheck) {
    let start_time = Instant::now();
    let check_name = "database_connection".to_string();

    match sqlx::query("SELECT 1 as health_check, pg_database_size(current_database()) as db_size")
        .fetch_one(&app_state.db_pool)
        .await
    {
        Ok(row) => {
            let duration = start_time.elapsed();
            let db_size: i64 = row.try_get("db_size").unwrap_or(0);

            let status = ComponentStatus {
                status: ServiceStatus::Healthy,
                response_time_ms: Some(duration.as_millis() as u64),
                last_check: chrono::Utc::now(),
                error_message: None,
                metadata: Some(serde_json::json!({
                    "database_size_bytes": db_size,
                    "pool_size": app_state.db_pool.size(),
                    "idle_connections": app_state.db_pool.num_idle()
                })),
            };

            let check = HealthCheck {
                name: check_name,
                status: ServiceStatus::Healthy,
                duration_ms: duration.as_millis() as u64,
                message: "Database connection successful".to_string(),
            };

            (status, check)
        }
        Err(e) => {
            let duration = start_time.elapsed();

            let status = ComponentStatus {
                status: ServiceStatus::Unhealthy,
                response_time_ms: Some(duration.as_millis() as u64),
                last_check: chrono::Utc::now(),
                error_message: Some(e.to_string()),
                metadata: None,
            };

            let check = HealthCheck {
                name: check_name,
                status: ServiceStatus::Unhealthy,
                duration_ms: duration.as_millis() as u64,
                message: format!("Database connection failed: {}", e),
            };

            (status, check)
        }
    }
}

async fn check_redis_health(app_state: &AppState) -> (ComponentStatus, HealthCheck) {
    let start_time = Instant::now();
    let check_name = "redis_connection".to_string();

    match app_state.redis_client.get_async_connection().await {
        Ok(mut conn) => {
            match redis::cmd("PING").query_async::<_, String>(&mut conn).await {
                Ok(response) if response == "PONG" => {
                    let duration = start_time.elapsed();

                    let status = ComponentStatus {
                        status: ServiceStatus::Healthy,
                        response_time_ms: Some(duration.as_millis() as u64),
                        last_check: chrono::Utc::now(),
                        error_message: None,
                        metadata: Some(serde_json::json!({
                            "ping_response": response
                        })),
                    };

                    let check = HealthCheck {
                        name: check_name,
                        status: ServiceStatus::Healthy,
                        duration_ms: duration.as_millis() as u64,
                        message: "Redis connection successful".to_string(),
                    };

                    (status, check)
                }
                Ok(unexpected_response) => {
                    let duration = start_time.elapsed();

                    let status = ComponentStatus {
                        status: ServiceStatus::Degraded,
                        response_time_ms: Some(duration.as_millis() as u64),
                        last_check: chrono::Utc::now(),
                        error_message: Some(format!("Unexpected Redis response: {}", unexpected_response)),
                        metadata: None,
                    };

                    let check = HealthCheck {
                        name: check_name,
                        status: ServiceStatus::Degraded,
                        duration_ms: duration.as_millis() as u64,
                        message: format!("Redis returned unexpected response: {}", unexpected_response),
                    };

                    (status, check)
                }
                Err(e) => {
                    let duration = start_time.elapsed();

                    let status = ComponentStatus {
                        status: ServiceStatus::Unhealthy,
                        response_time_ms: Some(duration.as_millis() as u64),
                        last_check: chrono::Utc::now(),
                        error_message: Some(e.to_string()),
                        metadata: None,
                    };

                    let check = HealthCheck {
                        name: check_name,
                        status: ServiceStatus::Unhealthy,
                        duration_ms: duration.as_millis() as u64,
                        message: format!("Redis PING failed: {}", e),
                    };

                    (status, check)
                }
            }
        }
        Err(e) => {
            let duration = start_time.elapsed();

            let status = ComponentStatus {
                status: ServiceStatus::Unhealthy,
                response_time_ms: Some(duration.as_millis() as u64),
                last_check: chrono::Utc::now(),
                error_message: Some(e.to_string()),
                metadata: None,
            };

            let check = HealthCheck {
                name: check_name,
                status: ServiceStatus::Unhealthy,
                duration_ms: duration.as_millis() as u64,
                message: format!("Redis connection failed: {}", e),
            };

            (status, check)
        }
    }
}

async fn check_github_api_health(app_state: &AppState) -> (ComponentStatus, HealthCheck) {
    let start_time = Instant::now();
    let check_name = "github_api".to_string();

    // I'm checking GitHub API rate limit status as a health indicator
    match app_state.github_service.get_rate_limit_status().await {
        Ok(rate_limit) => {
            let duration = start_time.elapsed();
            let remaining_percentage = (rate_limit.remaining as f64 / rate_limit.limit as f64) * 100.0;

            let status = if remaining_percentage < 10.0 {
                ServiceStatus::Degraded
            } else {
                ServiceStatus::Healthy
            };

            let component_status = ComponentStatus {
                status: status.clone(),
                response_time_ms: Some(duration.as_millis() as u64),
                last_check: chrono::Utc::now(),
                error_message: None,
                metadata: Some(serde_json::json!({
                    "rate_limit_remaining": rate_limit.remaining,
                    "rate_limit_total": rate_limit.limit,
                    "rate_limit_percentage": remaining_percentage,
                    "reset_time": chrono::DateTime::from_timestamp(rate_limit.reset as i64, 0)
                })),
            };

            let check = HealthCheck {
                name: check_name,
                status,
                duration_ms: duration.as_millis() as u64,
                message: format!("GitHub API accessible, {}/{} requests remaining",
                    rate_limit.remaining, rate_limit.limit),
            };

            (component_status, check)
        }
        Err(e) => {
            let duration = start_time.elapsed();

            let status = ComponentStatus {
                status: ServiceStatus::Degraded, // GitHub API issues shouldn't make the whole service unhealthy
                response_time_ms: Some(duration.as_millis() as u64),
                last_check: chrono::Utc::now(),
                error_message: Some(e.to_string()),
                metadata: None,
            };

            let check = HealthCheck {
                name: check_name,
                status: ServiceStatus::Degraded,
                duration_ms: duration.as_millis() as u64,
                message: format!("GitHub API check failed: {}", e),
            };

            (status, check)
        }
    }
}

async fn check_fractal_engine_health(app_state: &AppState) -> (ComponentStatus, HealthCheck) {
    let start_time = Instant::now();
    let check_name = "fractal_engine".to_string();

    // I'm performing a quick fractal computation test to verify the engine
    let test_request = crate::services::fractal_service::FractalRequest {
        width: 32,
        height: 32,
        center_x: -0.5,
        center_y: 0.0,
        zoom: 1.0,
        max_iterations: 50,
        fractal_type: crate::services::fractal_service::FractalType::Mandelbrot,
    };

    let computation_result = tokio::task::spawn_blocking(move || {
        let service = crate::services::fractal_service::FractalService::new();
        service.generate_mandelbrot(test_request)
    }).await;

    match computation_result {
        Ok(result) => {
            let duration = start_time.elapsed();

            let status = ComponentStatus {
                status: ServiceStatus::Healthy,
                response_time_ms: Some(duration.as_millis() as u64),
                last_check: chrono::Utc::now(),
                error_message: None,
                metadata: Some(serde_json::json!({
                    "test_computation_time_ms": result.computation_time_ms,
                    "pixels_computed": result.width * result.height,
                    "engine_version": "rayon-parallel"
                })),
            };

            let check = HealthCheck {
                name: check_name,
                status: ServiceStatus::Healthy,
                duration_ms: duration.as_millis() as u64,
                message: format!("Fractal engine healthy, test computation took {}ms", result.computation_time_ms),
            };

            (status, check)
        }
        Err(e) => {
            let duration = start_time.elapsed();

            let status = ComponentStatus {
                status: ServiceStatus::Unhealthy,
                response_time_ms: Some(duration.as_millis() as u64),
                last_check: chrono::Utc::now(),
                error_message: Some(e.to_string()),
                metadata: None,
            };

            let check = HealthCheck {
                name: check_name,
                status: ServiceStatus::Unhealthy,
                duration_ms: duration.as_millis() as u64,
                message: format!("Fractal engine test failed: {}", e),
            };

            (status, check)
        }
    }
}

async fn check_system_health(_app_state: &AppState) -> (SystemHealth, HealthCheck) {
    let start_time = Instant::now();

    // I'm collecting system resource information
    use sysinfo::{System, SystemExt, CpuExt, DiskExt};
    let mut sys = System::new_all();
    sys.refresh_all();

    let cpu_usage = sys.global_cpu_info().cpu_usage() as f64;
    let memory_usage = (sys.used_memory() as f64 / sys.total_memory() as f64) * 100.0;

    // Calculate disk usage (taking the root filesystem)
    let disk_usage = if let Some(disk) = sys.disks().first() {
        let used = disk.total_space() - disk.available_space();
        (used as f64 / disk.total_space() as f64) * 100.0
    } else {
        0.0
    };

    let load_average = sys.load_average();
    let load_avg_vec = vec![load_average.one, load_average.five, load_average.fifteen];

    // Determine system health status
    let system_status = if cpu_usage > 90.0 || memory_usage > 95.0 || disk_usage > 95.0 {
        ServiceStatus::Unhealthy
    } else if cpu_usage > 70.0 || memory_usage > 80.0 || disk_usage > 80.0 {
        ServiceStatus::Degraded
    } else {
        ServiceStatus::Healthy
    };

    let system_health = SystemHealth {
        cpu_usage_percent: cpu_usage,
        memory_usage_percent: memory_usage,
        disk_usage_percent: disk_usage,
        active_connections: 0, // This would need to be implemented based on your connection tracking
        load_average: load_avg_vec,
    };

    let duration = start_time.elapsed();
    let check = HealthCheck {
        name: "system_resources".to_string(),
        status: system_status,
        duration_ms: duration.as_millis() as u64,
        message: format!("CPU: {:.1}%, Memory: {:.1}%, Disk: {:.1}%",
            cpu_usage, memory_usage, disk_usage),
    };

    (system_health, check)
}

// Helper functions for readiness checks

async fn check_database_readiness(app_state: &AppState) -> bool {
    sqlx::query("SELECT 1")
        .fetch_one(&app_state.db_pool)
        .await
        .is_ok()
}

async fn check_redis_readiness(app_state: &AppState) -> bool {
    match app_state.redis_client.get_async_connection().await {
        Ok(mut conn) => {
            redis::cmd("PING")
                .query_async::<_, String>(&mut conn)
                .await
                .map(|response| response == "PONG")
                .unwrap_or(false)
        }
        Err(_) => false,
    }
}

async fn check_configuration_readiness(app_state: &AppState) -> bool {
    // I'm checking that essential configuration is present
    !app_state.config.github_token.is_empty()
        && !app_state.config.github_username.is_empty()
        && !app_state.config.database_url.is_empty()
        && !app_state.config.redis_url.is_empty()
}

// Helper functions for metrics and status determination

async fn collect_performance_metrics(_app_state: &AppState) -> PerformanceMetrics {
    // I'm implementing basic performance metrics collection
    // In a production system, you'd want to integrate with your metrics collection system
    PerformanceMetrics {
        requests_per_second: 0.0, // TODO: Implement actual metrics collection
        average_response_time_ms: 0.0,
        error_rate_percent: 0.0,
        fractal_computations_last_hour: 0,
        github_api_calls_last_hour: 0,
    }
}

fn determine_overall_status(statuses: &[&ServiceStatus]) -> ServiceStatus {
    // I'm implementing a conservative approach to overall status determination
    if statuses.iter().any(|&status| matches!(status, ServiceStatus::Unhealthy)) {
        ServiceStatus::Unhealthy
    } else if statuses.iter().any(|&status| matches!(status, ServiceStatus::Degraded)) {
        ServiceStatus::Degraded
    } else {
        ServiceStatus::Healthy
    }
}

fn get_uptime_seconds() -> u64 {
    // I'm implementing a simple uptime calculation
    // In a production system, you'd want to track this more accurately
    static START_TIME: std::sync::OnceLock<std::time::Instant> = std::sync::OnceLock::new();
    let start = START_TIME.get_or_init(|| std::time::Instant::now());
    start.elapsed().as_secs()
}
</file>

<file path="src/routes/mod.rs">
/*
 * Routes module aggregator organizing all HTTP endpoints with consistent structure and middleware integration.
 * I'm implementing clean route organization that enables easy expansion while maintaining performance and security standards.
 */

pub mod github;
pub mod fractals;
pub mod performance;
pub mod health;

// Re-export all route handlers for convenient access from main.rs
pub use github::*;
pub use fractals::*;
pub use performance::*;
pub use health::*;

use crate::utils::config::Config;
use axum::http::header;

use axum::{
    Router,
    response::IntoResponse,
    routing::{get, post, Route},
    http::{Method, HeaderValue},
};
use tower_http::{
    cors::{CorsLayer, Any},
    compression::CompressionLayer,
    trace::TraceLayer,
    timeout::TimeoutLayer,
    limit::RequestBodyLimitLayer,
};
use std::time::Duration;
use tracing::info;

use crate::{
    AppState,
    utils::error::AppError,
};

/// Create the complete application router with all endpoints and middleware
/// I'm implementing a comprehensive routing structure with performance optimization and security
pub fn create_router() -> Router<AppState> {
    info!("Defining core application routes");

    Router::new()
        .route("/health", get(health::health_check))
        .route("/health/ready", get(health::readiness_check))
        .route("/health/live", get(health::liveness_check))

        .route("/api/github/repos", get(github::get_repositories))
        .route("/api/github/repo/:owner/:name", get(github::get_repository_details))
        .route("/api/github/repo/:owner/:name/stats", get(github::get_repository_stats))
        .route("/api/github/language-distribution", get(github::get_language_distribution))

        .route("/api/fractals/mandelbrot", post(fractals::generate_mandelbrot))
        .route("/api/fractals/julia", post(fractals::generate_julia))
        .route("/api/fractals/benchmark", post(fractals::benchmark_generation))

        .route("/api/performance/metrics", get(performance::get_current_metrics))
        .route("/api/performance/system", get(performance::get_system_info))
        .route("/api/performance/benchmark", post(performance::run_benchmark))
        .route("/api/performance/history", get(performance::get_metrics_history))
}


pub fn create_middleware_stack(config: &Config) -> impl tower::Layer<Route> + Clone {
    use tower::ServiceBuilder;

    ServiceBuilder::new()
        .layer(create_cors_layer(config))
        .layer(CompressionLayer::new())
        .layer(TimeoutLayer::new(Duration::from_secs(30)))
        .layer(RequestBodyLimitLayer::new(10 * 1024 * 1024))
        .layer(TraceLayer::new_for_http())
}

/// I'm implementing flexible CORS that supports development while maintaining security in production
fn create_cors_layer(config: &Config) -> CorsLayer {

    let mut cors = CorsLayer::new()
        .allow_methods([
            Method::GET, Method::POST, Method::PUT, Method::DELETE, Method::HEAD, Method::OPTIONS,
        ])
        .allow_headers([
            header::CONTENT_TYPE, header::AUTHORIZATION, header::ACCEPT, header::USER_AGENT,
        ]);

    if config.is_development() {
        cors = cors.allow_origin(Any);
    } else {
        let origins: Vec<_> = config.cors_allowed_origins
            .iter()
            .filter_map(|origin| origin.parse().ok())
            .collect();
        if !origins.is_empty() {
            cors = cors.allow_origin(origins);
        } else {
            cors = cors.allow_origin(Any);
        }
    }
    cors.allow_credentials(false).max_age(Duration::from_secs(3600))
}

/// Custom rate limiting middleware
/// I'm providing a foundation for rate limiting that can be expanded based on requirements
#[allow(dead_code)]
async fn rate_limiting_middleware<B>(
    request: axum::http::Request<B>,
    next: axum::middleware::Next,
) -> Result<axum::response::Response, AppError> {
    // Get client IP address
    let client_ip = request
    .headers()
    .get("x-forwarded-for")
    .or_else(|| request.headers().get("x-real-ip"))
    .and_then(|hv| hv.to_str().ok())
    .unwrap_or("unknown");

    // Check rate limit based on endpoint
    let path = request.uri().path();
    let rate_limit = get_rate_limit_for_path(path);

    // Check against a rate limiting store
    // For now, I'll just pass through
    tracing::debug!("Rate limiting check for {} accessing {}: {:?}", client_ip, path, rate_limit);

    Ok(next.run(request).await)
}

/// Rate limiting configuration for different endpoint types
/// I'm categorizing endpoints by their computational cost and security requirements
#[derive(Debug, Clone, serde::Serialize)]
struct RateLimit {
    requests_per_minute: u32,
    burst_size: u32,
}

fn get_rate_limit_for_path(path: &str) -> RateLimit {
    match path {
        // Fractal endpoints are computationally expensive
        p if p.starts_with("/api/fractals/") => RateLimit {
            requests_per_minute: 10,
            burst_size: 3,
        },

        // Performance endpoints return cached data mostly
        p if p.starts_with("/api/performance/") => RateLimit {
            requests_per_minute: 60,
            burst_size: 10,
        },

        // GitHub endpoints depend on external API
        p if p.starts_with("/api/github/") => RateLimit {
            requests_per_minute: 30,
            burst_size: 5,
        },

        // Health checks should be very permissive
        "/health" | "/health/ready" | "/health/live" => RateLimit {
            requests_per_minute: 200,
            burst_size: 50,
        },

        // Default rate limit for other endpoints
        _ => RateLimit {
            requests_per_minute: 100,
            burst_size: 20,
        },
    }
}

/// Custom error handler for route-level errors
/// I'm implementing consistent error responses across all endpoints
pub async fn handle_404() -> axum::response::Response {
    let error_response = serde_json::json!({
        "error": {
            "code": "NOT_FOUND",
            "message": "The requested endpoint does not exist",
            "timestamp": chrono::Utc::now(),
                                           "available_endpoints": [
                                               "/health",
                                               "/api/github/repos",
                                               "/api/fractals/mandelbrot",
                                               "/api/performance/metrics"
                                           ]
        }
    });

    (
        axum::http::StatusCode::NOT_FOUND,
     axum::Json(error_response),
    )
    .into_response()
}

/// Create router with API versioning support
pub fn create_versioned_router() -> Router<AppState> {
    Router::new()
        .nest("/v1", create_router())

        .nest("/api", create_api_routes())

        .fallback(handle_404)
}

/// Create just the API routes without health endpoints
/// I'm separating API routes for cleaner organization
fn create_api_routes() -> Router<AppState> {
    Router::new()
    // GitHub API integration endpoints
    .route("/github/repos", get(github::get_repositories))
    .route("/github/repo/:owner/:name", get(github::get_repository_details))
    .route("/github/repo/:owner/:name/stats", get(github::get_repository_stats))
    .route("/github/language-distribution", get(github::get_language_distribution))

    // Fractal generation endpoints
    .route("/fractals/mandelbrot", post(fractals::generate_mandelbrot))
    .route("/fractals/julia", post(fractals::generate_julia))
    .route("/fractals/benchmark", post(fractals::benchmark_generation))

    // Performance monitoring endpoints
    .route("/performance/metrics", get(performance::get_current_metrics))
    .route("/performance/system", get(performance::get_system_info))
    .route("/performance/benchmark", post(performance::run_benchmark))
    .route("/performance/history", get(performance::get_metrics_history))
}

/// Route information for API documentation
/// I'm providing structured route information for documentation generation
#[derive(Debug, serde::Serialize)]
pub struct RouteInfo {
    pub path: String,
    pub method: String,
    pub description: String,
    pub parameters: Vec<RouteParameter>,
    pub response_type: String,
    pub rate_limit: RateLimit,
}

#[derive(Debug, serde::Serialize)]
pub struct RouteParameter {
    pub name: String,
    pub param_type: String,
    pub required: bool,
    pub description: String,
}

/// Get all available routes with their documentation
/// I'm providing comprehensive API documentation support
pub fn get_route_documentation() -> Vec<RouteInfo> {
    vec![
        RouteInfo {
            path: "/health".to_string(),
            method: "GET".to_string(),
            description: "Comprehensive health check with system status".to_string(),
            parameters: vec![],
            response_type: "HealthCheckResponse".to_string(),
            rate_limit: get_rate_limit_for_path("/health"),
        },
        RouteInfo {
            path: "/api/github/repos".to_string(),
            method: "GET".to_string(),
            description: "Get paginated list of repositories with filtering".to_string(),
            parameters: vec![
                RouteParameter {
                    name: "page".to_string(),
                    param_type: "query".to_string(),
                    required: false,
                    description: "Page number (default: 1)".to_string(),
                },
                RouteParameter {
                    name: "per_page".to_string(),
                    param_type: "query".to_string(),
                    required: false,
                    description: "Items per page (default: 20, max: 100)".to_string(),
                },
                RouteParameter {
                    name: "language".to_string(),
                    param_type: "query".to_string(),
                    required: false,
                    description: "Filter by programming language".to_string(),
                },
            ],
            response_type: "RepositoryResponse".to_string(),
            rate_limit: get_rate_limit_for_path("/api/github/repos"),
        },
        RouteInfo {
            path: "/api/fractals/mandelbrot".to_string(),
            method: "POST".to_string(),
            description: "Generate Mandelbrot fractal with real-time performance metrics".to_string(),
            parameters: vec![
                RouteParameter {
                    name: "width".to_string(),
                    param_type: "query".to_string(),
                    required: false,
                    description: "Image width in pixels (default: 800, max: 4096)".to_string(),
                },
                RouteParameter {
                    name: "height".to_string(),
                    param_type: "query".to_string(),
                    required: false,
                    description: "Image height in pixels (default: 600, max: 4096)".to_string(),
                },
                RouteParameter {
                    name: "zoom".to_string(),
                    param_type: "query".to_string(),
                    required: false,
                    description: "Zoom level (default: 1.0)".to_string(),
                },
            ],
            response_type: "FractalApiResponse".to_string(),
            rate_limit: get_rate_limit_for_path("/api/fractals/mandelbrot"),
        },
        RouteInfo {
            path: "/api/performance/metrics".to_string(),
            method: "GET".to_string(),
            description: "Get current system performance metrics".to_string(),
            parameters: vec![],
            response_type: "PerformanceMetrics".to_string(),
            rate_limit: get_rate_limit_for_path("/api/performance/metrics"),
        },
    ]
}

/// Export route testing utilities
/// I'm providing testing support for route handlers
#[cfg(test)]
pub mod test_utils {
    use super::*;
    use axum::body::Body;
    use axum::http::{Request, StatusCode};
    use tower::ServiceExt;

    pub async fn test_health_endpoint(app: Router<AppState>) -> Result<(), Box<dyn std::error::Error>> {
        let response = app
        .oneshot(Request::builder().uri("/health").body(Body::empty())?)
        .await?;

        assert_eq!(response.status(), StatusCode::OK);
        Ok(())
    }

    pub async fn test_404_handler(app: Router<AppState>) -> Result<(), Box<dyn std::error::Error>> {
        let response = app
        .oneshot(Request::builder().uri("/nonexistent").body(Body::empty())?)
        .await?;

        assert_eq!(response.status(), StatusCode::NOT_FOUND);
        Ok(())
    }
}
</file>

<file path="src/routes/performance.rs">
/*
 * Performance monitoring route handlers providing real-time system metrics and benchmark capabilities for the showcase.
 * I'm implementing comprehensive performance endpoints that demonstrate system capabilities while providing valuable diagnostic information.
 */

use axum::{
    extract::{Query, State},
    http::StatusCode,
    Json,
    response::Json as JsonResponse,
};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use tracing::{info, warn, error};
use sysinfo::{System, SystemExt, CpuExt, DiskExt, NetworkExt};

use crate::{
    utils::error::{AppError, Result},
    AppState,
};

#[derive(Debug, Deserialize)]
pub struct MetricsQuery {
    pub history_limit: Option<usize>,
    pub include_history: Option<bool>,
}

#[derive(Debug, Serialize)]
pub struct CurrentMetricsResponse {
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub system: SystemPerformance,
    pub application: ApplicationPerformance,
    pub hardware: HardwareInfo,
    pub runtime: RuntimeInfo,
}

#[derive(Debug, Serialize)]
pub struct SystemPerformance {
    pub cpu_usage_percent: f64,
    pub memory_usage_percent: f64,
    pub memory_total_gb: f64,
    pub memory_available_gb: f64,
    pub disk_usage_percent: f64,
    pub load_average_1m: f64,
    pub load_average_5m: f64,
    pub load_average_15m: f64,
    pub uptime_seconds: u64,
    pub active_processes: u32,
}

#[derive(Debug, Serialize)]
pub struct ApplicationPerformance {
    pub requests_handled: u64,
    pub average_response_time_ms: f64,
    pub fractal_computations: u64,
    pub github_api_calls: u64,
    pub cache_hit_rate: f64,
    pub database_connections: u32,
    pub memory_usage_mb: f64,
}

#[derive(Debug, Serialize)]
pub struct HardwareInfo {
    pub cpu_model: String,
    pub cpu_cores: u32,
    pub cpu_threads: u32,
    pub architecture: String,
    pub total_memory_gb: f64,
}

#[derive(Debug, Serialize)]
pub struct RuntimeInfo {
    pub rust_version: String,
    pub build_type: String,
    pub optimization_level: String,
    pub features_enabled: Vec<String>,
}

/// Get current performance metrics with comprehensive system analysis
/// I'm providing real-time performance data for monitoring and display
pub async fn get_current_metrics(
    State(app_state): State<AppState>,
    Query(params): Query<MetricsQuery>,
) -> Result<JsonResponse<CurrentMetricsResponse>> {
    info!("Fetching current performance metrics");

    // Collect system metrics
    let mut system = System::new_all();
    system.refresh_all();

    let system_perf = SystemPerformance {
        cpu_usage_percent: system.global_cpu_info().cpu_usage() as f64,
        memory_usage_percent: {
            let total = system.total_memory() as f64;
            let available = system.available_memory() as f64;
            ((total - available) / total) * 100.0
        },
        memory_total_gb: system.total_memory() as f64 / (1024.0 * 1024.0 * 1024.0),
        memory_available_gb: system.available_memory() as f64 / (1024.0 * 1024.0 * 1024.0),
        disk_usage_percent: {
            if let Some(disk) = system.disks().first() {
                let total = disk.total_space() as f64;
                let available = disk.available_space() as f64;
                ((total - available) / total) * 100.0
            } else {
                0.0
            }
        },
        load_average_1m: system.load_average().one,
        load_average_5m: system.load_average().five,
        load_average_15m: system.load_average().fifteen,
        uptime_seconds: system.uptime(),
        active_processes: system.processes().len() as u32,
    };

    let hardware_info = HardwareInfo {
        cpu_model: system.global_cpu_info().brand().to_string(),
        cpu_cores: system.physical_core_count().unwrap_or(0) as u32,
        cpu_threads: system.cpus().len() as u32,
        architecture: std::env::consts::ARCH.to_string(),
        total_memory_gb: system.total_memory() as f64 / (1024.0 * 1024.0 * 1024.0),
    };

    // Application performance metrics (simplified for now)
    let app_perf = ApplicationPerformance {
        requests_handled: 0, // Would be tracked from middleware
        average_response_time_ms: 0.0, // Would be calculated from request timings
        fractal_computations: 0, // Would be tracked from fractal service
        github_api_calls: 0, // Would be tracked from GitHub service
        cache_hit_rate: 0.0, // Would be retrieved from cache service
        database_connections: app_state.db_pool.size(),
        memory_usage_mb: 0.0, // Would be calculated from process memory usage
    };

    let runtime_info = RuntimeInfo {
        rust_version: option_env!("BUILD_RUST_VERSION").unwrap_or("unknown").to_string(),
        build_type: if cfg!(debug_assertions) { "debug".to_string() } else { "release".to_string() },
        optimization_level: if cfg!(debug_assertions) { "none".to_string() } else { "3".to_string() },
        features_enabled: get_enabled_features(),
    };

    let response = CurrentMetricsResponse {
        timestamp: chrono::Utc::now(),
        system: system_perf,
        application: app_perf,
        hardware: hardware_info,
        runtime: runtime_info,
    };

    info!("Performance metrics collected successfully");
    Ok(Json(response))
}

/// Get detailed system information for display
/// I'm providing comprehensive system information for the showcase
pub async fn get_system_info(
    State(_app_state): State<AppState>,
) -> Result<JsonResponse<serde_json::Value>> {
    info!("Fetching detailed system information");
    let mut system = System::new_all();
    system.refresh_all();

    let system_info = serde_json::json!({
        "timestamp": chrono::Utc::now(),
        "os_name": system.name().unwrap_or_default()
    });
    Ok(Json(system_info))
}

/// Run comprehensive performance benchmark
/// I'm implementing a thorough benchmark suite for performance evaluation
pub async fn run_benchmark(
    State(_app_state): State<AppState>,
) -> Result<JsonResponse<serde_json::Value>> {
    info!("Starting comprehensive performance benchmark");
    let benchmark_start = std::time::Instant::now();

    // CPU benchmark: prime number calculation
    let cpu_benchmark = tokio::task::spawn_blocking(|| {
        let start = std::time::Instant::now();
        let mut primes = Vec::new();

        for i in 2..10000 {
            if is_prime(i) {
                primes.push(i);
            }
        }

        let single_thread_time = start.elapsed();
        let single_thread_primes = primes.len();

        // Multi-threaded benchmark
        let start = std::time::Instant::now();
        let multi_thread_primes = (2..50000u32)
            .collect::<Vec<_>>()
            .into_iter()
            .filter(|&i| is_prime(i))
            .count();
        let multi_thread_time = start.elapsed();

        serde_json::json!({
            "single_thread": {
                "primes_found": single_thread_primes,
                "duration_ms": single_thread_time.as_millis(),
                "primes_per_second": single_thread_primes as f64 / single_thread_time.as_secs_f64()
            },
            "multi_thread": {
                "primes_found": multi_thread_primes,
                "duration_ms": multi_thread_time.as_millis(),
                "primes_per_second": multi_thread_primes as f64 / multi_thread_time.as_secs_f64()
            },
            "parallel_efficiency": (multi_thread_primes as f64 / multi_thread_time.as_secs_f64()) /
                                  (single_thread_primes as f64 / single_thread_time.as_secs_f64())
        })
    }).await.unwrap();

    // Memory benchmark: array operations
    let memory_benchmark = tokio::task::spawn_blocking(|| {
        let start = std::time::Instant::now();
        let data_size = 10_000_000;
        let data: Vec<u64> = (0..data_size as u64).collect();
        let allocation_time = start.elapsed();

        let start = std::time::Instant::now();
        let sum: u64 = data.iter().sum();
        let read_time = start.elapsed();

        let start = std::time::Instant::now();
        let mut write_data = vec![0u64; data_size as usize];
        for i in 0..data_size as usize {
            write_data[i] = i as u64;
        }
        let write_time = start.elapsed();

        serde_json::json!({
            "allocation": {
                "duration_ms": allocation_time.as_millis(),
                "mb_allocated": (data_size * 8) as f64 / (1024.0 * 1024.0),
                "mb_per_second": (data_size * 8) as f64 / (1024.0 * 1024.0) / allocation_time.as_secs_f64()
            },
            "sequential_read": {
                "duration_ms": read_time.as_millis(),
                "sum_result": sum,
                "mb_per_second": (data_size * 8) as f64 / (1024.0 * 1024.0) / read_time.as_secs_f64()
            },
            "sequential_write": {
                "duration_ms": write_time.as_millis(),
                "mb_per_second": (data_size * 8) as f64 / (1024.0 * 1024.0) / write_time.as_secs_f64()
            }
        })
    }).await.unwrap();

    // System information at benchmark time
    let mut system = System::new_all();
    system.refresh_all();

    let benchmark_duration = benchmark_start.elapsed();

    let benchmark_results = serde_json::json!({
        "benchmark_id": uuid::Uuid::new_v4().to_string(),
        "timestamp": chrono::Utc::now(),
        "total_duration_ms": benchmark_duration.as_millis(),
        "system_info": {
            "cpu_model": system.global_cpu_info().brand(),
            "cpu_cores": system.physical_core_count().unwrap_or(0),
            "cpu_threads": system.cpus().len(),
            "memory_total_gb": system.total_memory() as f64 / (1024.0 * 1024.0 * 1024.0),
            "architecture": std::env::consts::ARCH,
            "os": system.long_os_version(),
        },
        "benchmarks": {
            "cpu": cpu_benchmark,
            "memory": memory_benchmark,
        },
        "performance_rating": calculate_performance_rating(&cpu_benchmark, &memory_benchmark),
        "comparison": {
            "baseline_system": "Intel Core i5-8400 (6 cores, 16GB RAM)",
            "relative_performance": 1.0, // Would be calculated based on baseline comparison
        }
    });

    info!("Benchmark completed in {:?}", benchmark_duration);
    Ok(Json(benchmark_results))
}

/// Get performance metrics history for trend analysis
/// I'm providing historical performance data for analysis and visualization
pub async fn get_metrics_history(
    State(_app_state): State<AppState>,
    Query(params): Query<MetricsQuery>,
) -> Result<JsonResponse<serde_json::Value>> {
    info!("Fetching performance metrics history");

    let limit = params.history_limit.unwrap_or(100).min(1000);

    // In a real implementation, this would fetch from database
    // For now, I'm providing sample historical data structure
    let history = serde_json::json!({
        "timestamp": chrono::Utc::now(),
        "period_minutes": limit * 5, // Assuming 5-minute intervals
        "data_points": limit,
        "metrics": {
            "cpu_usage": generate_sample_timeseries(limit, 20.0, 80.0),
            "memory_usage": generate_sample_timeseries(limit, 40.0, 70.0),
            "disk_usage": generate_sample_timeseries(limit, 50.0, 60.0),
            "load_average": generate_sample_timeseries(limit, 0.1, 2.0),
            "response_times": generate_sample_timeseries(limit, 5.0, 50.0),
        },
        "summary": {
            "average_cpu": 45.0,
            "peak_cpu": 85.0,
            "average_memory": 55.0,
            "peak_memory": 72.0,
            "incidents": 0,
            "uptime_percentage": 100.0,
        }
    });

    info!("Performance history generated with {} data points", limit);
    Ok(Json(history))
}

// Helper functions for performance calculations and utilities

fn is_prime(n: u32) -> bool {
    if n < 2 {
        return false;
    }
    for i in 2..((n as f64).sqrt() as u32 + 1) {
        if n % i == 0 {
            return false;
        }
    }
    true
}

fn get_enabled_features() -> Vec<String> {
    let mut features = Vec::new();

    if cfg!(feature = "jemalloc") {
        features.push("jemalloc".to_string());
     }
     // if cfg!(feature = "simd") { // Custom feature, check Cargo.toml
     //     features.push("simd".to_string());
     // }
     // if cfg!(feature = "parallel") { // Custom feature, check Cargo.toml
     //     features.push("parallel".to_string());
     // }

    // Add compile-time features
    if cfg!(debug_assertions) {
        features.push("debug-assertions".to_string());
    }
    if cfg!(target_feature = "avx2") {
        features.push("avx2".to_string());
    }
    if cfg!(target_feature = "fma") {
        features.push("fma".to_string());
    }

    features
}

fn calculate_performance_rating(cpu_bench: &serde_json::Value, memory_bench: &serde_json::Value) -> String {
    // Simple performance rating based on benchmark results
    let cpu_score = cpu_bench["multi_thread"]["primes_per_second"].as_f64().unwrap_or(0.0);
    let memory_score = memory_bench["sequential_read"]["mb_per_second"].as_f64().unwrap_or(0.0);

    let combined_score = (cpu_score / 1000.0) + (memory_score / 1000.0);

    match combined_score {
        x if x > 10.0 => "Exceptional".to_string(),
        x if x > 7.0 => "Excellent".to_string(),
        x if x > 5.0 => "Very Good".to_string(),
        x if x > 3.0 => "Good".to_string(),
        x if x > 1.0 => "Fair".to_string(),
        _ => "Needs Optimization".to_string(),
    }
}

fn generate_sample_timeseries(count: usize, min: f64, max: f64) -> Vec<serde_json::Value> {
    use std::f64::consts::PI;

    (0..count)
        .map(|i| {
            let t = i as f64 / count as f64;
            let noise = (t * PI * 4.0).sin() * 0.1 + (t * PI * 8.0).cos() * 0.05;
            let base = min + (max - min) * (0.5 + 0.3 * (t * PI * 2.0).sin());
            let value = (base + noise * (max - min)).max(min).min(max);

            serde_json::json!({
                "timestamp": chrono::Utc::now() - chrono::Duration::minutes((count - i) as i64 * 5),
                "value": (value * 100.0).round() / 100.0
            })
        })
        .collect()
}
</file>

<file path="src/services/cache_service.rs">
// backend/src/services/cache_service.rs

use redis::{Client, AsyncCommands}; // Removed `Connection` as it wasn't directly used in the struct
use serde::{Deserialize, Serialize, de::DeserializeOwned};
use std::time::{Duration, SystemTime, UNIX_EPOCH};
use tracing::{info, warn, error, debug};
use std::sync::Arc;
use tokio::sync::RwLock;

use crate::utils::error::{AppError, Result};


#[derive(Clone)]
pub struct CacheService {
    client: Client,
    key_prefix: String,
    default_ttl: u64,
    connection_pool: Arc<RwLock<Option<redis::aio::ConnectionManager>>>,
}

// Manually implement Debug for CacheService
impl std::fmt::Debug for CacheService {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("CacheService")
            .field("client", &"<RedisClient>") // Placeholder for client as it might not be Debug or simple to Debug
            .field("key_prefix", &self.key_prefix)
            .field("default_ttl", &self.default_ttl)
            .field("connection_pool", &"<ConnectionPool>") // Placeholder for connection_pool
            .finish()
        // Or, if you want to indicate that some fields are not shown:
        // .finish_non_exhaustive()
    }
}

/// Cache entry with metadata for advanced cache management
/// I'm including metadata to enable sophisticated cache analytics and management
#[derive(Debug, Serialize, Deserialize)]
struct CacheEntry<T> {
    data: T,
    created_at: u64,
    expires_at: u64,
    access_count: u64,
    last_accessed: u64,
    version: u32,
}

/// Cache statistics for monitoring and optimization
/// I'm providing comprehensive cache analytics for performance tuning
#[derive(Debug, Serialize, Deserialize)]
pub struct CacheStats {
    pub total_keys: u64,
    pub hit_rate: f64,
    pub miss_rate: f64,
    pub memory_usage_bytes: u64,
    pub expired_keys: u64,
    pub evicted_keys: u64,
    pub average_ttl_seconds: f64,
    pub most_accessed_keys: Vec<String>,
}

/// Cache operation types for metrics tracking
/// I'm categorizing cache operations for detailed performance analysis
#[derive(Debug, Clone)]
pub enum CacheOperation {
    Get,
    Set,
    Delete,
    Expire,
    Flush,
}

impl CacheService {
    /// Create a new cache service with Redis connection
    /// I'm setting up comprehensive cache configuration with connection management
    pub fn new(redis_client: Client) -> Self {
        Self {
            client: redis_client,
            key_prefix: "perf_showcase:".to_string(),
            default_ttl: 3600, // 1 hour default TTL
            connection_pool: Arc::new(RwLock::new(None)),
        }
    }

    /// Create cache service with custom configuration
    /// I'm providing flexibility for different caching strategies and environments
    pub fn with_config(redis_client: Client, key_prefix: String, default_ttl: u64) -> Self {
        Self {
            client: redis_client,
            key_prefix,
            default_ttl,
            connection_pool: Arc::new(RwLock::new(None)),
        }
    }

    /// Get a connection with automatic pool management
    /// I'm implementing intelligent connection pooling with automatic recovery
    async fn get_connection(&self) -> Result<redis::aio::ConnectionManager> {
        let mut pool_guard = self.connection_pool.write().await;

        if let Some(conn_manager) = pool_guard.as_ref() {
            // Test connection health
            match self.ping_connection(conn_manager).await {
                Ok(_) => return Ok(conn_manager.clone()),
                Err(_) => {
                    warn!("Redis connection is stale, creating new connection");
                    // Connection is stale, drop it and create new one
                }
            }
        }

        // Create initial or new connection
        let new_conn_manager = redis::aio::ConnectionManager::new(self.client.clone())
            .await
            .map_err(|e| AppError::CacheError(format!("Failed to create Redis connection manager: {}", e)))?;

        info!("Created new Redis connection manager");
        *pool_guard = Some(new_conn_manager.clone());
        Ok(new_conn_manager)
    }


    /// Create a new Redis connection with optimal settings
    /// I'm configuring Redis connections for maximum performance and reliability
    async fn create_connection(&self) -> Result<redis::aio::ConnectionManager> {
        let conn_manager = redis::aio::ConnectionManager::new(self.client.clone())
        .await
        .map_err(|e| AppError::CacheError(format!("Failed to create Redis connection: {}", e)))?;

        info!("Created new Redis connection");
        Ok(conn_manager)
    }

    /// Test connection health with ping
    /// I'm implementing connection health verification
    async fn ping_connection(&self, conn_manager: &redis::aio::ConnectionManager) -> Result<()> {
        let mut conn = conn_manager.clone(); // Clone the manager to get a connection from its pool
        let response: String = redis::cmd("PING").query_async(&mut conn).await
            .map_err(|e| AppError::CacheError(format!("Redis ping failed: {}", e)))?;

        if response == "PONG" {
            Ok(())
        } else {
            Err(AppError::CacheError("Redis ping returned unexpected response".to_string()))
        }
    }

    /// Get a value from cache with automatic deserialization
    /// I'm implementing intelligent cache retrieval with metadata tracking
    pub async fn get<T>(&self, key: &str) -> Result<Option<T>>
    where
    T: DeserializeOwned + Send + Sync + Serialize,
    {
        let full_key = self.build_key(key);
        let mut conn = self.get_connection().await?;

        debug!("Cache GET: {}", full_key);

        match conn.get::<_, Option<String>>(&full_key).await {
            Ok(Some(cached_data)) => {
                match serde_json::from_str::<CacheEntry<T>>(&cached_data) {
                    Ok(mut entry) => {
                        let now = self.current_timestamp();

                        // Check if entry has expired
                        if now > entry.expires_at {
                            debug!("Cache entry expired: {}", full_key);
                            // Asynchronously delete expired entry
                            let _ = self.delete(key).await; // Use existing delete method
                            return Ok(None);
                        }

                        // Update access metadata
                        entry.access_count += 1;
                        entry.last_accessed = now;

                        // Update entry in cache (fire and forget, but handle potential errors)
                        let updated_data_res = serde_json::to_string(&entry);
                        if let Ok(updated_data) = updated_data_res {
                           let set_result = conn.set::<_, _, ()>(&full_key, updated_data).await;
                           if let Err(e) = set_result {
                               warn!("Failed to update access metadata for cache key {}: {}", full_key, e);
                           }
                        } else if let Err(e) = updated_data_res {
                             warn!("Failed to serialize updated metadata for cache key {}: {}", full_key, e);
                        }


                        debug!("Cache HIT: {}", full_key);
                        Ok(Some(entry.data))
                    }
                    Err(e) => {
                        warn!("Failed to deserialize cache entry {}: {}", full_key, e);
                        // Delete corrupted entry
                        let _ = self.delete(key).await;
                        Ok(None)
                    }
                }
            }
            Ok(None) => {
                debug!("Cache MISS: {}", full_key);
                Ok(None)
            }
            Err(e) => {
                error!("Cache GET error for {}: {}", full_key, e);
                Err(AppError::CacheError(format!("Failed to get cache entry: {}", e)))
            }
        }
    }

    /// Set a value in cache with optional TTL
    /// I'm implementing intelligent cache storage with metadata and expiration management
    pub async fn set<T>(&self, key: &str, value: &T, ttl_seconds: Option<u64>) -> Result<()>
    where
    T: Serialize + Send + Sync,
    {
        let full_key = self.build_key(key);
        let ttl = ttl_seconds.unwrap_or(self.default_ttl);
        let now = self.current_timestamp();

        let entry = CacheEntry {
            data: value,
            created_at: now,
            expires_at: now + ttl,
            access_count: 0,
            last_accessed: now,
            version: 1,
        };

        let serialized = serde_json::to_string(&entry)
        .map_err(|e| AppError::SerializationError(format!("Failed to serialize cache entry: {}", e)))?;

        let mut conn = self.get_connection().await?;

        debug!("Cache SET: {} (TTL: {}s)", full_key, ttl);

        conn.set_ex(&full_key, serialized, ttl).await // Using set_ex for value and TTL together
        .map_err(|e| AppError::CacheError(format!("Failed to set cache entry: {}", e)))?;

        Ok(())
    }

    /// Set a value in cache with default TTL
    /// I'm providing a convenient method for standard cache operations
    pub async fn set_default<T>(&self, key: &str, value: &T) -> Result<()>
    where
    T: Serialize + Send + Sync,
    {
        self.set(key, value, None).await
    }

    /// Delete a value from cache
    /// I'm implementing safe cache invalidation with error handling
    pub async fn delete(&self, key: &str) -> Result<bool> {
        let full_key = self.build_key(key);
        let mut conn = self.get_connection().await?;

        debug!("Cache DELETE: {}", full_key);

        let deleted: i32 = conn.del(&full_key).await
        .map_err(|e| AppError::CacheError(format!("Failed to delete cache entry: {}", e)))?;

        Ok(deleted > 0)
    }

    /// Check if a key exists in cache
    /// I'm providing cache presence verification
    pub async fn exists(&self, key: &str) -> Result<bool> {
        let full_key = self.build_key(key);
        let mut conn = self.get_connection().await?;

        let exists: bool = conn.exists(&full_key).await
        .map_err(|e| AppError::CacheError(format!("Failed to check cache existence: {}", e)))?;

        Ok(exists)
    }

    /// Set expiration time for an existing key
    /// I'm providing TTL management for existing cache entries
    pub async fn expire(&self, key: &str, ttl_seconds: u64) -> Result<bool> {
        let full_key = self.build_key(key);
        let mut conn = self.get_connection().await?;

        debug!("Cache EXPIRE: {} (TTL: {}s)", full_key, ttl_seconds);

        let expired: bool = conn.expire(&full_key, ttl_seconds as usize).await
        .map_err(|e| AppError::CacheError(format!("Failed to set cache expiration: {}", e)))?;

        Ok(expired)
    }

    /// Get remaining TTL for a key
    /// I'm providing TTL inspection for cache management
    pub async fn ttl(&self, key: &str) -> Result<i64> {
        let full_key = self.build_key(key);
        let mut conn = self.get_connection().await?;

        let ttl_val: Option<i64> = conn.ttl(&full_key).await // Changed to Option<i64> as per redis crate docs for non-existent keys or no expiry
        .map_err(|e| AppError::CacheError(format!("Failed to get cache TTL: {}", e)))?;

        Ok(ttl_val.unwrap_or(-2)) // Return -2 if key does not exist, -1 if no expiry, consistent with Redis TTL command
    }

    /// Flush all cache entries with the current prefix
    /// I'm implementing safe cache clearing that respects key namespacing
    pub async fn flush_prefix(&self) -> Result<u64> {
        let pattern = format!("{}*", self.key_prefix);
        let mut conn = self.get_connection().await?;

        info!("Flushing cache entries with pattern: {}", pattern);

        // Get all keys matching the pattern
        let keys: Vec<String> = conn.keys(&pattern).await
        .map_err(|e| AppError::CacheError(format!("Failed to get cache keys: {}", e)))?;

        if keys.is_empty() {
            return Ok(0);
        }

        // Delete all matching keys
        let deleted: i32 = conn.del(&keys).await
        .map_err(|e| AppError::CacheError(format!("Failed to delete cache keys: {}", e)))?;

        info!("Flushed {} cache entries", deleted);
        Ok(deleted as u64)
    }

    /// Get comprehensive cache statistics
    /// I'm providing detailed cache analytics for performance monitoring
    pub async fn get_stats(&self) -> Result<CacheStats> {
        let mut conn = self.get_connection().await?;

        // Get Redis info
        let info_str: String = redis::cmd("INFO").query_async(&mut conn).await
            .map_err(|e| AppError::CacheError(format!("Failed to get Redis info: {}", e)))?;

        // Parse INFO string manually or use a helper if available (redis::InfoDict is not directly async)
        let mut info_map = std::collections::HashMap::new();
        for line in info_str.lines() {
            if line.starts_with('#') || line.is_empty() {
                continue;
            }
            let parts: Vec<&str> = line.split(':').collect();
            if parts.len() == 2 {
                info_map.insert(parts[0].to_string(), parts[1].trim().to_string());
            }
        }

        // Get keys with our prefix
        let pattern = format!("{}*", self.key_prefix);
        let keys: Vec<String> = conn.keys(&pattern).await
        .map_err(|e| AppError::CacheError(format!("Failed to get cache keys: {}", e)))?;

        let total_keys = keys.len() as u64;
        let memory_usage_bytes = info_map.get("used_memory").and_then(|s| s.parse().ok()).unwrap_or(0u64);

        let keyspace_hits: u64 = info_map.get("keyspace_hits").and_then(|s| s.parse().ok()).unwrap_or(0);
        let keyspace_misses: u64 = info_map.get("keyspace_misses").and_then(|s| s.parse().ok()).unwrap_or(0);
        let total_requests = keyspace_hits + keyspace_misses;

        let hit_rate = if total_requests > 0 {
            keyspace_hits as f64 / total_requests as f64
        } else {
            0.0
        };
        let miss_rate = 1.0 - hit_rate;

        let most_accessed_keys = keys.into_iter().take(10).collect();

        Ok(CacheStats {
            total_keys,
            hit_rate,
            miss_rate,
            memory_usage_bytes,
            expired_keys: info_map.get("expired_keys").and_then(|s| s.parse().ok()).unwrap_or(0),
            evicted_keys: info_map.get("evicted_keys").and_then(|s| s.parse().ok()).unwrap_or(0),
            average_ttl_seconds: self.default_ttl as f64, // Simplified
            most_accessed_keys,
        })
    }

    /// Batch get operation for multiple keys
    /// I'm providing efficient bulk cache operations
    pub async fn mget<T>(&self, keys: &[&str]) -> Result<Vec<Option<T>>>
    where
    T: DeserializeOwned + Send + Sync,
    {
        if keys.is_empty() {
            return Ok(vec![]);
        }

        let full_keys: Vec<String> = keys.iter().map(|k| self.build_key(k)).collect();
        let mut conn = self.get_connection().await?;

        debug!("Cache MGET: {} keys", keys.len());

        let results: Vec<Option<String>> = conn.mget(&full_keys).await
        .map_err(|e| AppError::CacheError(format!("Failed to get multiple cache entries: {}", e)))?;

        let mut output = Vec::with_capacity(results.len());
        let now = self.current_timestamp();

        for (i, result) in results.into_iter().enumerate() {
            match result {
                Some(cached_data) => {
                    match serde_json::from_str::<CacheEntry<T>>(&cached_data) {
                        Ok(entry) => {
                            if now <= entry.expires_at {
                                output.push(Some(entry.data));
                            } else {
                                // Entry expired
                                output.push(None);
                                // Asynchronously delete expired entry
                                let _ = self.delete(keys[i]).await;
                            }
                        }
                        Err(_) => {
                            output.push(None);
                            // Delete corrupted entry
                            let _ = self.delete(keys[i]).await;
                        }
                    }
                }
                None => output.push(None),
            }
        }

        Ok(output)
    }

    /// Batch set operation for multiple key-value pairs
    /// I'm providing efficient bulk cache storage
    pub async fn mset<T>(&self, entries: &[(&str, &T)], ttl_seconds: Option<u64>) -> Result<()>
    where
    T: Serialize + Send + Sync,
    {
        if entries.is_empty() {
            return Ok(());
        }

        let ttl = ttl_seconds.unwrap_or(self.default_ttl);
        let now = self.current_timestamp();
        let mut conn = self.get_connection().await?;

        debug!("Cache MSET: {} entries (TTL: {}s)", entries.len(), ttl);

        // Prepare entries as (key, value) tuples for mset_multiple
        let mut kv_pairs_for_redis: Vec<(String, String)> = Vec::with_capacity(entries.len());

        for (key, value) in entries {
            let full_key = self.build_key(key);
            let entry = CacheEntry {
                data: value,
                created_at: now,
                expires_at: now + ttl,
                access_count: 0,
                last_accessed: now,
                version: 1,
            };

            let serialized = serde_json::to_string(&entry)
            .map_err(|e| AppError::SerializationError(format!("Failed to serialize cache entry: {}", e)))?;

            kv_pairs_for_redis.push((full_key, serialized));
        }

        // Set all entries
        conn.mset(&kv_pairs_for_redis).await
        .map_err(|e| AppError::CacheError(format!("Failed to set multiple cache entries: {}", e)))?;

        // Set expiration for all keys in a pipeline for efficiency
        let mut pipe = redis::pipe();
        for (key, _) in entries { // Iterate original keys to avoid issues with kv_pairs_for_redis potentially being moved
            let full_key_for_expire = self.build_key(key);
            pipe.expire(full_key_for_expire, ttl);
        }
        pipe.query_async(&mut conn).await
            .map_err(|e| AppError::CacheError(format!("Failed to set expiration for multiple keys: {}", e)))?;


        Ok(())
    }

    /// Build full cache key with prefix
    /// I'm implementing consistent key naming for cache organization
    fn build_key(&self, key: &str) -> String {
        format!("{}{}", self.key_prefix, key)
    }

    /// Get current timestamp in seconds
    /// I'm providing consistent timestamp generation for cache metadata
    fn current_timestamp(&self) -> u64 {
        SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_default()
        .as_secs()
    }

    /// Health check for cache service
    /// I'm implementing comprehensive cache health verification
    pub async fn health_check(&self) -> Result<serde_json::Value> {
        let start = std::time::Instant::now();
        let mut conn = self.get_connection().await?;

        // Test basic connectivity with ping
        let ping_response: String = redis::cmd("PING").query_async(&mut conn).await
        .map_err(|e| AppError::CacheError(format!("Cache ping failed: {}", e)))?;

        if ping_response != "PONG" {
            return Err(AppError::CacheError("Cache ping returned unexpected response".to_string()));
        }

        // Test set/get operations
        let test_key = "health_check_test";
        let test_value = "test_data";

        conn.set_ex(self.build_key(test_key), test_value, 10).await // Use set_ex
        .map_err(|e| AppError::CacheError(format!("Cache set test failed: {}", e)))?;

        let retrieved: String = conn.get(self.build_key(test_key)).await
        .map_err(|e| AppError::CacheError(format!("Cache get test failed: {}", e)))?;

        if retrieved != test_value {
            return Err(AppError::CacheError("Cache data integrity test failed".to_string()));
        }

        // Clean up test key
        let _: Option<i32> = conn.del(self.build_key(test_key)).await.map_err(|e| AppError::CacheError(format!("Cache del test failed: {}", e)))?;


        let response_time = start.elapsed().as_millis();

        Ok(serde_json::json!({
            "status": "healthy",
            "response_time_ms": response_time,
            "ping_response": ping_response,
            "connectivity": "ok",
            "data_integrity": "ok"
        }))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde::{Deserialize, Serialize};

    #[derive(Debug, Serialize, Deserialize, PartialEq)]
    struct TestData {
        id: u32,
        name: String,
    }

    // Note: These tests require a Redis instance running
    // In CI, you'd use a Redis container

    #[tokio::test]
    #[ignore] // Requires Redis instance
    async fn test_cache_basic_operations() {
        let client = redis::Client::open("redis://127.0.0.1:6379").unwrap();
        let cache = CacheService::new(client);

        let test_data = TestData {
            id: 1,
            name: "test".to_string(),
        };

        // Test set
        cache.set("test_key", &test_data, Some(60)).await.unwrap();

        // Test get
        let retrieved: Option<TestData> = cache.get("test_key").await.unwrap();
        assert_eq!(retrieved, Some(test_data));

        // Test delete
        let deleted = cache.delete("test_key").await.unwrap();
        assert!(deleted);

        // Verify deletion
        let retrieved_after_delete: Option<TestData> = cache.get("test_key").await.unwrap();
        assert_eq!(retrieved_after_delete, None);
    }
}
</file>

<file path="src/services/fractal_service.rs">
/*
 * Core fractal generation service showcasing Rust's computational performance.
 * I'm implementing both Mandelbrot and Julia set generation with deep zoom capabilities and parallel processing to really demonstrate speed.
 */

use num_complex::Complex;
use rayon::prelude::*;
use serde::{Deserialize, Serialize};
use std::time::Instant;

#[derive(Debug, Clone)]
pub struct FractalRequest {
    pub width: u32,
    pub height: u32,
    pub center_x: f64,
    pub center_y: f64,
    pub zoom: f64,
    pub max_iterations: u32,
    pub fractal_type: FractalType,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FractalType {
    Mandelbrot,
    Julia { c_real: f64, c_imag: f64 },
}

#[derive(Debug, Serialize)]
pub struct FractalResponse {
    pub data: Vec<u8>,
    pub width: u32,
    pub height: u32,
    pub computation_time_ms: u128,
    pub zoom_level: f64,
}

#[derive(Clone)]
pub struct FractalService;

impl FractalService {
    pub fn new() -> Self {
        Self
    }

    // Here I'm generating Mandelbrot fractals with parallel processing for maximum performance
    pub fn generate_mandelbrot(&self, request: FractalRequest) -> FractalResponse {
        let start_time = Instant::now();

        let scale = 4.0 / request.zoom;
        let data: Vec<u8> = (0..request.height)
        .into_par_iter()
        .flat_map(|y| {
            (0..request.width).into_par_iter().map(move |x| {
                let cx = request.center_x + (x as f64 - request.width as f64 / 2.0) * scale / request.width as f64;
                let cy = request.center_y + (y as f64 - request.height as f64 / 2.0) * scale / request.height as f64;

                let c = Complex::new(cx, cy);
                let iterations = self.mandelbrot_iterations(c, request.max_iterations);

                // I'm creating an eerie color palette that fits the dark theme
                self.iteration_to_dark_color(iterations, request.max_iterations)
            }).collect::<Vec<_>>()
        })
        .flatten()
        .collect();

        FractalResponse {
            data,
            width: request.width,
            height: request.height,
            computation_time_ms: start_time.elapsed().as_millis(),
            zoom_level: request.zoom,
        }
    }

    // Julia set generation with similar parallel approach
    pub fn generate_julia(&self, request: FractalRequest, c: Complex<f64>) -> FractalResponse {
        let start_time = Instant::now();

        let scale = 4.0 / request.zoom;
        let data: Vec<u8> = (0..request.height)
        .into_par_iter()
        .flat_map(|y| {
            (0..request.width).into_par_iter().map(move |x| {
                let zx = request.center_x + (x as f64 - request.width as f64 / 2.0) * scale / request.width as f64;
                let zy = request.center_y + (y as f64 - request.height as f64 / 2.0) * scale / request.height as f64;

                let z = Complex::new(zx, zy);
                let iterations = self.julia_iterations(z, c, request.max_iterations);

                self.iteration_to_dark_color(iterations, request.max_iterations)
            }).collect::<Vec<_>>()
        })
        .flatten()
        .collect();

        FractalResponse {
            data,
            width: request.width,
            height: request.height,
            computation_time_ms: start_time.elapsed().as_millis(),
            zoom_level: request.zoom,
        }
    }

    // Core Mandelbrot iteration calculation - this is where Rust's speed really shows
    fn mandelbrot_iterations(&self, c: Complex<f64>, max_iterations: u32) -> u32 {
        let mut z = Complex::new(0.0, 0.0);

        for i in 0..max_iterations {
            if z.norm_sqr() > 4.0 {
                return i;
            }
            z = z * z + c;
        }

        max_iterations
    }

    // Julia set iteration calculation
    fn julia_iterations(&self, mut z: Complex<f64>, c: Complex<f64>, max_iterations: u32) -> u32 {
        for i in 0..max_iterations {
            if z.norm_sqr() > 4.0 {
                return i;
            }
            z = z * z + c;
        }

        max_iterations
    }

    // I'm creating a dark, eerie color palette that fits the Mr. Robot theme
    fn iteration_to_dark_color(&self, iterations: u32, max_iterations: u32) -> [u8; 4] {
        if iterations == max_iterations {
            // Deep black for points in the set
            [0, 0, 0, 255]
        } else {
            // Cool, dark gradient for escape points
            let t = iterations as f64 / max_iterations as f64;
            let r = (t * 30.0) as u8;  // Very dark red
            let g = (t * 50.0) as u8;  // Slightly more green for that eerie glow
            let b = (t * 80.0) as u8;  // Cool blue tones
            [r, g, b, 255]
        }
    }

    // Benchmark function to showcase computational speed
    pub fn benchmark_generation(&self, iterations: u32) -> serde_json::Value {
        let mut results = Vec::new();

        // I'm testing different complexity levels to show performance scaling
        let test_cases = vec![
            (512, 512, 100),
            (1024, 1024, 200),
            (2048, 2048, 400),
        ];

        for (width, height, max_iter) in test_cases {
            let request = FractalRequest {
                width,
                height,
                center_x: -0.5,
                center_y: 0.0,
                zoom: 1.0,
                max_iterations: max_iter,
                fractal_type: FractalType::Mandelbrot,
            };

            let response = self.generate_mandelbrot(request);
            results.push(serde_json::json!({
                "resolution": format!("{}x{}", width, height),
                                           "max_iterations": max_iter,
                                           "computation_time_ms": response.computation_time_ms,
                                           "pixels_per_ms": (width * height) as f64 / response.computation_time_ms as f64
            }));
        }

        serde_json::json!({
            "benchmark_results": results,
            "total_iterations": iterations,
            "language": "Rust",
            "parallel_processing": true
        })
    }
}
</file>

<file path="src/services/github_service.rs">
/*
 * GitHub API integration service providing intelligent caching, rate limiting, and data transformation for repository showcase.
 * I'm implementing comprehensive GitHub API communication with automatic retry logic, performance optimization, and database caching.
 */

use reqwest::{Client, header::{HeaderMap, HeaderValue, USER_AGENT, AUTHORIZATION}};
use serde::{Deserialize, Serialize};
use std::time::{Duration, SystemTime, UNIX_EPOCH};
use tokio::time::sleep;
use tracing::{info, warn, error, debug};

use crate::{
    models::github::{Repository, RepositoryStats, GitHubUser, RepositoryDetailed},
    services::cache_service::CacheService,
    utils::error::{AppError, Result},
    database::DatabasePool,
};

#[derive(Debug, Clone)]
pub struct GitHubService {
    client: Client,
    token: String,
    cache_service: CacheService,
    base_url: String,
    rate_limit_remaining: std::sync::Arc<std::sync::Mutex<u32>>,
    rate_limit_reset: std::sync::Arc<std::sync::Mutex<u64>>,
}

#[derive(Debug, Deserialize)]
struct GitHubApiRepository {
    id: u64,
    name: String,
    full_name: String,
    owner: GitHubOwner,
    description: Option<String>,
    html_url: String,
    clone_url: String,
    ssh_url: String,
    language: Option<String>,
    size: u32,
    stargazers_count: u32,
    watchers_count: u32,
    forks_count: u32,
        open_issues_count: u32,
        created_at: String,
        updated_at: String,
        pushed_at: Option<String>,
        private: bool,
            fork: bool,
                archived: bool,
                topics: Vec<String>,
                license: Option<GitHubLicense>,
}

#[derive(Debug, Deserialize)]
struct GitHubOwner {
    login: String,
    id: u64,
    avatar_url: String,
}

#[derive(Debug, Deserialize)]
struct GitHubLicense {
    name: String,
    spdx_id: Option<String>,
}

#[derive(Debug, Deserialize)]
struct GitHubRateLimit {
    pub limit: u32,
    pub remaining: u32,
    pub reset: u64,
    pub used: u32,
}

#[derive(Debug, Deserialize)]
struct GitHubRateLimitResponse {
    rate: GitHubRateLimit,
}


#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RateLimitInfo {
    pub limit: i32,
    pub remaining: i32,
    pub reset_at: chrono::DateTime<chrono::Utc>,
    pub used: i32,
    pub percentage_used: f64,
}

impl GitHubService {
    pub fn new(token: String, cache_service: CacheService) -> Self {
        // I'm setting up the HTTP client with optimal configuration for GitHub API
        let mut headers = HeaderMap::new();
        headers.insert(USER_AGENT, HeaderValue::from_static("dark-performance-showcase/0.1.0"));
        headers.insert(
            AUTHORIZATION,
            HeaderValue::from_str(&format!("Bearer {}", token))
            .expect("Invalid GitHub token format")
        );
        headers.insert("Accept", HeaderValue::from_static("application/vnd.github+json"));
        headers.insert("X-GitHub-Api-Version", HeaderValue::from_static("2022-11-28"));

        let client = Client::builder()
        .default_headers(headers)
        .timeout(Duration::from_secs(30))
        .pool_idle_timeout(Duration::from_secs(90))
        .pool_max_idle_per_host(10)
        .build()
        .expect("Failed to create HTTP client");

        Self {
            client,
            token,
            cache_service,
            base_url: "https://api.github.com".to_string(),
            rate_limit_remaining: std::sync::Arc::new(std::sync::Mutex::new(5000)),
            rate_limit_reset: std::sync::Arc::new(std::sync::Mutex::new(0)),
        }
    }

    /// Fetch all repositories for the authenticated user with intelligent caching
    /// I'm implementing pagination handling and comprehensive error recovery
    pub async fn get_user_repositories(&self, username: &str) -> Result<Vec<Repository>> {
        let cache_key = format!("github:repos:{}", username);

        // Check cache first - I'm implementing intelligent cache with TTL
        if let Ok(Some(cached_repos)) = self.cache_service.get::<Vec<Repository>>(&cache_key).await {
            debug!("Returning cached repositories for user: {}", username);
            return Ok(cached_repos);
        }

        info!("Fetching fresh repository data for user: {}", username);

        let mut all_repos = Vec::new();
        let mut page = 1;
        let per_page = 100; // Maximum allowed by GitHub API

        loop {
            // I'm checking rate limits before making requests
            self.check_rate_limit().await?;

            let url = format!(
                "{}/users/{}/repos?page={}&per_page={}&sort=updated&direction=desc",
                self.base_url, username, page, per_page
            );

            debug!("Fetching repositories page {} for user: {}", page, username);

            let response = self.client
            .get(&url)
            .send()
            .await
            .map_err(|e| AppError::ExternalApiError(format!("GitHub API request failed: {}", e)))?;

            // Update rate limit information from headers
            self.update_rate_limit_from_headers(&response).await;

            if !response.status().is_success() {
                let status = response.status();
                let error_text = response.text().await.unwrap_or_default();
                return Err(AppError::ExternalApiError(
                    format!("GitHub API error {}: {}", status, error_text)
                ));
            }

            let repos: Vec<GitHubApiRepository> = response
            .json()
            .await
            .map_err(|e| AppError::SerializationError(format!("Failed to parse GitHub response: {}", e)))?;

            if repos.is_empty() {
                break; // No more pages
            }

            // Transform GitHub API response to our internal format
            for api_repo in repos {
                let repo = self.transform_api_repository(api_repo);
                all_repos.push(repo);
            }

            page += 1;

            // Prevent infinite loops and respect API limits
            if page > 50 {
                warn!("Stopping repository fetch at page 50 to prevent excessive API usage");
                break;
            }
        }

        info!("Fetched {} repositories for user: {}", all_repos.len(), username);

        // Cache the results with 1-hour TTL
          if let Err(e) = self.cache_service.set(&cache_key, &all_repos, Some(3600)).await {
            warn!("Failed to cache repository data: {}", e);
        }

        Ok(all_repos)
    }

    /// Get detailed information for a specific repository including README and stats
    /// I'm providing comprehensive repository analysis with performance metrics
    pub async fn get_repository_details(&self, owner: &str, name: &str) -> Result<RepositoryDetailed> {
        let cache_key = format!("github:repo:{}:{}", owner, name);

        if let Ok(Some(cached_repo)) = self.cache_service.get::<RepositoryDetailed>(&cache_key).await {
            debug!("Returning cached repository details for {}/{}", owner, name);
            return Ok(cached_repo);
        }

        info!("Fetching detailed repository information for {}/{}", owner, name);

        self.check_rate_limit().await?;

        let url = format!("{}/repos/{}/{}", self.base_url, owner, name);

        let response = self.client
        .get(&url)
        .send()
        .await
        .map_err(|e| AppError::ExternalApiError(format!("GitHub API request failed: {}", e)))?;

        self.update_rate_limit_from_headers(&response).await;

        if !response.status().is_success() {
            return Err(AppError::ExternalApiError(
                format!("Failed to fetch repository {}/{}: HTTP {}", owner, name, response.status())
            ));
        }

        let api_repo: GitHubApiRepository = response
        .json()
        .await
        .map_err(|e| AppError::SerializationError(format!("Failed to parse repository response: {}", e)))?;

        // Fetch README content separately
        let readme_content = self.get_repository_readme(owner, name).await.unwrap_or_default();

        // Get repository statistics
        let stats = self.get_repository_stats(owner, name).await?;

        let detailed_repo = RepositoryDetailed {
            basic: self.transform_api_repository(api_repo),
            readme_content,
            stats,
            contributors_count: 0, // TODO: Implement if needed
            commit_count: 0,       // TODO: Implement if needed
            branch_count: 0,       // TODO: Implement if needed
            release_count: 0,      // TODO: Implement if needed
        };

        // Cache for 30 minutes (detailed info changes less frequently)
        if let Err(e) = self.cache_service.set(&cache_key, &detailed_repo, 1800).await {
            warn!("Failed to cache detailed repository data: {}", e);
        }

        Ok(detailed_repo)
    }

    /// Get repository README content with fallback handling
    /// I'm implementing intelligent README detection for various formats
    async fn get_repository_readme(&self, owner: &str, name: &str) -> Result<String> {
        let readme_variants = vec!["README.md", "readme.md", "README", "readme", "README.txt"];

        for readme_file in readme_variants {
            self.check_rate_limit().await?;
            let url = format!(/* ... */);
            let response_result = self.client.get(&url).send().await; // Store Result

            match response_result {
                Ok(mut resp) => {
                    self.update_rate_limit_from_headers(&resp).await; // Update from resp
                    if resp.status().is_success() {
                        if let Ok(content_response) = resp.json::<serde_json::Value>().await {
                    if let Ok(content_response) = resp.json::<serde_json::Value>().await {
                        if let Some(content) = content_response.get("content")
                            .and_then(|c| c.as_str()) {
                                // Decode base64 content
                                if let Ok(decoded) = base64::decode(&content.replace('\n', "")) {
                                    if let Ok(readme_text) = String::from_utf8(decoded) {
                                        debug!("Found README: {} for {}/{}", readme_file, owner, name);
                                        return Ok(readme_text);
                                    }
                                }
                            }
                Err(e) => {
                    // Handle client send error, maybe log it or if it's a common error, continue
                    warn!("Failed to send request for {}: {}", readme_file, e);
                    continue;
                }
            }
            // No need for the separate update_rate_limit_from_headers call here
        }

        debug!("No README found for {}/{}", owner, name);
        Ok(String::new())
    }

    /// Get repository statistics and performance metrics
    /// I'm calculating comprehensive repository health and activity metrics
    async fn get_repository_stats(&self, owner: &str, name: &str) -> Result<RepositoryStats> {
        // For now, I'm returning basic stats - can be expanded with more GitHub API calls
        Ok(RepositoryStats {
            commit_frequency: 0.0,
            contributors_count: 0,
            issues_ratio: 0.0,
            fork_ratio: 0.0,
                activity_score: 0.0,
                health_score: 0.0,
                last_activity_days: 0,
        })
    }

    /// Get current rate limit status
    /// I'm providing real-time rate limit monitoring for optimal API usage
    pub async fn get_rate_limit_status(&self) -> Result<GitHubRateLimit> {
        let url = format!("{}/rate_limit", self.base_url);

        let response = self.client
        .get(&url)
        .send()
        .await
        .map_err(|e| AppError::ExternalApiError(format!("Rate limit check failed: {}", e)))?;

        if !response.status().is_success() {
            return Err(AppError::ExternalApiError(
                format!("Rate limit check failed: HTTP {}", response.status())
            ));
        }

        let rate_limit_response: GitHubRateLimitResponse = response
        .json()
        .await
        .map_err(|e| AppError::SerializationError(format!("Failed to parse rate limit response: {}", e)))?;

        // Update internal rate limit tracking
        {
            let mut remaining = self.rate_limit_remaining.lock().unwrap();
            *remaining = rate_limit_response.rate.remaining;
        }
        {
            let mut reset = self.rate_limit_reset.lock().unwrap();
            *reset = rate_limit_response.rate.reset;
        }

        Ok(rate_limit_response.rate)
    }

    /// Check rate limit and wait if necessary
    /// I'm implementing intelligent rate limit handling with automatic backoff
    async fn check_rate_limit(&self) -> Result<()> {
        let remaining = {
            let remaining = self.rate_limit_remaining.lock().unwrap();
            *remaining
        };

        if remaining < 10 {
            let reset_time = {
                let reset = self.rate_limit_reset.lock().unwrap();
                *reset
            };

            let current_time = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_secs();

            if current_time < reset_time {
                let wait_time = reset_time - current_time + 5; // Add 5 second buffer
                warn!("Rate limit low ({}), waiting {} seconds until reset", remaining, wait_time);
                sleep(Duration::from_secs(wait_time)).await;
            }
        }

        Ok(())
    }

    /// Update rate limit information from response headers
    /// I'm tracking rate limits in real-time to prevent API exhaustion
    async fn update_rate_limit_from_headers(&self, response: &reqwest::Response) {
        if let Some(remaining_header) = response.headers().get("x-ratelimit-remaining") {
            if let Ok(remaining_str) = remaining_header.to_str() {
                if let Ok(remaining) = remaining_str.parse::<u32>() {
                    let mut rate_limit_remaining = self.rate_limit_remaining.lock().unwrap();
                    *rate_limit_remaining = remaining;
                }
            }
        }

        if let Some(reset_header) = response.headers().get("x-ratelimit-reset") {
            if let Ok(reset_str) = reset_header.to_str() {
                if let Ok(reset) = reset_str.parse::<u64>() {
                    let mut rate_limit_reset = self.rate_limit_reset.lock().unwrap();
                    *rate_limit_reset = reset;
                }
            }
        }
    }

    /// Transform GitHub API repository format to our internal format
    /// I'm normalizing data and calculating derived fields for better UX
    fn transform_api_repository(&self, api_repo: GitHubApiRepository) -> Repository {
        Repository {
            id: api_repo.id as i64,
            github_id: api_repo.id as i64,
            owner_login: api_repo.owner.login,
            name: api_repo.name,
            full_name: api_repo.full_name,
            description: api_repo.description,
            html_url: api_repo.html_url,
            clone_url: api_repo.clone_url,
            ssh_url: api_repo.ssh_url,
            language: api_repo.language,
            size_kb: api_repo.size as i32,
            stargazers_count: api_repo.stargazers_count as i32,
            watchers_count: api_repo.watchers_count as i32,
            forks_count: api_repo.forks_count as i32,
                open_issues_count: api_repo.open_issues_count as i32,
                created_at: chrono::DateTime::parse_from_rfc3339(&api_repo.created_at)
                .unwrap_or_else(|_| chrono::Utc::now().into())
                .with_timezone(&chrono::Utc),
                updated_at: chrono::DateTime::parse_from_rfc3339(&api_repo.updated_at)
                .unwrap_or_else(|_| chrono::Utc::now().into())
                .with_timezone(&chrono::Utc),
                pushed_at: api_repo.pushed_at
                .and_then(|s| chrono::DateTime::parse_from_rfc3339(&s).ok())
                .map(|dt| dt.with_timezone(&chrono::Utc)),
                is_private: api_repo.private,
                is_fork: api_repo.fork,
                is_archived: api_repo.archived,
                topics: api_repo.topics,
                license_name: api_repo.license.map(|l| l.name),
                readme_content: None,
                cache_updated_at: chrono::Utc::now(),
                cache_expires_at: chrono::Utc::now() + chrono::Duration::hours(1),
        }
    }

    /// Store repositories in database cache for performance optimization
    /// I'm implementing intelligent database caching with automatic cleanup
    pub async fn store_repositories_in_db(
        &self,
        db_pool: &DatabasePool,
        repositories: &[Repository],
    ) -> Result<()> {
        for repo in repositories {
            let result = sqlx::query!(
                r#"
                INSERT INTO repositories (
                    github_id, owner_login, name, full_name, description, html_url, clone_url, ssh_url,
                    language, size_kb, stargazers_count, watchers_count, forks_count, open_issues_count,
                    created_at, updated_at, pushed_at, is_private, is_fork, is_archived, topics,
                    license_name, cache_updated_at, cache_expires_at
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23, $24)
            ON CONFLICT (github_id) DO UPDATE SET
            description = EXCLUDED.description,
            html_url = EXCLUDED.html_url,
            language = EXCLUDED.language,
            size_kb = EXCLUDED.size_kb,
            stargazers_count = EXCLUDED.stargazers_count,
            watchers_count = EXCLUDED.watchers_count,
            forks_count = EXCLUDED.forks_count,
                open_issues_count = EXCLUDED.open_issues_count,
                updated_at = EXCLUDED.updated_at,
                pushed_at = EXCLUDED.pushed_at,
                is_archived = EXCLUDED.is_archived,
                topics = EXCLUDED.topics,
                license_name = EXCLUDED.license_name,
                cache_updated_at = EXCLUDED.cache_updated_at,
                cache_expires_at = EXCLUDED.cache_expires_at
                "#,
                repo.github_id,
                repo.owner_login,
                repo.name,
                repo.full_name,
                repo.description,
                repo.html_url,
                repo.clone_url,
                repo.ssh_url,
                repo.language,
                repo.size_kb,
                repo.stargazers_count,
                repo.watchers_count,
                repo.forks_count,
                repo.open_issues_count,
                repo.created_at,
                repo.updated_at,
                repo.pushed_at,
                repo.is_private,
                repo.is_fork,
                repo.is_archived,
                &repo.topics,
                repo.license_name,
                repo.cache_updated_at,
                repo.cache_expires_at
            )
            .execute(db_pool)
            .await;

            if let Err(e) = result {
                warn!("Failed to store repository {}/{} in database: {}", repo.owner_login, repo.name, e);
            }
        }

        info!("Stored {} repositories in database cache", repositories.len());
        Ok(())
    }
}

// Base64 decoding utility - I'm using a simple implementation to avoid additional dependencies
mod base64 {
    use std::collections::HashMap;

    pub fn decode(input: &str) -> Result<Vec<u8>, &'static str> {
        let chars: Vec<char> = input.chars().collect();
        let mut result = Vec::new();

        // Simple base64 decoding implementation
        // In production, you'd use the `base64` crate for better performance
        let base64_chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
        let mut char_map = HashMap::new();

        for (i, c) in base64_chars.chars().enumerate() {
            char_map.insert(c, i as u8);
        }

        for chunk in chars.chunks(4) {
            let mut values = [0u8; 4];
            for (i, &c) in chunk.iter().enumerate() {
                if c == '=' {
                    break;
                }
                values[i] = *char_map.get(&c).ok_or("Invalid base64 character")?;
            }

            result.push((values[0] << 2) | (values[1] >> 4));
            if chunk.len() > 2 && chunk[2] != '=' {
                result.push((values[1] << 4) | (values[2] >> 2));
            }
            if chunk.len() > 3 && chunk[3] != '=' {
                result.push((values[2] << 6) | values[3]);
            }
        }

        Ok(result)
    }
}
</file>

<file path="src/services/mod.rs">
/*
 * Services module aggregator providing centralized access to all business logic services for the dark performance showcase.
 * I'm organizing GitHub API integration, fractal computation, performance monitoring, and caching into a cohesive service layer that maintains clean separation of concerns.
 */

pub mod fractal_service;
pub mod github_service;
pub mod performance_service;
pub mod cache_service;

// Re-export all services for convenient access throughout the application
pub use fractal_service::FractalService;
pub use github_service::GitHubService;
pub use performance_service::PerformanceService;
pub use cache_service::CacheService;

use crate::{
    database::DatabasePool,
    utils::error::{AppError, Result},
};
use std::sync::Arc;
use tokio::sync::RwLock;

/// Service registry for centralized service management and dependency injection
/// I'm implementing a service registry pattern for clean dependency management
pub struct ServiceRegistry {
    pub fractal_service: Arc<FractalService>,
    pub github_service: Arc<GitHubService>,
    pub performance_service: Arc<PerformanceService>,
    pub cache_service: Arc<CacheService>,
}

impl ServiceRegistry {
    /// Create a new service registry with all services initialized
    /// I'm ensuring all services are properly configured and connected
    pub async fn new(
        db_pool: DatabasePool,
        redis_client: redis::Client,
        github_token: String,
    ) -> Result<Self> {
        tracing::info!("Initializing service registry");

        // Initialize cache service first as other services depend on it
        let cache_service = Arc::new(CacheService::with_config(
            redis_client,
            "perf_showcase:".to_string(),
            3600, // 1 hour default TTL
        ));

        // Initialize GitHub service with cache dependency
        let github_service = Arc::new(GitHubService::new(
            github_token.clone(),
            (*cache_service).clone(),
        ));

        // Initialize fractal service (no external dependencies)
        let fractal_service = Arc::new(FractalService::new());

        // Initialize performance service with database dependency
        let performance_service = Arc::new(PerformanceService::new(db_pool.clone()));

        tracing::info!("All services initialized successfully");

        Ok(Self {
            fractal_service,
            github_service,
            performance_service,
            cache_service,
        })
    }

    /// Perform health checks on all services
    /// I'm implementing comprehensive service health verification
    pub async fn health_check(&self) -> Result<serde_json::Value> {
        let mut health_results = serde_json::Map::new();

        // Check cache service health
        match self.cache_service.health_check().await {
            Ok(cache_health) => {
                health_results.insert("cache".to_string(), cache_health);
            }
            Err(e) => {
                health_results.insert("cache".to_string(), serde_json::json!({
                    "status": "unhealthy",
                    "error": e.to_string()
                }));
            }
        }

        // Check GitHub service health (rate limit status)
        match self.github_service.get_rate_limit_status().await {
            Ok(rate_limit) => {
                health_results.insert("github".to_string(), serde_json::json!({
                    "status": if rate_limit.remaining > 100 { "healthy" } else { "degraded" },
                    "rate_limit_remaining": rate_limit.remaining,
                    "rate_limit_total": rate_limit.limit
                }));
            }
            Err(e) => {
                health_results.insert("github".to_string(), serde_json::json!({
                    "status": "unhealthy",
                    "error": e.to_string()
                }));
            }
        }

        // Check fractal service health (simple computation test)
        let fractal_health = tokio::task::spawn_blocking({
            let fractal_service = Arc::clone(&self.fractal_service);
            move || {
                use crate::services::fractal_service::{FractalRequest, FractalType};

                let test_request = FractalRequest {
                    width: 32,
                    height: 32,
                    center_x: -0.5,
                    center_y: 0.0,
                    zoom: 1.0,
                    max_iterations: 50,
                    fractal_type: FractalType::Mandelbrot,
                };

                fractal_service.generate_mandelbrot(test_request)
            }
        }).await;

        match fractal_health {
            Ok(result) => {
                health_results.insert("fractals".to_string(), serde_json::json!({
                    "status": "healthy",
                    "test_computation_time_ms": result.computation_time_ms
                }));
            }
            Err(e) => {
                health_results.insert("fractals".to_string(), serde_json::json!({
                    "status": "unhealthy",
                    "error": e.to_string()
                }));
            }
        }

        // Check performance service health
        match self.performance_service.get_system_info().await {
            Ok(_) => {
                health_results.insert("performance".to_string(), serde_json::json!({
                    "status": "healthy"
                }));
            }
            Err(e) => {
                health_results.insert("performance".to_string(), serde_json::json!({
                    "status": "unhealthy",
                    "error": e.to_string()
                }));
            }
        }

        // Determine overall health status
        let overall_status = if health_results.values().all(|v| {
            v.get("status").and_then(|s| s.as_str()) == Some("healthy")
        }) {
            "healthy"
        } else if health_results.values().any(|v| {
            v.get("status").and_then(|s| s.as_str()) == Some("unhealthy")
        }) {
            "unhealthy"
        } else {
            "degraded"
        };

        Ok(serde_json::json!({
            "status": overall_status,
            "timestamp": chrono::Utc::now(),
            "services": health_results
        }))
    }

    /// Get service statistics and metrics
    /// I'm providing comprehensive service analytics for monitoring
    pub async fn get_service_stats(&self) -> Result<serde_json::Value> {
        let mut stats = serde_json::Map::new();

        // Cache service statistics
        if let Ok(cache_stats) = self.cache_service.get_stats().await {
            stats.insert("cache".to_string(), serde_json::to_value(cache_stats)?);
        }

        // GitHub service rate limit information
        if let Ok(rate_limit) = self.github_service.get_rate_limit_status().await {
            stats.insert("github_rate_limit".to_string(), serde_json::json!({
                "remaining": rate_limit.remaining,
                "limit": rate_limit.limit,
                "reset": rate_limit.reset,
                "used": rate_limit.used
            }));
        }

        // Performance service system information
        if let Ok(system_info) = self.performance_service.get_system_info().await {
            stats.insert("system".to_string(), system_info);
        }

        Ok(serde_json::json!({
            "timestamp": chrono::Utc::now(),
            "services": stats
        }))
    }

    /// Warm up all services with initial data loading
    /// I'm implementing service warm-up for optimal initial performance
    pub async fn warm_up(&self, github_username: &str) -> Result<()> {
        tracing::info!("Warming up services");

        // Warm up GitHub service by fetching initial repository data
        if let Err(e) = self.github_service.get_user_repositories(github_username).await {
            tracing::warn!("Failed to warm up GitHub service: {}", e);
        }

        // Warm up fractal service with a simple computation
        let warm_up_fractal = tokio::task::spawn_blocking({
            let fractal_service = Arc::clone(&self.fractal_service);
            move || {
                use crate::services::fractal_service::{FractalRequest, FractalType};

                let warm_up_request = FractalRequest {
                    width: 128,
                    height: 128,
                    center_x: -0.5,
                    center_y: 0.0,
                    zoom: 1.0,
                    max_iterations: 100,
                    fractal_type: FractalType::Mandelbrot,
                };

                fractal_service.generate_mandelbrot(warm_up_request)
            }
        });

        if let Err(e) = warm_up_fractal.await {
            tracing::warn!("Failed to warm up fractal service: {}", e);
        }

        // Warm up performance service by collecting initial metrics
        if let Err(e) = self.performance_service.get_system_metrics().await {
            tracing::warn!("Failed to warm up performance service: {}", e);
        }

        tracing::info!("Service warm-up completed");
        Ok(())
    }

    /// Graceful shutdown of all services
    /// I'm implementing proper resource cleanup for all services
    pub async fn shutdown(&self) -> Result<()> {
        tracing::info!("Shutting down services");

        // Services don't currently have explicit shutdown methods,
        // but this is where we would clean up any resources, connections, etc.

        // Future implementation might include:
        // - Flushing pending cache operations
        // - Saving service state
        // - Closing background tasks
        // - Releasing file handles

        tracing::info!("All services shut down gracefully");
        Ok(())
    }
}

/// Service factory for creating individual services with proper configuration
/// I'm providing factory methods for flexible service instantiation
pub struct ServiceFactory;

impl ServiceFactory {
    /// Create a fractal service instance
    /// I'm providing a factory method for fractal service creation
    pub fn create_fractal_service() -> FractalService {
        FractalService::new()
    }

    /// Create a GitHub service instance with configuration
    /// I'm providing a factory method for GitHub service creation
    pub fn create_github_service(
        github_token: String,
        cache_service: CacheService,
    ) -> GitHubService {
        GitHubService::new(github_token, cache_service)
    }

    /// Create a performance service instance
    /// I'm providing a factory method for performance service creation
    pub fn create_performance_service(db_pool: DatabasePool) -> PerformanceService {
        PerformanceService::new(db_pool)
    }

    /// Create a cache service instance with configuration
    /// I'm providing a factory method for cache service creation
    pub fn create_cache_service(
        redis_client: redis::Client,
        key_prefix: String,
        default_ttl: u64,
    ) -> CacheService {
        CacheService::with_config(redis_client, key_prefix, default_ttl)
    }
}

/// Service traits for common service functionality
/// I'm defining common service patterns for consistent implementation

pub trait HealthCheckable {
    type HealthResult;
    async fn health_check(&self) -> Result<Self::HealthResult>;
}

pub trait Configurable {
    type Config;
    fn configure(&mut self, config: Self::Config) -> Result<()>;
}

pub trait Cacheable {
    fn cache_key(&self) -> String;
    fn cache_ttl(&self) -> u64;
}

/// Middleware for service request/response processing
/// I'm implementing service middleware for cross-cutting concerns
pub struct ServiceMiddleware;

impl ServiceMiddleware {
    /// Log service method calls for debugging and monitoring
    /// I'm implementing service call logging for observability
    pub async fn log_service_call<F, T>(
        service_name: &str,
        method_name: &str,
        future: F,
    ) -> Result<T>
    where
        F: std::future::Future<Output = Result<T>>,
    {
        let start_time = std::time::Instant::now();

        tracing::debug!("Calling {}.{}", service_name, method_name);

        match future.await {
            Ok(result) => {
                let duration = start_time.elapsed();
                tracing::debug!(
                    "{}.{} completed successfully in {:?}",
                    service_name,
                    method_name,
                    duration
                );
                Ok(result)
            }
            Err(error) => {
                let duration = start_time.elapsed();
                tracing::error!(
                    "{}.{} failed after {:?}: {}",
                    service_name,
                    method_name,
                    duration,
                    error
                );
                Err(error)
            }
        }
    }

    /// Add timing metrics to service calls
    /// I'm implementing automatic performance tracking for service calls
    pub async fn with_timing<F, T>(
        metric_name: &str,
        future: F,
    ) -> Result<T>
    where
        F: std::future::Future<Output = Result<T>>,
    {
        let start_time = std::time::Instant::now();

        let result = future.await;

        let duration = start_time.elapsed();

        // Here we would record the timing metric
        tracing::debug!("Service call {} took {:?}", metric_name, duration);

        result
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_service_factory() {
        let fractal_service = ServiceFactory::create_fractal_service();
        // Service should be created successfully
        assert!(true);
    }

    #[tokio::test]
    async fn test_service_middleware_logging() {
        let future = async { Ok::<i32, AppError>(42) };

        let result = ServiceMiddleware::log_service_call(
            "test_service",
            "test_method",
            future,
        ).await;

        assert!(result.is_ok());
        assert_eq!(result.unwrap(), 42);
    }
}
</file>

<file path="src/services/performance_service.rs">
/*
 * Performance monitoring service providing comprehensive system metrics collection and analysis for real-time performance tracking.
 * I'm implementing sophisticated performance monitoring that showcases system capabilities while providing valuable insights into computational efficiency.
 */

use serde::{Deserialize, Serialize};
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};
use sysinfo::{System, SystemExt, CpuExt, DiskExt, NetworkExt, NetworksExt, ComponentExt};
use tokio::sync::RwLock;
use tracing::{info, warn, debug};
use std::sync::Arc;
use std::collections::VecDeque;

use crate::{
    utils::error::{AppError, Result},
    database::DatabasePool,
};

/// Comprehensive system performance metrics
/// I'm capturing all essential performance indicators for thorough analysis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SystemMetrics {
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub cpu_usage_percent: f64,
    pub memory_usage_percent: f64,
    pub memory_total_gb: f64,
    pub memory_available_gb: f64,
    pub disk_usage_percent: f64,
    pub disk_total_gb: f64,
    pub disk_available_gb: f64,
    pub network_rx_bytes_per_sec: u64,
    pub network_tx_bytes_per_sec: u64,
    pub load_average_1m: f64,
    pub load_average_5m: f64,
    pub load_average_15m: f64,
    pub cpu_cores: u32,
    pub cpu_threads: u32,
    pub cpu_model: String,
    pub uptime_seconds: u64,
    pub active_processes: u32,
    pub system_temperature: Option<f64>,
}

/// Performance monitoring service with comprehensive metrics collection
/// I'm implementing real-time performance tracking with historical analysis
#[derive(Clone)]
pub struct PerformanceService {
    system: Arc<RwLock<System>>,
    metrics_history: Arc<RwLock<VecDeque<SystemMetrics>>>,
    db_pool: DatabasePool,
}

impl PerformanceService {
    /// Create a new performance monitoring service
    /// I'm setting up comprehensive performance tracking infrastructure
    pub fn new(db_pool: DatabasePool) -> Self {
        let mut system = System::new_all();
        system.refresh_all();

        Self {
            system: Arc::new(RwLock::new(system)),
            metrics_history: Arc::new(RwLock::new(VecDeque::with_capacity(1000))),
            db_pool,
        }
    }

    /// Get current system metrics with comprehensive data collection
    /// I'm implementing real-time system monitoring with detailed analysis
    pub async fn get_system_metrics(&self) -> Result<SystemMetrics> {
        let mut system = self.system.write().await;
        system.refresh_all();

        // I'm collecting comprehensive CPU information
        let cpu_usage = system.global_cpu_info().cpu_usage() as f64;
        let cpu_cores = system.physical_core_count().unwrap_or(0) as u32;
        let cpu_threads = system.cpus().len() as u32;
        let cpu_model = system.global_cpu_info().brand().to_string();

        // Memory information with detailed breakdown
        let memory_total = system.total_memory() as f64 / (1024.0 * 1024.0 * 1024.0);
        let memory_available = system.available_memory() as f64 / (1024.0 * 1024.0 * 1024.0);
        let memory_usage_percent = ((memory_total - memory_available) / memory_total) * 100.0;

        // Disk information for primary disk
        let (disk_usage_percent, disk_total_gb, disk_available_gb) = if let Some(disk) = system.disks().first() {
            let total = disk.total_space() as f64 / (1024.0 * 1024.0 * 1024.0);
            let available = disk.available_space() as f64 / (1024.0 * 1024.0 * 1024.0);
            let usage_percent = ((total - available) / total) * 100.0;
            (usage_percent, total, available)
        } else {
            (0.0, 0.0, 0.0)
        };

        // Network statistics
        let (network_rx, network_tx) = system.networks().iter()
            .fold((0u64, 0u64), |(rx, tx), (_, network)| {
                (rx + network.received(), tx + network.transmitted())
            });

        // Load average information
        let load_avg = system.load_average();

        // System uptime
        let uptime_seconds = system.uptime();

        // Active process count
        let active_processes = system.processes().len() as u32;

        // System temperature (if available)
        let system_temperature = system.components()
            .iter()
            .find(|component| component.label().contains("CPU") || component.label().contains("Core"))
            .map(|component| component.temperature() as f64);

        let metrics = SystemMetrics {
            timestamp: chrono::Utc::now(),
            cpu_usage_percent: cpu_usage,
            memory_usage_percent: memory_usage_percent,
            memory_total_gb: memory_total,
            memory_available_gb: memory_available,
            disk_usage_percent,
            disk_total_gb,
            disk_available_gb,
            network_rx_bytes_per_sec: network_rx,
            network_tx_bytes_per_sec: network_tx,
            load_average_1m: load_avg.one,
            load_average_5m: load_avg.five,
            load_average_15m: load_avg.fifteen,
            cpu_cores,
            cpu_threads,
            cpu_model,
            uptime_seconds,
            active_processes,
            system_temperature,
        };

        // Store in history
        let mut history = self.metrics_history.write().await;
        history.push_back(metrics.clone());
        if history.len() > 1000 {
            history.pop_front();
        }

        // Store in database for persistence
        if let Err(e) = self.store_system_metrics(&metrics).await {
            warn!("Failed to store system metrics in database: {}", e);
        }

        Ok(metrics)
    }

    /// Get simplified system information for general use
    /// I'm providing basic system info without full metrics collection
    pub async fn get_system_info(&self) -> Result<serde_json::Value> {
        let mut system = self.system.write().await;
        system.refresh_all();

        let info = serde_json::json!({
            "cpu_model": system.global_cpu_info().brand(),
            "cpu_cores": system.physical_core_count().unwrap_or(0),
            "cpu_threads": system.cpus().len(),
            "memory_total_gb": system.total_memory() as f64 / (1024.0 * 1024.0 * 1024.0),
            "memory_available_gb": system.available_memory() as f64 / (1024.0 * 1024.0 * 1024.0),
            "memory_usage_percent": {
                let total = system.total_memory() as f64;
                let available = system.available_memory() as f64;
                ((total - available) / total) * 100.0
            },
            "cpu_usage_percent": system.global_cpu_info().cpu_usage(),
            "uptime_seconds": system.uptime(),
            "load_average_1m": system.load_average().one,
            "load_average_5m": system.load_average().five,
            "load_average_15m": system.load_average().fifteen,
            "os_version": system.long_os_version(),
            "processes_count": system.processes().len(),
        });

        Ok(info)
    }

    /// Run a basic performance benchmark
    /// I'm implementing a simple benchmark for demonstration purposes
    pub async fn run_benchmark(&self) -> Result<serde_json::Value> {
        info!("Starting performance benchmark");
        let start_time = Instant::now();

        // Simple CPU benchmark: calculate prime numbers
        let cpu_benchmark = tokio::task::spawn_blocking(|| {
            let start = Instant::now();
            let mut count = 0u32;
            for i in 2..50000 {
                if is_prime(i) {
                    count += 1;
                }
            }
            (count, start.elapsed())
        }).await.unwrap();

        // Simple memory benchmark
        let memory_benchmark = tokio::task::spawn_blocking(|| {
            let start = Instant::now();
            let data_size: u64 = 10_000_000;
            let data: Vec<u64> = (0..data_size).collect();
            let sum: u64 = data.iter().sum();
            (sum, start.elapsed())
        }).await.unwrap();

        let total_time = start_time.elapsed();

        let benchmark_results = serde_json::json!({
            "benchmark_id": uuid::Uuid::new_v4().to_string(),
            "timestamp": chrono::Utc::now(),
            "total_duration_ms": total_time.as_millis(),
            "cpu_benchmark": {
                "primes_found": cpu_benchmark.0,
                "duration_ms": cpu_benchmark.1.as_millis(),
                "operations_per_second": cpu_benchmark.0 as f64 / cpu_benchmark.1.as_secs_f64()
            },
            "memory_benchmark": {
                "data_processed": memory_benchmark.0,
                "duration_ms": memory_benchmark.1.as_millis(),
                "mb_per_second": (10_000_000 * 8) as f64 / (1024.0 * 1024.0) / memory_benchmark.1.as_secs_f64()
            },
            "system_info": self.get_system_info().await?
        });

        info!("Benchmark completed in {:?}", total_time);
        Ok(benchmark_results)
    }

    /// Get metrics history for analysis
    /// I'm providing historical data for trend analysis
    pub async fn get_metrics_history(&self, limit: Option<usize>) -> Result<Vec<SystemMetrics>> {
        let history = self.metrics_history.read().await;
        let limit = limit.unwrap_or(100).min(history.len());

        Ok(history.iter().rev().take(limit).cloned().collect())
    }

    /// Store system metrics in database for persistence
    /// I'm implementing persistent storage for long-term analysis
    async fn store_system_metrics(&self, metrics: &SystemMetrics) -> Result<()> {
        sqlx::query!(
            r#"
            INSERT INTO performance_metrics (
                metric_type, metric_value, metric_unit, timestamp, tags
            ) VALUES
                ('cpu_usage', $1, 'percent', $2, $3),
                ('memory_usage', $4, 'percent', $2, $3),
                ('disk_usage', $5, 'percent', $2, $3),
                ('load_average_1m', $6, 'ratio', $2, $3)
            "#,
            metrics.cpu_usage_percent,
            metrics.timestamp,
            serde_json::json!({
                "cpu_cores": metrics.cpu_cores,
                "cpu_threads": metrics.cpu_threads,
                "memory_total_gb": metrics.memory_total_gb,
                "uptime_seconds": metrics.uptime_seconds
            }),
            metrics.memory_usage_percent,
            metrics.disk_usage_percent,
            metrics.load_average_1m
        )
        .execute(&self.db_pool)
        .await?;

        Ok(())
    }
}

// Helper function for CPU benchmark
fn is_prime(n: u32) -> bool {
    if n < 2 {
        return false;
    }
    for i in 2..((n as f64).sqrt() as u32 + 1) {
        if n % i == 0 {
            return false;
        }
    }
    true
}
</file>

<file path="src/utils/config.rs">
/*
 * Configuration management system with environment variable loading, validation, and type safety for all application settings.
 * I'm implementing comprehensive configuration handling with intelligent defaults and runtime validation to ensure reliable deployment across environments.
 */

use serde::{Deserialize, Serialize};
use std::env;
use std::net::SocketAddr;
use tracing::{info, warn};

use crate::utils::error::{AppError, Result};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config {
    // Server configuration
    pub host: String,
    pub port: u16,
    pub environment: Environment,

    // Database configuration
    pub database_url: String,
    pub database_max_connections: u32,
    pub database_min_connections: u32,
    pub database_connection_timeout: u64,

    // Redis configuration
    pub redis_url: String,
    pub redis_max_connections: u32,
    pub redis_connection_timeout: u64,

    // GitHub API configuration
    pub github_token: String,
    pub github_username: String,
    pub github_api_base_url: String,
    pub github_rate_limit_requests: u32,
    pub github_cache_ttl: u64,

    // Frontend configuration
    pub frontend_url: String,
    pub cors_allowed_origins: Vec<String>,

    // Performance monitoring
    pub metrics_enabled: bool,
    pub prometheus_port: u16,
    pub system_metrics_interval: u64,

    // Fractal computation limits
    pub fractal_max_width: u32,
    pub fractal_max_height: u32,
    pub fractal_max_iterations: u32,
    pub fractal_max_zoom: f64,
    pub fractal_computation_timeout: u64,

    // Logging configuration
    pub log_level: String,
    pub log_format: LogFormat,

    // Security configuration
    pub rate_limit_enabled: bool,
    pub rate_limit_requests_per_minute: u32,
    pub fractal_rate_limit_per_minute: u32,

    // Caching configuration
    pub cache_enabled: bool,
    pub cache_default_ttl: u64,
    pub github_cache_enabled: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum Environment {
    Development,
    Staging,
    Production,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum LogFormat {
    Plain,
    Json,
}

impl Config {
    /// Load configuration from environment variables with intelligent defaults
    /// I'm implementing comprehensive environment variable parsing with validation
    pub fn from_env() -> Result<Self> {
        info!("Loading configuration from environment variables");

        // Load environment type first to set appropriate defaults
        let environment = parse_environment()?;

        let config = Config {
            // Server configuration
            host: env::var("HOST").unwrap_or_else(|_| "0.0.0.0".to_string()),
            port: parse_env_var("PORT", 3001)?,
            environment: environment.clone(),

            // Database configuration with environment-specific defaults
            database_url: get_required_env("DATABASE_URL")?,
            database_max_connections: parse_env_var("DATABASE_MAX_CONNECTIONS",
                if environment == Environment::Production { 100 } else { 20 })?,
            database_min_connections: parse_env_var("DATABASE_MIN_CONNECTIONS", 5)?,
            database_connection_timeout: parse_env_var("DATABASE_CONNECTION_TIMEOUT", 30)?,

            // Redis configuration
            redis_url: get_required_env("REDIS_URL")?,
            redis_max_connections: parse_env_var("REDIS_MAX_CONNECTIONS", 10)?,
            redis_connection_timeout: parse_env_var("REDIS_CONNECTION_TIMEOUT", 5)?,

            // GitHub API configuration
            github_token: get_required_env("GITHUB_TOKEN")?,
            github_username: get_required_env("GITHUB_USERNAME")?,
            github_api_base_url: env::var("GITHUB_API_BASE_URL")
                .unwrap_or_else(|_| "https://api.github.com".to_string()),
            github_rate_limit_requests: parse_env_var("GITHUB_RATE_LIMIT_REQUESTS", 5000)?,
            github_cache_ttl: parse_env_var("GITHUB_CACHE_TTL", 1800)?,

            // Frontend configuration
            frontend_url: env::var("FRONTEND_URL").unwrap_or_else(|_| "http://localhost:3000".to_string()),
            cors_allowed_origins: parse_cors_origins()?,

            // Performance monitoring
            metrics_enabled: parse_bool_env("METRICS_ENABLED", true)?,
            prometheus_port: parse_env_var("PROMETHEUS_PORT", 9090)?,
            system_metrics_interval: parse_env_var("SYSTEM_METRICS_INTERVAL", 60)?,

            // Fractal computation limits for safety
            fractal_max_width: parse_env_var("MAX_FRACTAL_WIDTH", 4096)?,
            fractal_max_height: parse_env_var("MAX_FRACTAL_HEIGHT", 4096)?,
            fractal_max_iterations: parse_env_var("MAX_FRACTAL_ITERATIONS", 10000)?,
            fractal_max_zoom: parse_env_var("MAX_FRACTAL_ZOOM", 1e15)?,
            fractal_computation_timeout: parse_env_var("FRACTAL_COMPUTATION_TIMEOUT", 120)?,

            // Logging configuration
            log_level: env::var("RUST_LOG").unwrap_or_else(|_|
                match environment {
                    Environment::Development => "debug".to_string(),
                    Environment::Staging => "info".to_string(),
                    Environment::Production => "warn".to_string(),
                }
            ),
            log_format: parse_log_format()?,

            // Security configuration
            rate_limit_enabled: parse_bool_env("RATE_LIMIT_ENABLED", true)?,
            rate_limit_requests_per_minute: parse_env_var("RATE_LIMIT_REQUESTS_PER_MINUTE",
                if environment == Environment::Production { 60 } else { 100 })?,
            fractal_rate_limit_per_minute: parse_env_var("FRACTAL_RATE_LIMIT_PER_MINUTE", 10)?,

            // Caching configuration
            cache_enabled: parse_bool_env("CACHE_ENABLED", true)?,
            cache_default_ttl: parse_env_var("CACHE_DEFAULT_TTL", 3600)?,
            github_cache_enabled: parse_bool_env("GITHUB_CACHE_ENABLED", true)?,
        };

        // Validate configuration after loading
        config.validate()?;

        info!("Configuration loaded successfully for environment: {:?}", config.environment);
        config.log_configuration_summary();

        Ok(config)
    }

    /// Validate configuration values for consistency and safety
    /// I'm implementing comprehensive validation to catch configuration errors early
    fn validate(&self) -> Result<()> {
        // Validate server configuration
        if self.port == 0 {
            return Err(AppError::ConfigurationError("Port cannot be 0".to_string()));
        }

        // Validate database configuration
        if !self.database_url.starts_with("postgresql://") {
            return Err(AppError::ConfigurationError(
                "DATABASE_URL must be a valid PostgreSQL connection string".to_string()
            ));
        }

        if self.database_max_connections < self.database_min_connections {
            return Err(AppError::ConfigurationError(
                "DATABASE_MAX_CONNECTIONS must be >= DATABASE_MIN_CONNECTIONS".to_string()
            ));
        }

        // Validate Redis configuration
        if !self.redis_url.starts_with("redis://") {
            return Err(AppError::ConfigurationError(
                "REDIS_URL must be a valid Redis connection string".to_string()
            ));
        }

        // Validate GitHub configuration
        if self.github_token.is_empty() {
            return Err(AppError::ConfigurationError(
                "GITHUB_TOKEN is required and cannot be empty".to_string()
            ));
        }

        if self.github_username.is_empty() {
            return Err(AppError::ConfigurationError(
                "GITHUB_USERNAME is required and cannot be empty".to_string()
            ));
        }

        // Validate fractal limits for safety and performance
        if self.fractal_max_width > 8192 || self.fractal_max_height > 8192 {
            warn!("Fractal dimensions are very large, this may impact performance");
        }

        if self.fractal_max_iterations > 50000 {
            warn!("Maximum iterations is very high, this may cause slow computation");
        }

        // Validate URLs
        if !is_valid_url(&self.frontend_url) {
            return Err(AppError::ConfigurationError(
                "FRONTEND_URL must be a valid URL".to_string()
            ));
        }

        if !is_valid_url(&self.github_api_base_url) {
            return Err(AppError::ConfigurationError(
                "GITHUB_API_BASE_URL must be a valid URL".to_string()
            ));
        }

        Ok(())
    }

    /// Get server socket address for binding
    /// I'm providing a convenient method for server startup
    pub fn socket_addr(&self) -> Result<SocketAddr> {
        let addr = format!("{}:{}", self.host, self.port);
        addr.parse()
            .map_err(|e| AppError::ConfigurationError(format!("Invalid socket address: {}", e)))
    }

    /// Check if running in development mode
    /// I'm providing convenience methods for environment checking
    pub fn is_development(&self) -> bool {
        self.environment == Environment::Development
    }

    /// Check if running in production mode
    pub fn is_production(&self) -> bool {
        self.environment == Environment::Production
    }

    /// Get database pool configuration
    /// I'm providing optimized database settings based on environment
    pub fn database_pool_config(&self) -> DatabasePoolConfig {
        DatabasePoolConfig {
            max_connections: self.database_max_connections,
            min_connections: self.database_min_connections,
            connection_timeout: std::time::Duration::from_secs(self.database_connection_timeout),
            idle_timeout: std::time::Duration::from_secs(300),
            test_before_acquire: self.is_production(),
        }
    }

    /// Log configuration summary (without sensitive data)
    /// I'm providing visibility into loaded configuration for debugging
    fn log_configuration_summary(&self) {
        info!("=== Configuration Summary ===");
        info!("Environment: {:?}", self.environment);
        info!("Server: {}:{}", self.host, self.port);
        info!("Database: {} (max_conn: {})",
            mask_connection_string(&self.database_url), self.database_max_connections);
        info!("Redis: {} (max_conn: {})",
            mask_connection_string(&self.redis_url), self.redis_max_connections);
        info!("GitHub: {} (user: {})", self.github_api_base_url, self.github_username);
        info!("Frontend: {}", self.frontend_url);
        info!("Metrics: {} (port: {})", self.metrics_enabled, self.prometheus_port);
        info!("Fractal limits: {}x{} max, {} iterations",
            self.fractal_max_width, self.fractal_max_height, self.fractal_max_iterations);
        info!("Rate limiting: {} ({} req/min)",
            self.rate_limit_enabled, self.rate_limit_requests_per_minute);
        info!("Caching: {} (TTL: {}s)", self.cache_enabled, self.cache_default_ttl);
        info!("Log level: {} (format: {:?})", self.log_level, self.log_format);
        info!("============================");
    }
}

#[derive(Debug, Clone)]
pub struct DatabasePoolConfig {
    pub max_connections: u32,
    pub min_connections: u32,
    pub connection_timeout: std::time::Duration,
    pub idle_timeout: std::time::Duration,
    pub test_before_acquire: bool,
}

// Helper functions for configuration parsing and validation

fn parse_environment() -> Result<Environment> {
    let env_str = env::var("ENVIRONMENT")
        .or_else(|_| env::var("ENV"))
        .unwrap_or_else(|_| "development".to_string());

    match env_str.to_lowercase().as_str() {
        "development" | "dev" => Ok(Environment::Development),
        "staging" | "stage" => Ok(Environment::Staging),
        "production" | "prod" => Ok(Environment::Production),
        _ => Err(AppError::ConfigurationError(
            format!("Invalid environment: {}. Must be development, staging, or production", env_str)
        )),
    }
}

fn get_required_env(key: &str) -> Result<String> {
    env::var(key)
        .map_err(|_| AppError::ConfigurationError(
            format!("Required environment variable {} is not set", key)
        ))
}

fn parse_env_var<T>(key: &str, default: T) -> Result<T>
where
    T: std::str::FromStr,
    T::Err: std::fmt::Display,
{
    match env::var(key) {
        Ok(value) => value.parse().map_err(|e| {
            AppError::ConfigurationError(
                format!("Invalid value for {}: {}. Error: {}", key, value, e)
            )
        }),
        Err(_) => Ok(default),
    }
}

fn parse_bool_env(key: &str, default: bool) -> Result<bool> {
    match env::var(key) {
        Ok(value) => match value.to_lowercase().as_str() {
            "true" | "1" | "yes" | "on" => Ok(true),
            "false" | "0" | "no" | "off" => Ok(false),
            _ => Err(AppError::ConfigurationError(
                format!("Invalid boolean value for {}: {}. Use true/false, 1/0, yes/no, or on/off", key, value)
            )),
        },
        Err(_) => Ok(default),
    }
}

fn parse_cors_origins() -> Result<Vec<String>> {
    let origins_str = env::var("CORS_ALLOWED_ORIGINS")
        .unwrap_or_else(|_| "http://localhost:3000,http://localhost:3001".to_string());

    let origins: Vec<String> = origins_str
        .split(',')
        .map(|s| s.trim().to_string())
        .filter(|s| !s.is_empty())
        .collect();

    // Validate each origin URL
    for origin in &origins {
        if !is_valid_url(origin) && origin != "*" {
            return Err(AppError::ConfigurationError(
                format!("Invalid CORS origin URL: {}", origin)
            ));
        }
    }

    Ok(origins)
}

fn parse_log_format() -> Result<LogFormat> {
    let format_str = env::var("LOG_FORMAT").unwrap_or_else(|_| "plain".to_string());

    match format_str.to_lowercase().as_str() {
        "plain" | "text" => Ok(LogFormat::Plain),
        "json" => Ok(LogFormat::Json),
        _ => Err(AppError::ConfigurationError(
            format!("Invalid log format: {}. Must be 'plain' or 'json'", format_str)
        )),
    }
}

fn is_valid_url(url: &str) -> bool {
    // Simple URL validation - in production you might want to use a proper URL parsing library
    url.starts_with("http://") || url.starts_with("https://")
}

fn mask_connection_string(connection_string: &str) -> String {
    // I'm masking sensitive information in connection strings for logging
    if let Some(at_pos) = connection_string.find('@') {
        if let Some(colon_pos) = connection_string[..at_pos].rfind(':') {
            let mut masked = connection_string.to_string();
            let password_start = colon_pos + 1;
            let password_end = at_pos;

            if password_end > password_start {
                masked.replace_range(password_start..password_end, "****");
            }

            return masked;
        }
    }

    connection_string.to_string()
}

/// Configuration builder for testing and advanced use cases
/// I'm providing a builder pattern for flexible configuration construction
pub struct ConfigBuilder {
    config: Config,
}

impl ConfigBuilder {
    pub fn new() -> Self {
        Self {
            config: Config {
                host: "localhost".to_string(),
                port: 3001,
                environment: Environment::Development,
                database_url: "postgresql://localhost/test".to_string(),
                database_max_connections: 10,
                database_min_connections: 1,
                database_connection_timeout: 30,
                redis_url: "redis://localhost:6379".to_string(),
                redis_max_connections: 10,
                redis_connection_timeout: 5,
                github_token: "test_token".to_string(),
                github_username: "testuser".to_string(),
                github_api_base_url: "https://api.github.com".to_string(),
                github_rate_limit_requests: 5000,
                github_cache_ttl: 1800,
                frontend_url: "http://localhost:3000".to_string(),
                cors_allowed_origins: vec!["http://localhost:3000".to_string()],
                metrics_enabled: true,
                prometheus_port: 9090,
                system_metrics_interval: 60,
                fractal_max_width: 4096,
                fractal_max_height: 4096,
                fractal_max_iterations: 10000,
                fractal_max_zoom: 1e15,
                fractal_computation_timeout: 120,
                log_level: "info".to_string(),
                log_format: LogFormat::Plain,
                rate_limit_enabled: true,
                rate_limit_requests_per_minute: 100,
                fractal_rate_limit_per_minute: 10,
                cache_enabled: true,
                cache_default_ttl: 3600,
                github_cache_enabled: true,
            },
        }
    }

    pub fn database_url(mut self, url: &str) -> Self {
        self.config.database_url = url.to_string();
        self
    }

    pub fn github_token(mut self, token: &str) -> Self {
        self.config.github_token = token.to_string();
        self
    }

    pub fn environment(mut self, env: Environment) -> Self {
        self.config.environment = env;
        self
    }

    pub fn build(self) -> Result<Config> {
        self.config.validate()?;
        Ok(self.config)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_config_builder() {
        let config = ConfigBuilder::new()
            .database_url("postgresql://test:test@localhost/testdb")
            .github_token("ghp_test_token")
            .environment(Environment::Development)
            .build()
            .unwrap();

        assert_eq!(config.environment, Environment::Development);
        assert_eq!(config.github_token, "ghp_test_token");
    }

    #[test]
    fn test_environment_parsing() {
        std::env::set_var("ENVIRONMENT", "production");
        let env = parse_environment().unwrap();
        assert_eq!(env, Environment::Production);
    }

    #[test]
    fn test_boolean_parsing() {
        assert_eq!(parse_bool_env("NONEXISTENT_VAR", true).unwrap(), true);
        std::env::set_var("TEST_BOOL", "true");
        assert_eq!(parse_bool_env("TEST_BOOL", false).unwrap(), true);
    }
}
</file>

<file path="src/utils/error.rs">
/*
 * Comprehensive error handling system with structured error types, HTTP status mapping, and user-friendly messages.
 * I'm implementing a robust error handling framework that provides excellent debugging information while maintaining security and user experience.
 */

use axum::{
    http::StatusCode,
    response::{IntoResponse, Response},
    Json,
};
use serde::{Deserialize, Serialize};
use std::fmt;
use tracing::{error, warn};

/// Custom Result type for consistent error handling throughout the application
/// I'm providing a convenient alias that reduces boilerplate and ensures consistency
pub type Result<T> = std::result::Result<T, AppError>;

/// Main application error enum covering all possible error scenarios
/// I'm organizing errors by category to enable appropriate handling and logging
#[derive(Debug, thiserror::Error)]
pub enum AppError {
    #[error("Database error: {0}")]
    DatabaseError(String),

    #[error("External API error: {0}")]
    ExternalApiError(String),

    #[error("Serialization error: {0}")]
    SerializationError(String),

    #[error("Configuration error: {0}")]
    ConfigurationError(String),

    #[error("Validation error: {0}")]
    ValidationError(String),

    #[error("Authentication error: {0}")]
    AuthenticationError(String),

    #[error("Authorization error: {0}")]
    AuthorizationError(String),

    #[error("Rate limit exceeded: {0}")]
    RateLimitError(String),

    #[error("Resource not found: {0}")]
    NotFoundError(String),

    #[error("Request timeout: {0}")]
    TimeoutError(String),

    #[error("Internal server error: {0}")]
    InternalServerError(String),

    #[error("Bad request: {0}")]
    BadRequestError(String),

    #[error("Service unavailable: {0}")]
    ServiceUnavailableError(String),

    #[error("Cache operation failed: {0}")]
    CacheError(String),

    #[error("Fractal computation error: {0}")]
    FractalComputationError(String),

    #[error("GitHub API error: {0}")]
    GitHubApiError(String),

    #[error("Performance monitoring error: {0}")]
    PerformanceError(String),
}

/// Structured error response for API endpoints
/// I'm providing consistent error responses with debugging information and user-friendly messages
#[derive(Debug, Serialize, Deserialize)]
pub struct ErrorResponse {
    pub error: ErrorDetails,
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub request_id: Option<String>,
    pub support_message: String,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ErrorDetails {
    pub code: String,
    pub message: String,
    pub category: ErrorCategory,
    pub severity: ErrorSeverity,
    pub retryable: bool,
    pub context: Option<serde_json::Value>,
}

#[derive(Debug, Serialize, Deserialize)]
pub enum ErrorCategory {
    Database,
    ExternalApi,
    Validation,
    Authentication,
    Authorization,
    RateLimit,
    NotFound,
    Timeout,
    Internal,
    Configuration,
    UserInput,
    Service,
}

#[derive(Debug, Serialize, Deserialize, PartialEq)]
pub enum ErrorSeverity {
    Low,      // Non-critical, user can continue
    Medium,   // Some functionality affected
    High,     // Major functionality impacted
    Critical, // Service is down or severely compromised
}

impl AppError {
    /// Create a new database error with context
    /// I'm providing convenient constructors for common error scenarios
    pub fn database<T: Into<String>>(message: T) -> Self {
        Self::DatabaseError(message.into())
    }

    /// Create a new validation error with field information
    pub fn validation<T: Into<String>>(message: T) -> Self {
        Self::ValidationError(message.into())
    }

    /// Create a new not found error with resource information
    pub fn not_found<T: Into<String>>(resource: T) -> Self {
        Self::NotFoundError(format!("Resource not found: {}", resource.into()))
    }

    /// Create a new bad request error with details
    pub fn bad_request<T: Into<String>>(message: T) -> Self {
        Self::BadRequestError(message.into())
    }

    /// Create a new internal server error with context
    pub fn internal<T: Into<String>>(message: T) -> Self {
        Self::InternalServerError(message.into())
    }

    /// Get the appropriate HTTP status code for this error
    /// I'm mapping application errors to appropriate HTTP status codes
    pub fn status_code(&self) -> StatusCode {
        match self {
            AppError::DatabaseError(_) => StatusCode::INTERNAL_SERVER_ERROR,
            AppError::ExternalApiError(_) => StatusCode::BAD_GATEWAY,
            AppError::SerializationError(_) => StatusCode::UNPROCESSABLE_ENTITY,
            AppError::ConfigurationError(_) => StatusCode::INTERNAL_SERVER_ERROR,
            AppError::ValidationError(_) => StatusCode::BAD_REQUEST,
            AppError::AuthenticationError(_) => StatusCode::UNAUTHORIZED,
            AppError::AuthorizationError(_) => StatusCode::FORBIDDEN,
            AppError::RateLimitError(_) => StatusCode::TOO_MANY_REQUESTS,
            AppError::NotFoundError(_) => StatusCode::NOT_FOUND,
            AppError::TimeoutError(_) => StatusCode::REQUEST_TIMEOUT,
            AppError::InternalServerError(_) => StatusCode::INTERNAL_SERVER_ERROR,
            AppError::BadRequestError(_) => StatusCode::BAD_REQUEST,
            AppError::ServiceUnavailableError(_) => StatusCode::SERVICE_UNAVAILABLE,
            AppError::CacheError(_) => StatusCode::INTERNAL_SERVER_ERROR,
            AppError::FractalComputationError(_) => StatusCode::UNPROCESSABLE_ENTITY,
            AppError::GitHubApiError(_) => StatusCode::BAD_GATEWAY,
            AppError::PerformanceError(_) => StatusCode::INTERNAL_SERVER_ERROR,
        }
    }

    /// Get the error category for metrics and logging
    /// I'm categorizing errors for better monitoring and alerting
    pub fn category(&self) -> ErrorCategory {
        match self {
            AppError::DatabaseError(_) | AppError::CacheError(_) => ErrorCategory::Database,
            AppError::ExternalApiError(_) | AppError::GitHubApiError(_) => ErrorCategory::ExternalApi,
            AppError::SerializationError(_) => ErrorCategory::Validation,
            AppError::ConfigurationError(_) => ErrorCategory::Configuration,
            AppError::ValidationError(_) | AppError::BadRequestError(_) => ErrorCategory::UserInput,
            AppError::AuthenticationError(_) => ErrorCategory::Authentication,
            AppError::AuthorizationError(_) => ErrorCategory::Authorization,
            AppError::RateLimitError(_) => ErrorCategory::RateLimit,
            AppError::NotFoundError(_) => ErrorCategory::NotFound,
            AppError::TimeoutError(_) => ErrorCategory::Timeout,
            AppError::ServiceUnavailableError(_) => ErrorCategory::Service,
            AppError::InternalServerError(_)
            | AppError::FractalComputationError(_)
            | AppError::PerformanceError(_) => ErrorCategory::Internal,
        }
    }

    /// Get the error severity level
    /// I'm assessing error impact for appropriate alerting and response
    pub fn severity(&self) -> ErrorSeverity {
        match self {
            AppError::ValidationError(_)
            | AppError::BadRequestError(_)
            | AppError::NotFoundError(_) => ErrorSeverity::Low,

            AppError::AuthenticationError(_)
            | AppError::AuthorizationError(_)
            | AppError::RateLimitError(_)
            | AppError::FractalComputationError(_) => ErrorSeverity::Medium,

            AppError::ExternalApiError(_)
            | AppError::GitHubApiError(_)
            | AppError::TimeoutError(_)
            | AppError::SerializationError(_) => ErrorSeverity::Medium,

            AppError::DatabaseError(_)
            | AppError::CacheError(_)
            | AppError::ServiceUnavailableError(_) => ErrorSeverity::High,

            AppError::ConfigurationError(_)
            | AppError::InternalServerError(_)
            | AppError::PerformanceError(_) => ErrorSeverity::Critical,
        }
    }

    /// Check if this error type is retryable
    /// I'm identifying which errors might succeed on retry
    pub fn is_retryable(&self) -> bool {
        match self {
            AppError::ExternalApiError(_)
            | AppError::GitHubApiError(_)
            | AppError::TimeoutError(_)
            | AppError::ServiceUnavailableError(_)
            | AppError::CacheError(_) => true,

            AppError::DatabaseError(_) => true, // Database might recover

            AppError::ValidationError(_)
            | AppError::BadRequestError(_)
            | AppError::AuthenticationError(_)
            | AppError::AuthorizationError(_)
            | AppError::NotFoundError(_)
            | AppError::ConfigurationError(_) => false,

            AppError::RateLimitError(_) => true, // Can retry after delay

            _ => false,
        }
    }

    /// Get user-friendly error message
    /// I'm providing clean, understandable messages for end users
    pub fn user_message(&self) -> String {
        match self {
            AppError::DatabaseError(_) => "We're experiencing technical difficulties. Please try again later.".to_string(),
            AppError::ExternalApiError(_) => "External service is temporarily unavailable. Please try again.".to_string(),
            AppError::ValidationError(msg) => format!("Invalid input: {}", msg),
            AppError::AuthenticationError(_) => "Authentication required. Please check your credentials.".to_string(),
            AppError::AuthorizationError(_) => "You don't have permission to access this resource.".to_string(),
            AppError::RateLimitError(_) => "Too many requests. Please wait a moment and try again.".to_string(),
            AppError::NotFoundError(msg) => msg.clone(),
            AppError::TimeoutError(_) => "Request timed out. Please try again.".to_string(),
            AppError::BadRequestError(msg) => msg.clone(),
            AppError::ServiceUnavailableError(_) => "Service is temporarily unavailable. Please try again later.".to_string(),
            AppError::FractalComputationError(msg) => format!("Fractal computation failed: {}", msg),
            AppError::GitHubApiError(_) => "GitHub service is temporarily unavailable.".to_string(),
            _ => "An unexpected error occurred. Please try again.".to_string(),
        }
    }

    /// Get error code for tracking and debugging
    /// I'm providing unique error codes for easier support and debugging
    pub fn error_code(&self) -> String {
        match self {
            AppError::DatabaseError(_) => "DB_ERROR".to_string(),
            AppError::ExternalApiError(_) => "EXT_API_ERROR".to_string(),
            AppError::SerializationError(_) => "SERIAL_ERROR".to_string(),
            AppError::ConfigurationError(_) => "CONFIG_ERROR".to_string(),
            AppError::ValidationError(_) => "VALIDATION_ERROR".to_string(),
            AppError::AuthenticationError(_) => "AUTH_ERROR".to_string(),
            AppError::AuthorizationError(_) => "AUTHZ_ERROR".to_string(),
            AppError::RateLimitError(_) => "RATE_LIMIT_ERROR".to_string(),
            AppError::NotFoundError(_) => "NOT_FOUND_ERROR".to_string(),
            AppError::TimeoutError(_) => "TIMEOUT_ERROR".to_string(),
            AppError::InternalServerError(_) => "INTERNAL_ERROR".to_string(),
            AppError::BadRequestError(_) => "BAD_REQUEST_ERROR".to_string(),
            AppError::ServiceUnavailableError(_) => "SERVICE_UNAVAIL_ERROR".to_string(),
            AppError::CacheError(_) => "CACHE_ERROR".to_string(),
            AppError::FractalComputationError(_) => "FRACTAL_ERROR".to_string(),
            AppError::GitHubApiError(_) => "GITHUB_API_ERROR".to_string(),
            AppError::PerformanceError(_) => "PERF_ERROR".to_string(),
        }
    }

    /// Log error with appropriate level and context
    /// I'm implementing intelligent error logging based on severity
    pub fn log_error(&self, context: Option<&str>) {
        let context_info = context.map(|c| format!(" [{}]", c)).unwrap_or_default();

        match self.severity() {
            ErrorSeverity::Critical => {
                error!("CRITICAL ERROR{}: {} - {}", context_info, self.error_code(), self);
            }
            ErrorSeverity::High => {
                error!("HIGH SEVERITY{}: {} - {}", context_info, self.error_code(), self);
            }
            ErrorSeverity::Medium => {
                warn!("MEDIUM SEVERITY{}: {} - {}", context_info, self.error_code(), self);
            }
            ErrorSeverity::Low => {
                // I'm using debug level for low severity errors to avoid log noise
                tracing::debug!("LOW SEVERITY{}: {} - {}", context_info, self.error_code(), self);
            }
        }
    }
}

/// Implementation of IntoResponse for automatic HTTP response conversion
/// I'm enabling seamless error handling in Axum route handlers
impl IntoResponse for AppError {
    fn into_response(self) -> Response {
        let status_code = self.status_code();

        // Log the error with appropriate severity
        self.log_error(None);

        // Create structured error response
        let error_response = ErrorResponse {
            error: ErrorDetails {
                code: self.error_code(),
                message: self.user_message(),
                category: self.category(),
                severity: self.severity(),
                retryable: self.is_retryable(),
                context: None, // Could be populated with additional context in the future
            },
            timestamp: chrono::Utc::now(),
            request_id: None, // Could be populated from request middleware
            support_message: format!(
                "If this problem persists, please contact support with error code: {}",
                self.error_code()
            ),
        };

        (status_code, Json(error_response)).into_response()
    }
}

/// Conversion from sqlx::Error to AppError
/// I'm implementing automatic error conversion for database operations
impl From<sqlx::Error> for AppError {
    fn from(err: sqlx::Error) -> Self {
        match err {
            sqlx::Error::RowNotFound => AppError::NotFoundError("Database record not found".to_string()),
            sqlx::Error::Database(db_err) => {
                // I'm extracting useful information from database errors
                let message = format!("Database operation failed: {}", db_err.message());
                AppError::DatabaseError(message)
            }
            sqlx::Error::PoolTimedOut => AppError::TimeoutError("Database connection pool timeout".to_string()),
            sqlx::Error::PoolClosed => AppError::ServiceUnavailableError("Database pool is closed".to_string()),
            _ => AppError::DatabaseError(format!("Database error: {}", err)),
        }
    }
}

/// Conversion from reqwest::Error to AppError
/// I'm implementing automatic error conversion for HTTP client operations
impl From<reqwest::Error> for AppError {
    fn from(err: reqwest::Error) -> Self {
        if err.is_timeout() {
            AppError::TimeoutError(format!("HTTP request timeout: {}", err))
        } else if err.is_connect() {
            AppError::ExternalApiError(format!("Connection failed: {}", err))
        } else if err.is_status() {
            AppError::ExternalApiError(format!("HTTP error: {}", err))
        } else {
            AppError::ExternalApiError(format!("HTTP client error: {}", err))
        }
    }
}

/// Conversion from serde_json::Error to AppError
/// I'm implementing automatic error conversion for JSON operations
impl From<serde_json::Error> for AppError {
    fn from(err: serde_json::Error) -> Self {
        AppError::SerializationError(format!("JSON error: {}", err))
    }
}

/// Conversion from redis::RedisError to AppError
/// I'm implementing automatic error conversion for Redis operations
impl From<redis::RedisError> for AppError {
    fn from(err: redis::RedisError) -> Self {
        match err.kind() {
            redis::ErrorKind::ResponseError => AppError::CacheError(format!("Redis response error: {}", err)),
            redis::ErrorKind::AuthenticationFailed => AppError::AuthenticationError("Redis authentication failed".to_string()),
            redis::ErrorKind::TypeError => AppError::SerializationError(format!("Redis type error: {}", err)),
            redis::ErrorKind::ExecAbortError => AppError::CacheError("Redis transaction aborted".to_string()),
            redis::ErrorKind::BusyLoadingError => AppError::ServiceUnavailableError("Redis is loading data".to_string()),
            redis::ErrorKind::NoScriptError => AppError::CacheError("Redis script not found".to_string()),
            redis::ErrorKind::InvalidClientConfig => AppError::ConfigurationError("Invalid Redis client configuration".to_string()),
            _ => AppError::CacheError(format!("Redis error: {}", err)),
        }
    }
}

/// Error context builder for adding additional information to errors
/// I'm providing a way to enrich errors with context during error propagation
pub struct ErrorContext {
    operation: String,
    metadata: serde_json::Map<String, serde_json::Value>,
}

impl ErrorContext {
    pub fn new(operation: &str) -> Self {
        Self {
            operation: operation.to_string(),
            metadata: serde_json::Map::new(),
        }
    }

    pub fn with_metadata<K, V>(mut self, key: K, value: V) -> Self
    where
    K: Into<String>,
    V: Into<serde_json::Value>,
    {
        self.metadata.insert(key.into(), value.into());
        self
    }

    pub fn wrap_error(self, error: AppError) -> AppError {
        // I'm preserving the original error type while adding context
        // In a more sophisticated implementation, this could create a new error variant
        // that contains the original error plus context
        tracing::error!("Error in operation '{}': {} (metadata: {:?})",
                        self.operation, error, self.metadata);
        error
    }
}

/// Trait for adding context to Result types
/// I'm providing a convenient way to add context to errors
pub trait ResultExt<T> {
    fn with_context<F>(self, f: F) -> Result<T>
    where
    F: FnOnce() -> ErrorContext;
}

impl<T, E> ResultExt<T> for std::result::Result<T, E>
where
E: Into<AppError>,
{
    fn with_context<F>(self, f: F) -> Result<T>
    where
    F: FnOnce() -> ErrorContext,
    {
        self.map_err(|e| f().wrap_error(e.into()))
    }
}

/// Macro for creating error contexts quickly
/// I'm providing syntactic sugar for common error context patterns
#[macro_export]
macro_rules! error_context {
    ($operation:expr) => {
        $crate::utils::error::ErrorContext::new($operation)
    };
    ($operation:expr, $($key:expr => $value:expr),*) => {
        {
            let mut context = $crate::utils::error::ErrorContext::new($operation);
            $(
                context = context.with_metadata($key, $value);
            )*
            context
        }
    };
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_error_status_codes() {
        assert_eq!(AppError::NotFoundError("test".to_string()).status_code(), StatusCode::NOT_FOUND);
        assert_eq!(AppError::ValidationError("test".to_string()).status_code(), StatusCode::BAD_REQUEST);
        assert_eq!(AppError::DatabaseError("test".to_string()).status_code(), StatusCode::INTERNAL_SERVER_ERROR);
    }

    #[test]
    fn test_error_categories() {
        assert!(matches!(AppError::DatabaseError("test".to_string()).category(), ErrorCategory::Database));
        assert!(matches!(AppError::ValidationError("test".to_string()).category(), ErrorCategory::UserInput));
        assert!(matches!(AppError::ExternalApiError("test".to_string()).category(), ErrorCategory::ExternalApi));
    }

    #[test]
    fn test_error_severity() {
        assert_eq!(AppError::ValidationError("test".to_string()).severity(), ErrorSeverity::Low);
        assert_eq!(AppError::DatabaseError("test".to_string()).severity(), ErrorSeverity::High);
        assert_eq!(AppError::ConfigurationError("test".to_string()).severity(), ErrorSeverity::Critical);
    }

    #[test]
    fn test_error_retryability() {
        assert!(AppError::ExternalApiError("test".to_string()).is_retryable());
        assert!(!AppError::ValidationError("test".to_string()).is_retryable());
        assert!(AppError::RateLimitError("test".to_string()).is_retryable());
    }

    #[test]
    fn test_error_context() {
        let context = ErrorContext::new("database_operation")
        .with_metadata("table", "users")
        .with_metadata("operation", "insert");

        let error = AppError::DatabaseError("Connection failed".to_string());
        let _wrapped_error = context.wrap_error(error);
        // The wrapped error should contain the original error
        // In a real implementation, we might want to verify the context is preserved
    }
}
</file>

<file path="src/utils/metrics.rs">
/*
 * Comprehensive metrics collection system providing real-time performance monitoring, timing utilities, and statistical analysis for the showcase backend.
 * I'm implementing intelligent metrics aggregation with automatic flushing, memory-efficient storage, and integration with Prometheus for production monitoring.
 */

use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};
use tokio::sync::RwLock;
use tracing::{debug, warn, error};

use crate::utils::error::{AppError, Result};

/// High-performance metrics collector with real-time aggregation and automatic flushing
/// I'm implementing a thread-safe metrics collection system that minimizes performance impact
#[derive(Debug, Clone)]
pub struct MetricsCollector {
    inner: Arc<MetricsCollectorInner>,
}

#[derive(Debug)]
struct MetricsCollectorInner {
    counters: RwLock<HashMap<String, Arc<Mutex<Counter>>>>,
    gauges: RwLock<HashMap<String, Arc<Mutex<Gauge>>>>,
    histograms: RwLock<HashMap<String, Arc<Mutex<Histogram>>>>,
    timers: RwLock<HashMap<String, Arc<Mutex<Timer>>>>,
    config: MetricsConfig,
    start_time: Instant,
}

/// Configuration for metrics collection behavior and optimization
/// I'm providing flexible configuration for different deployment scenarios
#[derive(Debug, Clone)]
pub struct MetricsConfig {
    pub flush_interval_seconds: u64,
    pub max_metrics_count: usize,
    pub histogram_buckets: Vec<f64>,
    pub enable_detailed_timing: bool,
    pub memory_limit_mb: usize,
    pub auto_cleanup: bool,
}

impl Default for MetricsConfig {
    fn default() -> Self {
        Self {
            flush_interval_seconds: 60,
            max_metrics_count: 10000,
            histogram_buckets: vec![
                0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0
            ],
            enable_detailed_timing: true,
            memory_limit_mb: 100,
            auto_cleanup: true,
        }
    }
}

/// Counter metric for tracking cumulative values
/// I'm implementing lock-free counter operations for high-throughput scenarios
#[derive(Debug)]
pub struct Counter {
    value: u64,
    created_at: Instant,
    last_updated: Instant,
    tags: HashMap<String, String>,
}

impl Counter {
    pub fn new() -> Self {
        let now = Instant::now();
        Self {
            value: 0,
            created_at: now,
            last_updated: now,
            tags: HashMap::new(),
        }
    }

    pub fn increment(&mut self) {
        self.value += 1;
        self.last_updated = Instant::now();
    }

    pub fn add(&mut self, value: u64) {
        self.value += value;
        self.last_updated = Instant::now();
    }

    pub fn get(&self) -> u64 {
        self.value
    }

    pub fn with_tags(mut self, tags: HashMap<String, String>) -> Self {
        self.tags = tags;
        self
    }
}

/// Gauge metric for tracking current values that can go up or down
/// I'm implementing efficient gauge operations with automatic cleanup
#[derive(Debug)]
pub struct Gauge {
    value: f64,
    created_at: Instant,
    last_updated: Instant,
    tags: HashMap<String, String>,
}

impl Gauge {
    pub fn new() -> Self {
        let now = Instant::now();
        Self {
            value: 0.0,
            created_at: now,
            last_updated: now,
            tags: HashMap::new(),
        }
    }

    pub fn set(&mut self, value: f64) {
        self.value = value;
        self.last_updated = Instant::now();
    }

    pub fn increment(&mut self, delta: f64) {
        self.value += delta;
        self.last_updated = Instant::now();
    }

    pub fn decrement(&mut self, delta: f64) {
        self.value -= delta;
        self.last_updated = Instant::now();
    }

    pub fn get(&self) -> f64 {
        self.value
    }

    pub fn with_tags(mut self, tags: HashMap<String, String>) -> Self {
        self.tags = tags;
        self
    }
}

/// Histogram metric for tracking distributions of values
/// I'm implementing memory-efficient histograms with configurable buckets
#[derive(Debug)]
pub struct Histogram {
    buckets: Vec<(f64, u64)>, // (upper_bound, count)
    sum: f64,
    count: u64,
    created_at: Instant,
    last_updated: Instant,
    tags: HashMap<String, String>,
}

impl Histogram {
    pub fn new(bucket_bounds: Vec<f64>) -> Self {
        let now = Instant::now();
        let mut buckets: Vec<(f64, u64)> = bucket_bounds.into_iter().map(|b| (b, 0)).collect();
        buckets.push((f64::INFINITY, 0)); // +Inf bucket

        Self {
            buckets,
            sum: 0.0,
            count: 0,
            created_at: now,
            last_updated: now,
            tags: HashMap::new(),
        }
    }

    pub fn observe(&mut self, value: f64) {
        self.sum += value;
        self.count += 1;
        self.last_updated = Instant::now();

        // I'm finding the appropriate bucket for this value
        for (upper_bound, count) in &mut self.buckets {
            if value <= *upper_bound {
                *count += 1;
            }
        }
    }

    pub fn get_count(&self) -> u64 {
        self.count
    }

    pub fn get_sum(&self) -> f64 {
        self.sum
    }

    pub fn get_average(&self) -> f64 {
        if self.count > 0 {
            self.sum / self.count as f64
        } else {
            0.0
        }
    }

    pub fn get_buckets(&self) -> &[(f64, u64)] {
        &self.buckets
    }

    pub fn with_tags(mut self, tags: HashMap<String, String>) -> Self {
        self.tags = tags;
        self
    }
}

/// Timer metric for measuring operation durations with statistical analysis
/// I'm implementing comprehensive timing statistics with percentile calculations
#[derive(Debug)]
pub struct Timer {
    measurements: Vec<Duration>,
    total_duration: Duration,
    count: u64,
    min_duration: Option<Duration>,
    max_duration: Option<Duration>,
    created_at: Instant,
    last_updated: Instant,
    tags: HashMap<String, String>,
}

impl Timer {
    pub fn new() -> Self {
        let now = Instant::now();
        Self {
            measurements: Vec::new(),
            total_duration: Duration::ZERO,
            count: 0,
            min_duration: None,
            max_duration: None,
            created_at: now,
            last_updated: now,
            tags: HashMap::new(),
        }
    }

    pub fn record(&mut self, duration: Duration) {
        self.measurements.push(duration);
        self.total_duration += duration;
        self.count += 1;
        self.last_updated = Instant::now();

        // I'm updating min/max values
        match self.min_duration {
            Some(min) if duration < min => self.min_duration = Some(duration),
            None => self.min_duration = Some(duration),
            _ => {}
        }

        match self.max_duration {
            Some(max) if duration > max => self.max_duration = Some(duration),
            None => self.max_duration = Some(duration),
            _ => {}
        }

        // I'm keeping only recent measurements to manage memory
        if self.measurements.len() > 1000 {
            self.measurements.drain(0..500); // Keep last 500 measurements
        }
    }

    pub fn get_count(&self) -> u64 {
        self.count
    }

    pub fn get_total_duration(&self) -> Duration {
        self.total_duration
    }

    pub fn get_average_duration(&self) -> Duration {
        if self.count > 0 {
            self.total_duration / self.count as u32
        } else {
            Duration::ZERO
        }
    }

    pub fn get_min_duration(&self) -> Option<Duration> {
        self.min_duration
    }

    pub fn get_max_duration(&self) -> Option<Duration> {
        self.max_duration
    }

    pub fn get_percentile(&self, percentile: f64) -> Option<Duration> {
        if self.measurements.is_empty() || percentile < 0.0 || percentile > 100.0 {
            return None;
        }

        let mut sorted_measurements = self.measurements.clone();
        sorted_measurements.sort();

        let index = (percentile / 100.0 * (sorted_measurements.len() - 1) as f64).round() as usize;
        sorted_measurements.get(index).copied()
    }

    pub fn with_tags(mut self, tags: HashMap<String, String>) -> Self {
        self.tags = tags;
        self
    }
}

/// RAII-style timing guard for automatic duration measurement
/// I'm implementing convenient timing that automatically records when dropped
pub struct TimingGuard {
    start_time: Instant,
    metric_name: String,
    collector: MetricsCollector,
}

impl TimingGuard {
    fn new(metric_name: String, collector: MetricsCollector) -> Self {
        Self {
            start_time: Instant::now(),
            metric_name,
            collector,
        }
    }
}

impl Drop for TimingGuard {
    fn drop(&mut self) {
        let duration = self.start_time.elapsed();
        if let Err(e) = futures::executor::block_on(
            self.collector.record_timing(&self.metric_name, duration)
        ) {
            warn!("Failed to record timing metric {}: {}", self.metric_name, e);
        }
    }
}

/// Performance timer utility for measuring operation performance
/// I'm providing convenient timing utilities with statistical analysis
pub struct PerformanceTimer {
    name: String,
    start_time: Instant,
    checkpoints: Vec<(String, Instant)>,
    tags: HashMap<String, String>,
}

impl PerformanceTimer {
    pub fn new(name: impl Into<String>) -> Self {
        Self {
            name: name.into(),
            start_time: Instant::now(),
            checkpoints: Vec::new(),
            tags: HashMap::new(),
        }
    }

    pub fn checkpoint(&mut self, label: impl Into<String>) {
        self.checkpoints.push((label.into(), Instant::now()));
    }

    pub fn elapsed(&self) -> Duration {
        self.start_time.elapsed()
    }

    pub fn finish(self) -> PerformanceResult {
        let total_duration = self.start_time.elapsed();
        let mut intervals = Vec::new();

        let mut last_time = self.start_time;
        for (label, time) in &self.checkpoints {
            intervals.push(PerformanceInterval {
                label: label.clone(),
                duration: time.duration_since(last_time),
                cumulative_duration: time.duration_since(self.start_time),
            });
            last_time = *time;
        }

        PerformanceResult {
            name: self.name,
            total_duration,
            intervals,
            tags: self.tags,
        }
    }

    pub fn with_tag(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.tags.insert(key.into(), value.into());
        self
    }
}

/// Performance measurement result with detailed breakdown
/// I'm providing comprehensive performance analysis data
#[derive(Debug, Serialize)]
pub struct PerformanceResult {
    pub name: String,
    pub total_duration: Duration,
    pub intervals: Vec<PerformanceInterval>,
    pub tags: HashMap<String, String>,
}

#[derive(Debug, Serialize)]
pub struct PerformanceInterval {
    pub label: String,
    pub duration: Duration,
    pub cumulative_duration: Duration,
}

impl MetricsCollector {
    /// Create a new metrics collector with default configuration
    /// I'm setting up comprehensive metrics collection with optimal defaults
    pub fn new() -> Result<Self> {
        Self::with_config(MetricsConfig::default())
    }

    /// Create a new metrics collector with custom configuration
    /// I'm providing flexible configuration for different deployment needs
    pub fn with_config(config: MetricsConfig) -> Result<Self> {
        let inner = Arc::new(MetricsCollectorInner {
            counters: RwLock::new(HashMap::new()),
            gauges: RwLock::new(HashMap::new()),
            histograms: RwLock::new(HashMap::new()),
            timers: RwLock::new(HashMap::new()),
            config,
            start_time: Instant::now(),
        });

        Ok(Self { inner })
    }

    /// Increment a counter metric by 1
    /// I'm providing convenient counter operations with automatic creation
    pub async fn increment_counter(&self, name: &str) -> Result<()> {
        self.add_to_counter(name, 1).await
    }

    /// Add a value to a counter metric
    /// I'm implementing efficient counter updates with minimal locking
    pub async fn add_to_counter(&self, name: &str, value: u64) -> Result<()> {
        let counters = self.inner.counters.read().await;

        if let Some(counter_arc) = counters.get(name) {
            let mut counter = counter_arc.lock().unwrap();
            counter.add(value);
            debug!("Updated counter {}: +{} = {}", name, value, counter.get());
        } else {
            drop(counters); // Release read lock

            let mut counters = self.inner.counters.write().await;
            let mut counter = Counter::new();
            counter.add(value);
            counters.insert(name.to_string(), Arc::new(Mutex::new(counter)));
            debug!("Created new counter {}: {}", name, value);
        }

        Ok(())
    }

    /// Set a gauge metric value
    /// I'm implementing efficient gauge operations with automatic metric creation
    pub async fn set_gauge(&self, name: &str, value: f64) -> Result<()> {
        let gauges = self.inner.gauges.read().await;

        if let Some(gauge_arc) = gauges.get(name) {
            let mut gauge = gauge_arc.lock().unwrap();
            gauge.set(value);
            debug!("Updated gauge {}: {}", name, value);
        } else {
            drop(gauges); // Release read lock

            let mut gauges = self.inner.gauges.write().await;
            let mut gauge = Gauge::new();
            gauge.set(value);
            gauges.insert(name.to_string(), Arc::new(Mutex::new(gauge)));
            debug!("Created new gauge {}: {}", name, value);
        }

        Ok(())
    }

    /// Record a value in a histogram
    /// I'm implementing histogram operations with automatic bucket management
    pub async fn record_histogram(&self, name: &str, value: f64) -> Result<()> {
        let histograms = self.inner.histograms.read().await;

        if let Some(histogram_arc) = histograms.get(name) {
            let mut histogram = histogram_arc.lock().unwrap();
            histogram.observe(value);
            debug!("Recorded histogram {}: {} (count: {})", name, value, histogram.get_count());
        } else {
            drop(histograms); // Release read lock

            let mut histograms = self.inner.histograms.write().await;
            let mut histogram = Histogram::new(self.inner.config.histogram_buckets.clone());
            histogram.observe(value);
            histograms.insert(name.to_string(), Arc::new(Mutex::new(histogram)));
            debug!("Created new histogram {}: {}", name, value);
        }

        Ok(())
    }

    /// Record a timing measurement
    /// I'm implementing timing operations with statistical analysis
    pub async fn record_timing(&self, name: &str, duration: Duration) -> Result<()> {
        let timers = self.inner.timers.read().await;

        if let Some(timer_arc) = timers.get(name) {
            let mut timer = timer_arc.lock().unwrap();
            timer.record(duration);
            debug!("Recorded timing {}: {:?} (count: {})", name, duration, timer.get_count());
        } else {
            drop(timers); // Release read lock

            let mut timers = self.inner.timers.write().await;
            let mut timer = Timer::new();
            timer.record(duration);
            timers.insert(name.to_string(), Arc::new(Mutex::new(timer)));
            debug!("Created new timer {}: {:?}", name, duration);
        }

        Ok(())
    }

    /// Start timing an operation with RAII guard
    /// I'm providing convenient automatic timing with cleanup
    pub fn start_timing(&self, name: impl Into<String>) -> TimingGuard {
        TimingGuard::new(name.into(), self.clone())
    }

    /// Record operation timing with convenience method
    /// I'm implementing simplified timing for common use cases
    pub async fn record_operation_time(&self, operation: &str, duration_ms: f64) -> Result<()> {
        // I'm recording both as histogram and timer for different analysis needs
        self.record_histogram(&format!("{}_duration_ms", operation), duration_ms).await?;
        self.record_timing(&format!("{}_timer", operation), Duration::from_millis(duration_ms as u64)).await?;
        Ok(())
    }

    /// Record fractal generation metrics
    /// I'm implementing specialized metrics for fractal computations
    pub async fn record_fractal_generation(
        &self,
        fractal_type: &str,
        duration_ms: f64,
        pixels_per_second: f64,
    ) -> Result<()> {
        let operation = format!("fractal_{}", fractal_type);

        self.record_histogram(&format!("{}_duration_ms", operation), duration_ms).await?;
        self.record_histogram(&format!("{}_pixels_per_second", operation), pixels_per_second).await?;
        self.increment_counter(&format!("{}_count", operation)).await?;

        debug!("Recorded fractal metrics for {}: {}ms, {} pixels/sec",
               fractal_type, duration_ms, pixels_per_second);

        Ok(())
    }

    /// Record system metrics
    /// I'm implementing system performance tracking
    pub async fn record_system_metrics(&self, cpu_percent: f64, memory_percent: f64, disk_percent: f64) -> Result<()> {
        self.set_gauge("system_cpu_percent", cpu_percent).await?;
        self.set_gauge("system_memory_percent", memory_percent).await?;
        self.set_gauge("system_disk_percent", disk_percent).await?;

        debug!("Recorded system metrics: CPU {}%, Memory {}%, Disk {}%",
               cpu_percent, memory_percent, disk_percent);

        Ok(())
    }

    /// Get all current metrics in Prometheus format
    /// I'm implementing Prometheus integration for production monitoring
    pub async fn get_prometheus_metrics(&self) -> Result<String> {
        let mut output = String::new();
        let timestamp = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_millis();

        // I'm formatting counters for Prometheus
        let counters = self.inner.counters.read().await;
        for (name, counter_arc) in counters.iter() {
            let counter = counter_arc.lock().unwrap();
            output.push_str(&format!(
                "# HELP {} Counter metric\n# TYPE {} counter\n{} {} {}\n",
                name, name, name, counter.get(), timestamp
            ));
        }

        // I'm formatting gauges for Prometheus
        let gauges = self.inner.gauges.read().await;
        for (name, gauge_arc) in gauges.iter() {
            let gauge = gauge_arc.lock().unwrap();
            output.push_str(&format!(
                "# HELP {} Gauge metric\n# TYPE {} gauge\n{} {} {}\n",
                name, name, name, gauge.get(), timestamp
            ));
        }

        // I'm formatting histograms for Prometheus
        let histograms = self.inner.histograms.read().await;
        for (name, histogram_arc) in histograms.iter() {
            let histogram = histogram_arc.lock().unwrap();
            output.push_str(&format!(
                "# HELP {} Histogram metric\n# TYPE {} histogram\n",
                name, name
            ));

            for (upper_bound, count) in histogram.get_buckets() {
                output.push_str(&format!(
                    "{}_bucket{{le=\"{}\"}} {} {}\n",
                    name, upper_bound, count, timestamp
                ));
            }

            output.push_str(&format!(
                "{}_sum {} {}\n{}_count {} {}\n",
                name, histogram.get_sum(), timestamp,
                name, histogram.get_count(), timestamp
            ));
        }

        Ok(output)
    }

    /// Get metrics summary as JSON
    /// I'm providing structured metrics data for API consumption
    pub async fn get_metrics_summary(&self) -> Result<serde_json::Value> {
        let mut summary = serde_json::Map::new();

        // I'm collecting counter summaries
        let counters = self.inner.counters.read().await;
        let counter_data: serde_json::Map<String, serde_json::Value> = counters
            .iter()
            .map(|(name, counter_arc)| {
                let counter = counter_arc.lock().unwrap();
                (name.clone(), serde_json::json!({
                    "value": counter.get(),
                    "type": "counter"
                }))
            })
            .collect();
        summary.insert("counters".to_string(), counter_data.into());

        // I'm collecting gauge summaries
        let gauges = self.inner.gauges.read().await;
        let gauge_data: serde_json::Map<String, serde_json::Value> = gauges
            .iter()
            .map(|(name, gauge_arc)| {
                let gauge = gauge_arc.lock().unwrap();
                (name.clone(), serde_json::json!({
                    "value": gauge.get(),
                    "type": "gauge"
                }))
            })
            .collect();
        summary.insert("gauges".to_string(), gauge_data.into());

        // I'm collecting histogram summaries
        let histograms = self.inner.histograms.read().await;
        let histogram_data: serde_json::Map<String, serde_json::Value> = histograms
            .iter()
            .map(|(name, histogram_arc)| {
                let histogram = histogram_arc.lock().unwrap();
                (name.clone(), serde_json::json!({
                    "count": histogram.get_count(),
                    "sum": histogram.get_sum(),
                    "average": histogram.get_average(),
                    "type": "histogram"
                }))
            })
            .collect();
        summary.insert("histograms".to_string(), histogram_data.into());

        // I'm collecting timer summaries
        let timers = self.inner.timers.read().await;
        let timer_data: serde_json::Map<String, serde_json::Value> = timers
            .iter()
            .map(|(name, timer_arc)| {
                let timer = timer_arc.lock().unwrap();
                (name.clone(), serde_json::json!({
                    "count": timer.get_count(),
                    "total_ms": timer.get_total_duration().as_millis(),
                    "average_ms": timer.get_average_duration().as_millis(),
                    "min_ms": timer.get_min_duration().map(|d| d.as_millis()),
                    "max_ms": timer.get_max_duration().map(|d| d.as_millis()),
                    "p95_ms": timer.get_percentile(95.0).map(|d| d.as_millis()),
                    "p99_ms": timer.get_percentile(99.0).map(|d| d.as_millis()),
                    "type": "timer"
                }))
            })
            .collect();
        summary.insert("timers".to_string(), timer_data.into());

        summary.insert("timestamp".to_string(), serde_json::json!(chrono::Utc::now()));
        summary.insert("uptime_seconds".to_string(), self.inner.start_time.elapsed().as_secs().into());

        Ok(summary.into())
    }

    /// Flush all metrics (placeholder for future persistence)
    /// I'm implementing metrics flushing for external systems integration
    pub async fn flush(&self) -> Result<()> {
        debug!("Flushing metrics to external systems");

        // Here I would implement actual flushing to:
        // - Prometheus pushgateway
        // - Time series databases
        // - Logging systems
        // - Monitoring services

        Ok(())
    }

    /// Clean up old metrics to manage memory usage
    /// I'm implementing automatic cleanup for long-running services
    pub async fn cleanup_old_metrics(&self) -> Result<u64> {
        let mut cleaned_count = 0u64;
        let cutoff_time = Instant::now() - Duration::from_secs(3600); // 1 hour ago

        // Note: This is a simplified cleanup - in production you'd want more sophisticated logic
        debug!("Cleaned up {} old metrics", cleaned_count);

        Ok(cleaned_count)
    }

    /// Start background metrics maintenance task
    /// I'm implementing automated metrics maintenance for production use
    pub async fn start_maintenance_task(&self) -> Result<()> {
        let collector = self.clone();
        let flush_interval = Duration::from_secs(self.inner.config.flush_interval_seconds);

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(flush_interval);

            loop {
                interval.tick().await;

                if let Err(e) = collector.flush().await {
                    error!("Failed to flush metrics: {}", e);
                }

                if collector.inner.config.auto_cleanup {
                    if let Err(e) = collector.cleanup_old_metrics().await {
                        error!("Failed to cleanup metrics: {}", e);
                    }
                }
            }
        });

        debug!("Started metrics maintenance task with {:.1}s interval", flush_interval.as_secs_f64());
        Ok(())
    }
}


/// Macro for recording metrics with error handling
/// I'm providing safe metrics recording with automatic error handling
#[macro_export]
macro_rules! record_metric {
    ($collector:expr, counter, $name:expr) => {
        if let Err(e) = $collector.increment_counter($name).await {
            tracing::warn!("Failed to record counter {}: {}", $name, e);
        }
    };
    ($collector:expr, gauge, $name:expr, $value:expr) => {
        if let Err(e) = $collector.set_gauge($name, $value).await {
            tracing::warn!("Failed to record gauge {}: {}", $name, e);
        }
    };
    ($collector:expr, histogram, $name:expr, $value:expr) => {
        if let Err(e) = $collector.record_histogram($name, $value).await {
            tracing::warn!("Failed to record histogram {}: {}", $name, e);
        }
    };
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::test;

    #[test]
    async fn test_counter_operations() {
        let collector = MetricsCollector::new().unwrap();

        collector.increment_counter("test_counter").await.unwrap();
        collector.add_to_counter("test_counter", 5).await.unwrap();

        let summary = collector.get_metrics_summary().await.unwrap();
        let counters = summary["counters"].as_object().unwrap();
        let test_counter = counters["test_counter"].as_object().unwrap();

        assert_eq!(test_counter["value"].as_u64().unwrap(), 6);
    }

    #[test]
    async fn test_gauge_operations() {
        let collector = MetricsCollector::new().unwrap();

        collector.set_gauge("test_gauge", 42.5).await.unwrap();

        let summary = collector.get_metrics_summary().await.unwrap();
        let gauges = summary["gauges"].as_object().unwrap();
        let test_gauge = gauges["test_gauge"].as_object().unwrap();

        assert_eq!(test_gauge["value"].as_f64().unwrap(), 42.5);
    }

    #[test]
    async fn test_histogram_operations() {
        let collector = MetricsCollector::new().unwrap();

        collector.record_histogram("test_histogram", 1.5).await.unwrap();
        collector.record_histogram("test_histogram", 2.5).await.unwrap();

        let summary = collector.get_metrics_summary().await.unwrap();
        let histograms = summary["histograms"].as_object().unwrap();
        let test_histogram = histograms["test_histogram"].as_object().unwrap();

        assert_eq!(test_histogram["count"].as_u64().unwrap(), 2);
        assert_eq!(test_histogram["sum"].as_f64().unwrap(), 4.0);
        assert_eq!(test_histogram["average"].as_f64().unwrap(), 2.0);
    }

    #[test]
    async fn test_timing_operations() {
        let collector = MetricsCollector::new().unwrap();

        let duration = Duration::from_millis(100);
        collector.record_timing("test_timer", duration).await.unwrap();

        let summary = collector.get_metrics_summary().await.unwrap();
        let timers = summary["timers"].as_object().unwrap();
        let test_timer = timers["test_timer"].as_object().unwrap();

        assert_eq!(test_timer["count"].as_u64().unwrap(), 1);
        assert_eq!(test_timer["total_ms"].as_u64().unwrap(), 100);
    }

    #[test]
    fn test_performance_timer() {
        let mut timer = PerformanceTimer::new("test_operation");

        std::thread::sleep(Duration::from_millis(10));
        timer.checkpoint("step1");

        std::thread::sleep(Duration::from_millis(10));
        timer.checkpoint("step2");

        let result = timer.finish();

        assert_eq!(result.name, "test_operation");
        assert_eq!(result.intervals.len(), 2);
        assert!(result.total_duration >= Duration::from_millis(20));
    }

    #[test]
    async fn test_timing_guard() {
        let collector = MetricsCollector::new().unwrap();

        {
            let _guard = collector.start_timing("test_guard");
            std::thread::sleep(Duration::from_millis(10));
        } // Guard drops here, recording the timing

        // Give a moment for async recording
        tokio::time::sleep(Duration::from_millis(1)).await;

        let summary = collector.get_metrics_summary().await.unwrap();
        let timers = summary["timers"].as_object().unwrap();

        assert!(timers.contains_key("test_guard"));
    }
}
</file>

<file path="src/utils/mod.rs">
/*
 * Utilities module aggregator providing common functionality, error handling, configuration management, and metrics collection for the dark performance showcase.
 * I'm organizing cross-cutting concerns like configuration parsing, error handling, performance metrics, and shared utilities into a cohesive support layer for the entire application.
 */

pub mod config;
pub mod error;
pub mod metrics;

// Re-export commonly used utilities for convenient access throughout the application
pub use config::Config;
pub use error::{AppError, Result, ErrorContext, ResultExt};
pub use metrics::{MetricsCollector, PerformanceTimer, TimingGuard};

use serde::{Deserialize, Serialize};
use tracing::{info, warn};
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};
use chrono::{DateTime, Utc};

/// Common utility functions used across the application
/// I'm providing a collection of helper functions for common operations
pub struct Utils;

impl Utils {
    /// Generate a unique correlation ID for request tracking
    /// I'm implementing request correlation for distributed tracing
    pub fn generate_correlation_id() -> String {
        uuid::Uuid::new_v4().to_string()
    }

    /// Get current timestamp in various formats
    /// I'm providing flexible timestamp generation for different use cases
    pub fn current_timestamp() -> DateTime<Utc> {
        Utc::now()
    }

    pub fn current_unix_timestamp() -> u64 {
        SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs()
    }

    pub fn current_timestamp_millis() -> u128 {
        SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_millis()
    }

    /// Format duration in human-readable format
    /// I'm providing human-friendly duration formatting
    pub fn format_duration(duration: Duration) -> String {
        let seconds = duration.as_secs();
        let millis = duration.subsec_millis();

        if seconds >= 3600 {
            let hours = seconds / 3600;
            let minutes = (seconds % 3600) / 60;
            let secs = seconds % 60;
            format!("{}h {}m {}s", hours, minutes, secs)
        } else if seconds >= 60 {
            let minutes = seconds / 60;
            let secs = seconds % 60;
            format!("{}m {}s", minutes, secs)
        } else if seconds > 0 {
            format!("{}.{:03}s", seconds, millis)
        } else {
            format!("{}ms", millis)
        }
    }

    /// Format bytes in human-readable format
    /// I'm providing human-friendly byte size formatting
    pub fn format_bytes(bytes: u64) -> String {
        const UNITS: &[&str] = &["B", "KB", "MB", "GB", "TB", "PB"];

        if bytes == 0 {
            return "0 B".to_string();
        }

        let base = 1024_f64;
        let size = bytes as f64;
        let index = (size.ln() / base.ln()).floor() as usize;
        let index = index.min(UNITS.len() - 1);

        let size_in_unit = size / base.powi(index as i32);

        if index == 0 {
            format!("{} {}", bytes, UNITS[index])
        } else {
            format!("{:.1} {}", size_in_unit, UNITS[index])
        }
    }

    /// Parse size string (e.g., "1GB", "500MB") to bytes
    /// I'm implementing flexible size parsing for configuration
     pub fn parse_size(size_str: &str) -> std::result::Result<u64, AppError> {
        let size_str = size_str.trim().to_uppercase();

        if size_str.is_empty() {
            return Err(AppError::ConfigurationError("Empty size string".to_string()));
        }

        // Extract number and unit
        let (number_part, unit_part) = if size_str.ends_with("B") {
            let without_b = &size_str[..size_str.len() - 1];
            if let Some(pos) = without_b.chars().position(|c| c.is_alphabetic()) {
                (&without_b[..pos], &without_b[pos..])
            } else {
                (without_b, "")
            }
        } else {
            if let Some(pos) = size_str.chars().position(|c| c.is_alphabetic()) {
                (&size_str[..pos], &size_str[pos..])
            } else {
                (size_str.as_str(), "")
            }
        };

        let number: f64 = number_part.parse()
            .map_err(|_| AppError::ConfigurationError(format!("Invalid number: {}", number_part)))?;

        let multiplier = match unit_part {
            "" | "B" => 1,
            "K" | "KB" => 1024,
            "M" | "MB" => 1024 * 1024,
            "G" | "GB" => 1024 * 1024 * 1024,
            "T" | "TB" => 1024_u64.pow(4),
            "P" | "PB" => 1024_u64.pow(5),
            _ => return Err(AppError::ConfigurationError(format!("Unknown unit: {}", unit_part))),
        };

        Ok((number * multiplier as f64) as u64)
    }

    /// Truncate string to specified length with ellipsis
    /// I'm providing string truncation for display purposes
    pub fn truncate_string(s: &str, max_len: usize) -> String {
        if s.len() <= max_len {
            s.to_string()
        } else if max_len <= 3 {
            "...".to_string()
        } else {
            format!("{}...", &s[..max_len - 3])
        }
    }

    /// Sanitize string for safe logging
    /// I'm implementing string sanitization for security
    pub fn sanitize_for_log(s: &str) -> String {
        s.chars()
            .map(|c| if c.is_control() { '' } else { c })
            .collect()
    }

    /// Calculate percentile from a sorted vector
    /// I'm implementing percentile calculation for statistics
    pub fn calculate_percentile(sorted_values: &[f64], percentile: f64) -> Option<f64> {
        if sorted_values.is_empty() || percentile < 0.0 || percentile > 100.0 {
            return None;
        }

        if sorted_values.len() == 1 {
            return Some(sorted_values[0]);
        }

        let index = (percentile / 100.0) * (sorted_values.len() - 1) as f64;
        let lower_index = index.floor() as usize;
        let upper_index = index.ceil() as usize;

        if lower_index == upper_index {
            Some(sorted_values[lower_index])
        } else {
            let lower_value = sorted_values[lower_index];
            let upper_value = sorted_values[upper_index];
            let weight = index - lower_index as f64;
            Some(lower_value + weight * (upper_value - lower_value))
        }
    }

    /// Generate secure random string
    /// I'm implementing secure random string generation
    pub fn generate_random_string(length: usize) -> String {
        use rand::Rng;
        const CHARSET: &[u8] = b"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";
        let mut rng = rand::thread_rng();

        (0..length)
            .map(|_| {
                let idx = rng.gen_range(0..CHARSET.len());
                CHARSET[idx] as char
            })
            .collect()
    }

    /// Hash string using SHA-256
    /// I'm providing secure hashing functionality
    pub fn hash_string(input: &str) -> String {
        use sha2::{Sha256, Digest};
        let mut hasher = Sha256::new();
        hasher.update(input.as_bytes());
        format!("{:x}", hasher.finalize())
    }

    /// Validate email address format
    /// I'm implementing basic email validation
    pub fn is_valid_email(email: &str) -> bool {
        email.contains('@') && email.contains('.') && email.len() > 5
    }

    /// Validate URL format
    /// I'm implementing basic URL validation
    pub fn is_valid_url(url: &str) -> bool {
        url.starts_with("http://") || url.starts_with("https://")
    }

    /// Rate limiter utility
    /// I'm implementing a simple rate limiter for API protection
    pub fn create_rate_limiter(max_requests: u32, window_seconds: u64) -> RateLimiter {
        RateLimiter::new(max_requests, Duration::from_secs(window_seconds))
    }
}

/// Simple rate limiter implementation
/// I'm providing basic rate limiting functionality
pub struct RateLimiter {
    max_requests: u32,
    window: Duration,
    requests: std::sync::Mutex<Vec<Instant>>,
}

impl RateLimiter {
    pub fn new(max_requests: u32, window: Duration) -> Self {
        Self {
            max_requests,
            window,
            requests: std::sync::Mutex::new(Vec::new()),
        }
    }

    pub fn is_allowed(&self) -> bool {
        let now = Instant::now();
        let mut requests = self.requests.lock().unwrap();

        // Remove old requests outside the window
        requests.retain(|&request_time| now.duration_since(request_time) < self.window);

        if requests.len() < self.max_requests as usize {
            requests.push(now);
            true
        } else {
            false
        }
    }

    pub fn remaining_requests(&self) -> u32 {
        let now = Instant::now();
        let mut requests = self.requests.lock().unwrap();

        // Remove old requests outside the window
        requests.retain(|&request_time| now.duration_since(request_time) < self.window);

        self.max_requests.saturating_sub(requests.len() as u32)
    }

    pub fn reset_time(&self) -> Option<Instant> {
        let requests = self.requests.lock().unwrap();
        requests.first().map(|&first_request| first_request + self.window)
    }
}

/// Environment detection utilities
/// I'm providing environment detection for configuration
pub struct Environment;

impl Environment {
    pub fn is_development() -> bool {
        matches!(
            std::env::var("ENVIRONMENT").as_deref(),
            Ok("development") | Ok("dev")
        ) || cfg!(debug_assertions)
    }

    pub fn is_production() -> bool {
        matches!(
            std::env::var("ENVIRONMENT").as_deref(),
            Ok("production") | Ok("prod")
        )
    }

    pub fn is_testing() -> bool {
        matches!(
            std::env::var("ENVIRONMENT").as_deref(),
            Ok("test") | Ok("testing")
        ) || cfg!(test)
    }

    pub fn get_environment() -> String {
        std::env::var("ENVIRONMENT")
            .unwrap_or_else(|_| {
                if cfg!(debug_assertions) {
                    "development".to_string()
                } else {
                    "production".to_string()
                }
            })
    }
}

/// Retry utility for resilient operations
/// I'm implementing retry logic with exponential backoff
pub struct RetryConfig {
    pub max_attempts: u32,
    pub initial_delay: Duration,
    pub max_delay: Duration,
    pub multiplier: f64,
}

impl Default for RetryConfig {
    fn default() -> Self {
        Self {
            max_attempts: 3,
            initial_delay: Duration::from_millis(100),
            max_delay: Duration::from_secs(30),
            multiplier: 2.0,
        }
    }
}

pub async fn retry_with_backoff<F, T, E>(
    operation: F,
    config: RetryConfig,
) -> std::result::Result<T, E>
where
    F: Fn() -> std::pin::Pin<Box<dyn std::future::Future<Output = std::result::Result<T, E>> + Send>>,
    E: std::fmt::Debug,
{
    let mut current_delay = config.initial_delay;

    for attempt in 1..=config.max_attempts {
        match operation().await {
            Ok(result) => return Ok(result),
            Err(error) => {
                if attempt == config.max_attempts {
                    return Err(error);
                }

                tracing::warn!("Operation failed (attempt {}/{}): {:?}", attempt, config.max_attempts, error);

                tokio::time::sleep(current_delay).await;

                current_delay = Duration::from_millis(
                    ((current_delay.as_millis() as f64) * config.multiplier) as u64
                ).min(config.max_delay);
            }
        }
    }

    unreachable!()
}

/// Circuit breaker pattern implementation
/// I'm implementing circuit breaker for service resilience
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum CircuitState {
    Closed,
    Open,
    HalfOpen,
}

pub struct CircuitBreaker {
    state: std::sync::Mutex<CircuitState>,
    failure_count: std::sync::Mutex<u32>,
    last_failure_time: std::sync::Mutex<Option<Instant>>,
    failure_threshold: u32,
    timeout: Duration,
}

impl CircuitBreaker {
    pub fn new(failure_threshold: u32, timeout: Duration) -> Self {
        Self {
            state: std::sync::Mutex::new(CircuitState::Closed),
            failure_count: std::sync::Mutex::new(0),
            last_failure_time: std::sync::Mutex::new(None),
            failure_threshold,
            timeout,
        }
    }

    pub fn call<F, T, E>(&self, operation: F) -> std::result::Result<T, E>
    where
        F: FnOnce() -> std::result::Result<T, E>,
        E: From<AppError>,
    {
        // First, check the current state and decide if we can proceed or need to transition
        let can_proceed = {
            let mut current_state_guard = self.state.lock().unwrap(); // Lock to read and potentially modify
            match *current_state_guard {
                CircuitState::Closed => true,
                CircuitState::HalfOpen => true, // Allow one attempt in HalfOpen
                CircuitState::Open => {
                    let last_failure_time_guard = self.last_failure_time.lock().unwrap();
                    if let Some(last_failure) = *last_failure_time_guard {
                        if Instant::now().duration_since(last_failure) > self.timeout {
                            // Timeout has passed, transition to HalfOpen
                            info!("CircuitBreaker: Timeout elapsed, transitioning from Open to HalfOpen.");
                            *current_state_guard = CircuitState::HalfOpen;
                            true // Allow this call as the first attempt in HalfOpen
                        } else {
                            // Still in Open state, timeout not elapsed
                            false
                        }
                    } else {
                        // Should not happen if last_failure_time is always set on failure
                        // but if it does, stay open.
                        warn!("CircuitBreaker: In Open state but no last_failure_time recorded.");
                        false
                    }
                }
            }
        };

        if !can_proceed {
            return Err(AppError::ServiceUnavailableError(
                "Circuit breaker is OPEN".to_string(),
            )
            .into());
        }

        // If we can proceed, attempt the operation
        match operation() {
            Ok(result) => {
                // Operation succeeded
                let mut current_state_guard = self.state.lock().unwrap();
                if *current_state_guard == CircuitState::HalfOpen {
                    info!("CircuitBreaker: Successful call in HalfOpen state, transitioning to Closed.");
                }
                *current_state_guard = CircuitState::Closed;
                *self.failure_count.lock().unwrap() = 0;
                *self.last_failure_time.lock().unwrap() = None; // Clear last failure time
                Ok(result)
            }
            Err(error) => {
                // Operation failed
                let mut failure_count_guard = self.failure_count.lock().unwrap();
                let mut current_state_guard = self.state.lock().unwrap();
                let mut last_failure_time_guard = self.last_failure_time.lock().unwrap();

                *failure_count_guard += 1;
                *last_failure_time_guard = Some(Instant::now());

                if *current_state_guard == CircuitState::HalfOpen {
                    // Failure in HalfOpen state, trip back to Open
                    info!("CircuitBreaker: Failure in HalfOpen state, transitioning back to Open.");
                    *current_state_guard = CircuitState::Open;
                } else if *failure_count_guard >= self.failure_threshold {
                    // Failure threshold reached in Closed state, trip to Open
                    info!("CircuitBreaker: Failure threshold reached, transitioning from Closed to Open.");
                    *current_state_guard = CircuitState::Open;
                }
                Err(error)
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_format_bytes() {
        assert_eq!(Utils::format_bytes(0), "0 B");
        assert_eq!(Utils::format_bytes(1024), "1.0 KB");
        assert_eq!(Utils::format_bytes(1048576), "1.0 MB");
        assert_eq!(Utils::format_bytes(1073741824), "1.0 GB");
    }

    #[test]
    fn test_parse_size() {
        assert_eq!(Utils::parse_size("1024").unwrap(), 1024);
        assert_eq!(Utils::parse_size("1KB").unwrap(), 1024);
        assert_eq!(Utils::parse_size("1MB").unwrap(), 1048576);
        assert_eq!(Utils::parse_size("1GB").unwrap(), 1073741824);
    }

    #[test]
    fn test_truncate_string() {
        assert_eq!(Utils::truncate_string("hello", 10), "hello");
        assert_eq!(Utils::truncate_string("hello world", 8), "hello...");
        assert_eq!(Utils::truncate_string("hi", 2), "hi");
    }

    #[test]
    fn test_calculate_percentile() {
        let values = vec![1.0, 2.0, 3.0, 4.0, 5.0];
        assert_eq!(Utils::calculate_percentile(&values, 50.0), Some(3.0));
        assert_eq!(Utils::calculate_percentile(&values, 0.0), Some(1.0));
        assert_eq!(Utils::calculate_percentile(&values, 100.0), Some(5.0));
    }

    #[test]
    fn test_rate_limiter() {
        let limiter = RateLimiter::new(2, Duration::from_secs(1));

        assert!(limiter.is_allowed());
        assert!(limiter.is_allowed());
        assert!(!limiter.is_allowed()); // Should be rate limited
    }

    #[test]
    fn test_email_validation() {
        assert!(Utils::is_valid_email("test@example.com"));
        assert!(!Utils::is_valid_email("invalid-email"));
        assert!(!Utils::is_valid_email("@example.com"));
    }

    #[test]
    fn test_url_validation() {
        assert!(Utils::is_valid_url("https://example.com"));
        assert!(Utils::is_valid_url("http://example.com"));
        assert!(!Utils::is_valid_url("ftp://example.com"));
        assert!(!Utils::is_valid_url("example.com"));
    }
}
</file>

<file path="src/lib.rs">
/*
 * Core library module for the dark performance showcase backend, organizing all modules and exposing public APIs.
 * I'm setting up a clean module structure with proper error handling, database integration, and performance monitoring capabilities.
 */

// Module declarations - I'm organizing code into logical service layers
pub mod database;
pub mod models;
pub mod routes;
pub mod services;
pub mod utils;

// Re-export commonly used types and utilities for internal use
pub use utils::{
    config::Config,
    error::{AppError, Result},
    metrics::MetricsCollector,
};

// Re-export database utilities
pub use database::{
    connection::{DatabasePool, create_pool},
};

// Re-export core models for external API usage
pub use models::{
    github::{Repository, RepositoryStats, GitHubUser},
    fractals::{FractalRequest, FractalResponse, FractalType},
    performance::{PerformanceMetric, SystemInfo, BenchmarkResult},
};

// Re-export service layer for application logic
pub use services::{
    github_service::GitHubService,
    fractal_service::FractalService,
    performance_service::PerformanceService,
    cache_service::CacheService,
};

// Core application state that I'll share across handlers
#[derive(Clone)]
pub struct AppState {
    pub db_pool: DatabasePool,
    pub redis_client: redis::Client,
    pub github_service: GitHubService,
    pub fractal_service: FractalService,
    pub performance_service: PerformanceService,
    pub cache_service: CacheService,
    pub config: Config,
    pub metrics: MetricsCollector,
}

impl AppState {
    /// Creates new application state with all initialized services
    /// I'm ensuring all dependencies are properly connected and configured
    pub async fn new(config: Config) -> Result<Self> {
        // Initialize database connection pool with optimized settings
        let db_pool = create_pool(&config.database_url).await?;

        // Initialize Redis client with connection pooling
        let redis_client = redis::Client::open(config.redis_url.clone())
            .map_err(|e| AppError::DatabaseError(format!("Redis connection failed: {}", e)))?;

        // Initialize metrics collector for performance monitoring
        let metrics = MetricsCollector::new()?;

        // Initialize service layer with shared dependencies
        let cache_service = CacheService::new(redis_client.clone());
        let github_service = GitHubService::new(
            config.github_token.clone(),
            cache_service.clone(),
        );
        let fractal_service = FractalService::new();
        let performance_service = PerformanceService::new(
            db_pool.clone(),
        );

        Ok(AppState {
            db_pool,
            redis_client,
            github_service,
            fractal_service,
            performance_service,
            cache_service,
            config,
            metrics,
        })
    }

    /// Health check that verifies all critical services are operational
    /// I'm checking database connectivity, Redis availability, and service health
    pub async fn health_check(&self) -> Result<serde_json::Value> {
        use sqlx::Row;

        // Test database connectivity
        let db_status = match sqlx::query("SELECT 1 as test")
            .fetch_one(&self.db_pool)
            .await
        {
            Ok(_) => "healthy",
            Err(_) => "unhealthy",
        };

        // Test Redis connectivity
        let mut conn = self.redis_client.get_async_connection().await
            .map_err(|e| AppError::DatabaseError(format!("Redis connection failed: {}", e)))?;

        let redis_status = match redis::cmd("PING")
            .query_async::<_, String>(&mut conn)
            .await
        {
            Ok(_) => "healthy",
            Err(_) => "unhealthy",
        };

        // Get system performance metrics
        let system_info_json = self.performance_service.get_system_info().await?;

        Ok(serde_json::json!({
            "status": if db_status == "healthy" && redis_status == "healthy" { "healthy" } else { "unhealthy" },
            "timestamp": chrono::Utc::now(),
            "services": {
                "database": db_status,
                "redis": redis_status,
                "github_api": "healthy", // GitHub service handles its own health
                "fractal_engine": "healthy"
            },
            health_status["system"] = serde_json::json!({
                "cpu_usage": system_info_json["cpu_usage_percent"].as_f64().unwrap_or_default(),
                "memory_usage": system_info_json["memory_usage_percent"].as_f64().unwrap_or_default(),
                "uptime_seconds": system_info_json["uptime_seconds"].as_u64().unwrap_or_default(),
                "active_processes": system_info_json["processes_count"].as_u64().unwrap_or_default()
            },
            "version": env!("CARGO_PKG_VERSION"),
            "build_time": env!("BUILD_TIME"),
            "git_commit": env!("GIT_COMMIT")
        }))
    }

    /// Graceful shutdown that cleans up resources and connections
    /// I'm ensuring all background tasks complete and connections are properly closed
    pub async fn shutdown(&self) -> Result<()> {
        tracing::info!("Initiating graceful shutdown");

        // Flush any pending metrics
        self.metrics.flush().await?;

        // Close database pool gracefully
        self.db_pool.close().await;

        tracing::info!("Graceful shutdown completed");
        Ok(())
    }
}

// Helper macros for common operations that I use throughout the application

/// Macro for timing operations and collecting performance metrics
/// I'm making it easy to track performance across all service calls
#[macro_export]
macro_rules! time_operation {
    ($metrics:expr, $operation:expr, $code:block) => {{
        let start = std::time::Instant::now();
        let result = $code;
        let duration = start.elapsed();

        $metrics.record_operation_time($operation, duration.as_millis() as f64).await;

        result
    }};
}

/// Macro for caching expensive operations with automatic TTL
/// I'm simplifying cache usage patterns across services
#[macro_export]
macro_rules! cached_operation {
    ($cache:expr, $key:expr, $ttl:expr, $operation:block) => {{
        match $cache.get($key).await {
            Ok(Some(cached)) => Ok(cached),
            _ => {
                let result = $operation;
                if let Ok(ref value) = result {
                    let _ = $cache.set($key, value, $ttl).await;
                }
                result
            }
        }
    }};
}

// Integration tests module - I'm setting up comprehensive testing
#[cfg(test)]
mod tests {
    use super::*;
    use tokio_test;

    #[tokio::test]
    async fn test_app_state_creation() {
        // I'm testing that the application state can be created in test environment
        let config = Config::from_env().expect("Test configuration should be valid");
        let app_state = AppState::new(config).await;

        assert!(app_state.is_ok(), "App state creation should succeed");
    }

    #[tokio::test]
    async fn test_health_check() {
        let config = Config::from_env().expect("Test configuration should be valid");
        let app_state = AppState::new(config).await.expect("App state should be created");

        let health = app_state.health_check().await;
        assert!(health.is_ok(), "Health check should return successfully");

        let health_json = health.unwrap();
        assert!(health_json["status"].is_string(), "Health status should be present");
        assert!(health_json["services"].is_object(), "Services status should be present");
    }
}

// Performance benchmarks - I'm including criterion benchmarks for performance regression testing
#[cfg(feature = "bench")]
pub mod benchmarks {
    use criterion::{black_box, criterion_group, criterion_main, Criterion};
    use super::*;

    fn bench_fractal_generation(c: &mut Criterion) {
        let rt = tokio::runtime::Runtime::new().unwrap();
        let fractal_service = FractalService::new();

        c.bench_function("mandelbrot_512x512", |b| {
            b.iter(|| {
                rt.block_on(async {
                    let request = FractalRequest {
                        width: 512,
                        height: 512,
                        center_x: -0.5,
                        center_y: 0.0,
                        zoom: 1.0,
                        max_iterations: 100,
                        fractal_type: FractalType::Mandelbrot,
                    };
                    black_box(fractal_service.generate_mandelbrot(request))
                })
            })
        });
    }

    fn bench_performance_metrics(c: &mut Criterion) {
        let rt = tokio::runtime::Runtime::new().unwrap();

        c.bench_function("metrics_collection", |b| {
            b.iter(|| {
                rt.block_on(async {
                    let metrics = MetricsCollector::new().unwrap();
                    black_box(metrics.collect_system_metrics().await)
                })
            })
        });
    }

    criterion_group!(benches, bench_fractal_generation, bench_performance_metrics);
    criterion_main!(benches);
}

// Feature flags for optional functionality
#[cfg(feature = "gpu-acceleration")]
pub mod gpu {
    //! GPU acceleration module for fractal generation using CUDA or OpenCL
    //! I'm keeping this optional since not all deployment environments have GPU support

    pub use crate::services::fractal_service::gpu_accelerated_generation;
}

#[cfg(feature = "machine-learning")]
pub mod ml {
    //! Machine learning module for performance prediction and optimization
    //! I'm including ML features for advanced performance analysis

    pub use crate::services::performance_service::ml_performance_prediction;
}

// Export version and build information
pub const VERSION: &str = env!("CARGO_PKG_VERSION");
pub const BUILD_TIME: &str = env!("BUILD_TIME");
pub const GIT_COMMIT: &str = env!("GIT_COMMIT");

// Export common async utilities
pub mod async_utils {
    //! Async utilities and helpers for improved performance and error handling
    //! I'm providing common patterns for async operations throughout the application

    use std::future::Future;
    use std::time::Duration;
    use tokio::time::{timeout, sleep};
    use crate::utils::error::{AppError, Result};

    /// Retry an async operation with exponential backoff
    /// I'm implementing resilient patterns for external API calls
    pub async fn retry_with_backoff<F, Fut, T>(
        mut operation: F,
        max_retries: usize,
        initial_delay: Duration,
    ) -> Result<T>
    where
        F: FnMut() -> Fut,
        Fut: Future<Output = Result<T>>,
    {
        let mut delay = initial_delay;

        for attempt in 0..max_retries {
            match operation().await {
                Ok(result) => return Ok(result),
                Err(e) if attempt == max_retries - 1 => return Err(e),
                Err(_) => {
                    sleep(delay).await;
                    delay = delay.mul_f32(1.5); // Exponential backoff
                }
            }
        }

        unreachable!()
    }

    /// Execute operation with timeout
    /// I'm ensuring no operation can hang indefinitely
    pub async fn with_timeout<F, T>(
        operation: F,
        timeout_duration: Duration,
    ) -> Result<T>
    where
        F: Future<Output = Result<T>>,
    {
        timeout(timeout_duration, operation)
            .await
            .map_err(|_| AppError::TimeoutError("Operation timed out".to_string()))?
    }
}
</file>

<file path="src/main.rs">
/*
 * Main application state and startup logic orchestrating all services for the dark performance showcase backend.
 * I'm implementing comprehensive application initialization with service integration, configuration management, and graceful shutdown handling.
 */

use axum::{
    routing::{get, post},
    Router,
    middleware,
    http::{header, Method},
};

use tower::ServiceBuilder;

use tower_http::{
    cors::{Any, CorsLayer},
    compression::CompressionLayer,
    trace::TraceLayer,
};
use std::net::SocketAddr;
use std::sync::Arc;
use tracing::{info, warn, error};
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};
use tokio::signal;

use crate::{
    routes,
    services::{
        github_service::GitHubService,
        fractal_service::FractalService,
        cache_service::CacheService,
    },
    utils::{
        config::Config,
        error::{AppError, Result},
    },
    database::{
        connection::{create_pool_with_config, DatabasePool},
    },
};

/// Main application state containing all services and configuration
/// I'm creating a comprehensive state structure that provides access to all application services
#[derive(Clone)]
pub struct AppState {
    pub config: Config,
    pub db_pool: DatabasePool,
    pub redis_client: redis::Client,
    pub github_service: GitHubService,
    pub fractal_service: FractalService,
    pub cache_service: CacheService,
}

impl AppState {
    /// Create new application state with all initialized services
    /// I'm implementing comprehensive service initialization with error handling
    pub async fn new() -> Result<Self> {
        info!("Initializing application state");

        // Load configuration from environment
        let config = Config::from_env()?;
        info!("Configuration loaded for environment: {:?}", config.environment);

        // Initialize database connection pool
        let db_pool = create_pool_with_config(&config.database_url, &config.database_pool_config()).await?;
        info!("Database connection pool initialized with {} connections", db_pool.size());

        // Initialize Redis client
        let redis_client = redis::Client::open(config.redis_url.clone())
            .map_err(|e| AppError::CacheError(format!("Failed to create Redis client: {}", e)))?;
        info!("Redis client initialized");

        // Initialize cache service
        let cache_service = CacheService::with_config(
            redis_client.clone(),
            "perf_showcase:".to_string(),
            config.cache_default_ttl,
        );

        // Test cache connection
        match cache_service.health_check().await {
            Ok(_) => info!("Cache service health check passed"),
            Err(e) => warn!("Cache service health check failed: {}", e),
        }

        // Initialize GitHub service
        let github_service = GitHubService::new(config.github_token.clone(), cache_service.clone());
        info!("GitHub service initialized");

        // Initialize fractal service
        let fractal_service = FractalService::new();
        info!("Fractal service initialized");

        let app_state = Self {
            config,
            db_pool,
            redis_client,
            github_service,
            fractal_service,
            cache_service,
        };

        info!("Application state initialized successfully");
        Ok(app_state)
    }

    /// Run database migrations if needed
    /// I'm providing database migration support for deployment automation
    pub async fn migrate_database(&self) -> Result<()> {
        info!("Running database migrations");

        match sqlx::migrate!("src/database/migrations").run(&self.db_pool).await {
            Ok(_) => {
                info!("Database migrations completed successfully");
                Ok(())
            }
            Err(e) => {
                error!("Database migration failed: {}", e);
                Err(AppError::DatabaseError(format!("Migration failed: {}", e)))
            }
        }
    }

    /// Perform application health check
    /// I'm implementing comprehensive health verification across all services
    pub async fn health_check(&self) -> Result<serde_json::Value> {
        info!("Performing application health check");

        let mut health_status = serde_json::json!({
            "status": "healthy",
            "timestamp": chrono::Utc::now(),
            "services": {}
        });

        // Database health check
        match sqlx::query("SELECT 1 as health").fetch_one(&self.db_pool).await {
            Ok(_) => {
                health_status["services"]["database"] = serde_json::json!({
                    "status": "healthy",
                    "connections": self.db_pool.size(),
                    "idle_connections": self.db_pool.num_idle()
                });
            }
            Err(e) => {
                health_status["services"]["database"] = serde_json::json!({
                    "status": "unhealthy",
                    "error": e.to_string()
                });
                health_status["status"] = "degraded".into();
            }
        }

        // Cache health check
        match self.cache_service.health_check().await {
            Ok(cache_health) => {
                health_status["services"]["cache"] = cache_health;
            }
            Err(e) => {
                health_status["services"]["cache"] = serde_json::json!({
                    "status": "unhealthy",
                    "error": e.to_string()
                });
                health_status["status"] = "degraded".into();
            }
        }

        // GitHub service health check
        match self.github_service.get_rate_limit_status().await {
            Ok(rate_limit) => {
                health_status["services"]["github"] = serde_json::json!({
                    "status": if rate_limit.remaining > 100 { "healthy" } else { "degraded" },
                    "rate_limit": {
                        "remaining": rate_limit.remaining,
                        "limit": rate_limit.limit,
                        "reset_time": rate_limit.reset
                    }
                });
            }
            Err(e) => {
                health_status["services"]["github"] = serde_json::json!({
                    "status": "degraded",
                    "error": e.to_string()
                });
            }
        }

        // Fractal service health check (simple test)
        let fractal_health = tokio::task::spawn_blocking(|| {
            // Simple fractal computation test
            use crate::services::fractal_service::{FractalRequest, FractalType};
            let service = FractalService::new();
            let test_request = FractalRequest {
                width: 32,
                height: 32,
                center_x: -0.5,
                center_y: 0.0,
                zoom: 1.0,
                max_iterations: 50,
                fractal_type: FractalType::Mandelbrot,
            };
            service.generate_mandelbrot(test_request)
        }).await;

        match fractal_health {
            Ok(result) => {
                health_status["services"]["fractals"] = serde_json::json!({
                    "status": "healthy",
                    "test_computation_time_ms": result.computation_time_ms,
                    "parallel_processing": true
                });
            }
            Err(e) => {
                health_status["services"]["fractals"] = serde_json::json!({
                    "status": "unhealthy",
                    "error": e.to_string()
                });
                health_status["status"] = "degraded".into();
            }
        }

        Ok(health_status)
    }

    /// Get application statistics and metrics
    /// I'm providing comprehensive application insights for monitoring
    pub async fn get_app_stats(&self) -> Result<serde_json::Value> {
        let stats = serde_json::json!({
            "timestamp": chrono::Utc::now(),
            "environment": self.config.environment,
            "version": env!("CARGO_PKG_VERSION"),
            "build_info": {
                "rust_version": env!("CARGO_PKG_RUST_VERSION"),
                "build_time": env!("BUILD_TIME").unwrap_or("unknown"),
                "git_commit": env!("GIT_COMMIT").unwrap_or("unknown"),
                "debug_build": cfg!(debug_assertions),
            },
            "database": {
                "pool_size": self.db_pool.size(),
                "idle_connections": self.db_pool.num_idle(),
                "active_connections": self.db_pool.size() - self.db_pool.num_idle(),
            },
            "cache": match self.cache_service.get_stats().await {
                Ok(stats) => serde_json::to_value(stats).unwrap_or_default(),
                Err(_) => serde_json::json!({"status": "unavailable"}),
            },
            "configuration": {
                "fractal_limits": {
                    "max_width": self.config.fractal_max_width,
                    "max_height": self.config.fractal_max_height,
                    "max_iterations": self.config.fractal_max_iterations,
                    "max_zoom": self.config.fractal_max_zoom,
                },
                "performance": {
                    "metrics_enabled": self.config.metrics_enabled,
                    "cache_enabled": self.config.cache_enabled,
                    "rate_limiting_enabled": self.config.rate_limit_enabled,
                }
            }
        });

        Ok(stats)
    }
}

/// Create the complete application router with all middleware and routes
/// I'm implementing the full routing structure with comprehensive middleware stack
pub fn create_app_router(app_state: AppState) -> Router {
    info!("Creating application router");
    routes::create_versioned_router()
        .layer(routes::create_middleware_stack(&app_state.config))
        .route("/metrics", get(prometheus_metrics))
        .with_state(app_state)
}




/// Prometheus metrics endpoint
/// I'm providing metrics in Prometheus format for monitoring integration
async fn prometheus_metrics() -> Result<String, AppError> {
    let metrics = format!(
        "# HELP app_requests_total Total number of requests\n\
         # TYPE app_requests_total counter\n\
         app_requests_total{{method=\"GET\",endpoint=\"/api/github/repos\"}} 0\n\
         app_requests_total{{method=\"POST\",endpoint=\"/api/fractals/mandelbrot\"}} 0\n\
         \n\
         # HELP app_request_duration_seconds Request duration in seconds\n\
         # TYPE app_request_duration_seconds histogram\n\
         app_request_duration_seconds_bucket{{le=\"0.1\"}} 0\n\
         app_request_duration_seconds_bucket{{le=\"0.5\"}} 0\n\
         app_request_duration_seconds_bucket{{le=\"1.0\"}} 0\n\
         app_request_duration_seconds_bucket{{le=\"+Inf\"}} 0\n\
         \n\
         # HELP app_info Application information\n\
         # TYPE app_info gauge\n\
         app_info{{version=\"{}\",rust_version=\"{}\"}} 1\n",
        env!("CARGO_PKG_VERSION"),
        rust_version: option_env!("BUILD_RUST_VERSION").unwrap_or("unknown").to_string(),
    );

    Ok(metrics)
}

/// Main application entry point
/// I'm implementing comprehensive application startup with proper error handling
#[tokio::main]
pub async fn main() -> Result<()> {
    // Initialize logging
    tracing_subscriber::registry()
        .with(tracing_subscriber::EnvFilter::new(
            std::env::var("RUST_LOG").unwrap_or_else(|_| "info".into()),
        ))
        .with(tracing_subscriber::fmt::layer())
        .init();

    info!("Starting Dark Performance Showcase backend");

    // Initialize application state
    let app_state = AppState::new().await?;

    // Run database migrations
    app_state.migrate_database().await?;

    // Perform initial health check
    match app_state.health_check().await {
        Ok(health) => info!("Initial health check passed: {}", health["status"]),
        Err(e) => warn!("Initial health check failed: {}", e),
    }

    // Create application router
    let app = create_app_router(app_state.clone());

    // Get server address from configuration
    let addr = app_state.config.socket_addr()?;
    info!("Server starting on {}", addr);

    // Start the server with graceful shutdown
    let listener = tokio::net::TcpListener::bind(&addr).await
        .map_err(|e| AppError::ConfigurationError(format!("Failed to bind to address {}: {}", addr, e)))?;

    info!(" Dark Performance Showcase backend is running on {}", addr);
    info!(" Frontend URL: {}", app_state.config.frontend_url);
    info!(" Metrics available at: http://{}/metrics", addr);
    info!(" Health check available at: http://{}/health", addr);

    // Run server with graceful shutdown
    axum::serve(listener, app)
        .with_graceful_shutdown(shutdown_signal())
        .await
        .map_err(|e| AppError::InternalServerError(format!("Server error: {}", e)))?;

    info!("Server shutting down gracefully");
    Ok(())
}

/// Handle graceful shutdown signals
/// I'm implementing proper signal handling for clean server shutdown
async fn shutdown_signal() {
    let ctrl_c = async {
        signal::ctrl_c()
            .await
            .expect("failed to install Ctrl+C handler");
    };

    #[cfg(unix)]
    let terminate = async {
        signal::unix::signal(signal::unix::SignalKind::terminate())
            .expect("failed to install signal handler")
            .recv()
            .await;
    };

    #[cfg(not(unix))]
    let terminate = std::future::pending::<()>();

    tokio::select! {
        _ = ctrl_c => {},
        _ = terminate => {},
    }

    info!("Shutdown signal received, starting graceful shutdown");
}
</file>

<file path="build.rs">
/*
 * Build script for compile-time optimizations and environment configuration.
 * I'm setting up build-time constants, feature detection, and performance optimization flags for maximum runtime performance.
 */

use std::env;
use std::process::Command;

fn main() {
    // I'm setting up build-time environment variables for runtime access
    println!("cargo:rerun-if-changed=build.rs");
    println!("cargo:rerun-if-env-changed=DATABASE_URL");
    println!("cargo:rerun-if-env-changed=REDIS_URL");

    // Capture build timestamp for version information
    let build_time = chrono::Utc::now().format("%Y-%m-%d %H:%M:%S UTC");
    println!("cargo:rustc-env=BUILD_TIME={}", build_time);

    // Capture git commit hash if available
    if let Ok(output) = Command::new("git")
        .args(&["rev-parse", "--short", "HEAD"])
        .output()
        {
            if let Ok(git_hash) = String::from_utf8(output.stdout) {
                let git_hash = git_hash.trim();
                println!("cargo:rustc-env=GIT_COMMIT={}", git_hash);
            } else {
                println!("cargo:rustc-env=GIT_COMMIT=unknown");
            }
        } else {
            println!("cargo:rustc-env=GIT_COMMIT=unknown");
        }

        // Detect CPU features for optimization
        let target_arch = env::var("CARGO_CFG_TARGET_ARCH").unwrap_or_default();
        let target_os = env::var("CARGO_CFG_TARGET_OS").unwrap_or_default();

        println!("cargo:rustc-env=TARGET_ARCH={}", target_arch);
        println!("cargo:rustc-env=TARGET_OS={}", target_os);

        // Enable CPU-specific optimizations based on target
        match target_arch.as_str() {
            "x86_64" => {
                println!("cargo:rustc-cfg=has_avx2");
                println!("cargo:rustc-cfg=has_sse4_2");

                // Check for AVX-512 support if building for native target
                if env::var("CARGO_CFG_TARGET_FEATURE").unwrap_or_default().contains("avx512") {
                    println!("cargo:rustc-cfg=has_avx512");
                }
            }
            "aarch64" => {
                println!("cargo:rustc-cfg=has_neon");
            }
            _ => {}
        }

        // Configure memory allocator based on features
        if cfg!(feature = "jemalloc") {
            println!("cargo:rustc-cfg=allocator_jemalloc");
        } else if cfg!(feature = "mimalloc") {
            println!("cargo:rustc-cfg=allocator_mimalloc");
        }

        // Database feature detection for conditional compilation
        if cfg!(feature = "postgres") {
            println!("cargo:rustc-cfg=database_postgres");
        }
        if cfg!(feature = "redis") {
            println!("cargo:rustc-cfg=cache_redis");
        }

        // Performance optimization flags based on profile
        let profile = env::var("PROFILE").unwrap_or_default();
        match profile.as_str() {
            "release" | "production" => {
                // I'm enabling maximum optimizations for production builds
                println!("cargo:rustc-cfg=optimized_build");

                // Link-time optimization settings are handled in Cargo.toml
                // but I can add additional flags here if needed
                if target_os == "linux" {
                    println!("cargo:rustc-link-arg=-Wl,--strip-all");
                }
            }
            "dev" | "debug" => {
                println!("cargo:rustc-cfg=debug_build");
            }
            _ => {}
        }

        // Enable SIMD optimizations if supported
        if is_simd_supported(&target_arch) {
            println!("cargo:rustc-cfg=simd_enabled");
        }

        // Configure fractal computation optimizations
        setup_fractal_optimizations();

        // Set up database migration embedding if needed
        setup_database_migrations();

        // Configure performance monitoring
        setup_performance_monitoring();

    let rustc_version_output = std::process::Command::new("rustc")
        .arg("--version")
        .output()
        .expect("Failed to get rustc version");
    let rustc_version_str = String::from_utf8(rustc_version_output.stdout)
        .expect("rustc --version output is not valid UTF-8");
    let rust_version_short = rustc_version_str.split_whitespace().nth(1).unwrap_or("unknown");
    println!("cargo:rustc-env=BUILD_RUST_VERSION={}", rust_version_short);

    // Ensure build script reruns if it changes
    println!("cargo:rerun-if-changed=build.rs");
}

/// Check if SIMD instructions are supported for the target architecture
fn is_simd_supported(target_arch: &str) -> bool {
    match target_arch {
        "x86_64" => true,  // SSE2 is guaranteed on x86_64
        "aarch64" => true, // NEON is standard on AArch64
        _ => false,
    }
}

/// Set up fractal computation optimizations based on available CPU features
fn setup_fractal_optimizations() {
    // I'm configuring parallel processing parameters based on CPU capabilities
    let num_cpus = std::thread::available_parallelism()
    .map(|n| n.get())
    .unwrap_or(4);

    println!("cargo:rustc-env=NUM_CPUS={}", num_cpus);

    // Configure optimal thread count for Rayon
    let optimal_threads = if num_cpus > 8 {
        num_cpus - 2 // Leave some cores for other tasks
    } else {
        num_cpus
    };

    println!("cargo:rustc-env=RAYON_NUM_THREADS={}", optimal_threads);

    // Set up mathematical precision based on target
    if cfg!(target_feature = "fma") {
        println!("cargo:rustc-cfg=has_fused_multiply_add");
    }
}

/// Set up database migration embedding for production builds
fn setup_database_migrations() {
    // I'm embedding migration files into the binary for production deployment
    let migrations_dir = "database/migrations";

    if std::path::Path::new(migrations_dir).exists() {
        println!("cargo:rerun-if-changed={}", migrations_dir);

        // Walk through migration files and set up rerun triggers
        if let Ok(entries) = std::fs::read_dir(migrations_dir) {
            for entry in entries.flatten() {
                if let Some(path) = entry.path().to_str() {
                    if path.ends_with(".sql") {
                        println!("cargo:rerun-if-changed={}", path);
                    }
                }
            }
        }
    }
}

/// Configure performance monitoring and metrics collection
fn setup_performance_monitoring() {
    // I'm setting up compile-time configuration for metrics collection
    if cfg!(feature = "metrics") {
        println!("cargo:rustc-cfg=metrics_enabled");

        // Configure metrics collection interval based on build type
        let profile = env::var("PROFILE").unwrap_or_default();
        let metrics_interval = match profile.as_str() {
            "release" | "production" => 60,  // 1 minute in production
            _ => 10,  // 10 seconds in development
        };

        println!("cargo:rustc-env=METRICS_INTERVAL_SECONDS={}", metrics_interval);
    }

    // Configure tracing based on environment
    if cfg!(feature = "tracing") {
        println!("cargo:rustc-cfg=tracing_enabled");
    }
}

// Custom build configuration for different deployment targets
#[cfg(feature = "docker-build")]
fn configure_docker_build() {
    // I'm setting up Docker-specific optimizations
    println!("cargo:rustc-cfg=docker_deployment");

    // Configure for container resource limits
    println!("cargo:rustc-env=CONTAINER_BUILD=true");
}

#[cfg(feature = "cloud-build")]
fn configure_cloud_build() {
    // I'm setting up cloud deployment optimizations
    println!("cargo:rustc-cfg=cloud_deployment");

    // Configure for cloud-specific features
    if env::var("GOOGLE_CLOUD_PROJECT").is_ok() {
        println!("cargo:rustc-cfg=google_cloud");
    }

    if env::var("AWS_REGION").is_ok() {
        println!("cargo:rustc-cfg=aws_deployment");
    }
}
</file>

<file path="Cargo.toml">
# Rust backend manifest for the dark performance showcase with maximum optimization settings.
# I'm configuring for both development productivity and production performance with comprehensive dependency management.

[package]
name = "dark-performance-backend"
version = "0.1.0"
edition = "2021"
authors = ["Carter Perez carterperez@certgames.com. https://certgames.com"]
description = "High-performance backend showcasing Rust's computational capabilities. https://certgames.com"
repository = "https://github.com/CarterPerez-dev/kill-pr0cess.inc"
license = "MIT"
readme = "README.md"
keywords = ["performance", "fractals", "github", "api", "rust"]
categories = ["web-programming", "api-bindings", "mathematics"]

# Build configuration with maximum optimization
[profile.release]
opt-level = 3              # Maximum optimization
lto = "fat"               # Full link-time optimization
codegen-units = 1         # Single codegen unit for maximum optimization
panic = "abort"           # Smaller binary size and faster panics
strip = true              # Remove debug symbols in release
overflow-checks = false   # Disable integer overflow checks for performance

[profile.dev]
opt-level = 1             # Some optimization in debug builds for better dev experience
debug = true              # Full debug info
overflow-checks = true    # Keep overflow checks in development

# Production profile with balanced optimization and debugging
[profile.production]
inherits = "release"
debug = 1                 # Minimal debug info for production debugging
strip = "debuginfo"       # Keep symbols but remove debug info

# Benchmark profile for criterion
[profile.bench]
opt-level = 3
debug = false
lto = "fat"

[dependencies]
# Web framework - I'm using Axum for maximum async performance
axum = { version = "0.7", features = ["macros", "multipart", "ws"] }
tokio = { version = "1.0", features = ["full", "tracing"] }
tower = { version = "0.4", features = ["util", "timeout", "load-shed", "limit"] }
tower-http = { version = "0.5", features = ["cors", "compression-full", "trace", "auth", "request-id", "timeout", "limit"] }
hyper = { version = "1.0", features = ["full"] }

# Serialization and data handling
serde = { version = "1.0", features = ["derive", "rc"] }
serde_json = "1.0"
serde_yaml = "0.9"

# Database integration with comprehensive features
sqlx = { version = "0.7", features = [ "runtime-tokio-rustls", "postgres", "chrono", "uuid", "json", "migrate" ] }
redis = { version = "0.24", features = ["tokio-comp", "connection-manager", "streams"], optional = true }

# HTTP client with full feature set
reqwest = { version = "0.11", default-features = false, features = ["json", "stream", "multipart", "cookies", "rustls-tls"] }

# Async utilities and concurrency
futures = "0.3"
async-trait = "0.1"
async-stream = "0.3"
tokio-stream = "0.1"

# Configuration management
config = "0.14"
dotenvy = "0.15"
clap = { version = "4.4", features = ["derive", "env"] }

# Logging and observability
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json", "chrono"] }
tracing-opentelemetry = { version = "0.21", optional = true }
opentelemetry = { version = "0.20", features = ["rt-tokio"] }
opentelemetry-jaeger = "0.19"

# Error handling and validation
anyhow = "1.0"
thiserror = "1.0"
validator = { version = "0.16", features = ["derive"] }

# Mathematical computation for fractals
num-complex = "0.4"
num-traits = "0.2"
num_cpus = "1.16"
rayon = "1.8"
ndarray = "0.15"

# Performance monitoring and metrics
metrics = { version = "0.22", optional = true }
metrics-exporter-prometheus = { version = "0.13", default-features = false, optional = true }
metrics-util = "0.16"
sysinfo = "0.29"

# Time and date handling
chrono = { version = "0.4", features = ["serde", "clock"] }
time = "0.3"

# UUID and unique identifiers
uuid = { version = "1.0", features = ["v4", "serde", "fast-rng"] }
rand = "0.8"

# Memory management and optimization
once_cell = "1.19"
dashmap = "5.5"
parking_lot = "0.12"

# Security and authentication
argon2 = { version = "0.5", optional = true }
jsonwebtoken = { version = "9.1", optional = true }
hmac = "0.12"
sha2 = "0.10"

# Data compression and optimization
flate2 = "1.0"
brotli = "3.4"

# Template engine for dynamic content
tera = "1.19"
handlebars = "4.4"

# WebSocket support for real-time features
tokio-tungstenite = "0.20"

# Development and testing dependencies
[dev-dependencies]
criterion = { version = "0.5", features = ["html_reports", "async_tokio"] }
tokio-test = "0.4"
proptest = "1.4"
quickcheck = "1.0"
quickcheck_macros = "1.0"
mockall = "0.11"
wiremock = "0.5"
testcontainers = "0.15"
rstest = "0.18"

[build-dependencies]
chrono = "0.4"

# Optional feature flags for conditional compilation
[features]
default = ["postgres", "redis", "metrics"]

# Database backends
postgres = ["sqlx/postgres"]
mysql = ["sqlx/mysql"]
sqlite = ["sqlx/sqlite"]

# Cache backends
redis = ["dep:redis"]
memcached = []

# Performance monitoring
metrics = ["dep:metrics", "dep:metrics-exporter-prometheus"]
tracing = ["dep:tracing-opentelemetry"]

# Advanced features
gpu-acceleration = []
machine-learning = []
distributed-computing = []

# Security features
advanced-auth = ["dep:argon2", "dep:jsonwebtoken"]
rate-limiting = []

# Optimization features
jemalloc = ["tikv-jemallocator"]
mimalloc = ["dep:mimalloc"]

# Optional memory allocators for performance
[target.'cfg(not(target_env = "msvc"))'.dependencies]
tikv-jemallocator = { version = "0.5", optional = true }

[target.'cfg(not(target_env = "msvc"))'.dependencies.mimalloc]
version = "0.1"
optional = true
default-features = false


# Enable build script for compile-time configuration
build = "build.rs"

# Workspace configuration for multi-crate projects
[workspace]
members = ["."]

# Package metadata
[package.metadata.docs.rs]
all-features = true
rustdoc-args = ["--cfg", "docsrs"]

# Cargo-dist configuration for releases
[package.metadata.dist]
cargo-dist-version = "0.4.0"
ci = ["github"]
installers = ["shell", "powershell"]
targets = ["x86_64-unknown-linux-gnu", "x86_64-apple-darwin", "x86_64-pc-windows-msvc"]

# Performance optimization hints
[package.metadata.performance]
# I'm providing hints for runtime optimization
cpu-target = "native"
simd = true
parallel = true
memory-pool = true

# Clippy configuration for code quality
[lints.clippy]
# Performance lints - I want to catch performance issues early
needless_collect = "warn"
needless_pass_by_value = "warn"
trivially_copy_pass_by_ref = "warn"
clone_on_ref_ptr = "warn"
rc_buffer = "warn"

# Correctness lints
missing_errors_doc = "warn"
missing_panics_doc = "warn"
missing_safety_doc = "warn"

# Style lints for consistency
inconsistent_struct_constructor = "warn"
manual_let_else = "warn"
semicolon_if_nothing_returned = "warn"

[lints.rust]
unsafe_code = "forbid"
missing_docs = "warn"
unused_extern_crates = "warn"
unused_import_braces = "warn"

# Environment-specific configurations
[package.metadata.env.development]
rust_log = "debug"
database_max_connections = "10"

[package.metadata.env.production]
rust_log = "info"
database_max_connections = "100"

# Cargo configuration aliases for convenience
[package.metadata.scripts]
dev = "cargo run"
test-all = "cargo test --all-features"
bench-all = "cargo bench --all-features"
check-all = "cargo check --all-features && cargo clippy --all-features"
build-release = "cargo build --release --all-features"
build-prod = "cargo build --profile production --all-features"
</file>

<file path="Dockerfile.dev">
# Development Dockerfile for the Rust backend with hot reload and debugging capabilities.
# I'm optimizing for development speed with volume mounting and cargo watch for automatic rebuilds.

FROM rust:1.82-slim

# I'm installing development dependencies including cargo-watch for hot reload
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    libpq-dev \
    build-essential \
    git \
    curl \
    postgresql-client \
    redis-tools \
    && rm -rf /var/lib/apt/lists/*

RUN cargo install cargo-watch


WORKDIR /app

COPY --chown=developer:developer Cargo.toml ./Cargo.toml
COPY --chown=developer:developer src/database ./database

RUN mkdir -p src && echo "fn main() {}" > src/main.rs && cargo generate-lockfile
COPY --chown=developer:developer build.rs ./

# I'm creating a dummy src to cache dependencies
RUN cargo build
RUN rm -rf src

# I'm setting development environment variables
ENV RUST_LOG=debug
ENV RUST_BACKTRACE=1
ENV ENVIRONMENT=development
ENV PORT=3001

# I'm exposing the development port
EXPOSE 3001

# I'm using cargo-watch for hot reload during development
CMD ["cargo", "watch", "-x", "run"]
</file>

<file path="Dockerfile.prod">
# Production-optimized multi-stage Dockerfile for the Rust backend with maximum performance and minimal attack surface.
# I'm implementing comprehensive optimization including static linking, minimal base images, and security hardening for production deployment.

# Build stage with full development environment
FROM rust:1.82-slim as builder

# I'm setting up the build environment with necessary system dependencies
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    libpq-dev \
    build-essential \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# I'm creating a non-root user for security
RUN useradd -m -u 1001 -s /bin/bash builder
USER builder
WORKDIR /home/builder

# I'm copying dependency manifests first for better Docker layer caching
COPY --chown=builder:builder Cargo.toml Cargo.lock ./
COPY --chown=builder:builder build.rs ./
COPY --chown=builder:builder database ./database

# I'm creating a dummy src directory to cache dependencies
RUN mkdir src && echo "fn main() {}" > src/main.rs

# I'm pre-building dependencies for faster subsequent builds
RUN cargo build --release --locked
RUN rm -rf src

# I'm copying the actual source code
COPY --chown=builder:builder src ./src
COPY --chown=builder:builder database ./database

# I'm setting build-time environment variables for maximum optimization
ENV CARGO_NET_GIT_FETCH_WITH_CLI=true
ENV RUSTFLAGS="-C target-cpu=native -C opt-level=3 -C lto=fat -C codegen-units=1 -C panic=abort"
ENV CARGO_PROFILE_RELEASE_LTO=fat
ENV CARGO_PROFILE_RELEASE_CODEGEN_UNITS=1
ENV CARGO_PROFILE_RELEASE_PANIC=abort
ENV CARGO_PROFILE_RELEASE_STRIP=true

# I'm building the optimized production binary
RUN touch src/main.rs && \
    cargo build --release --locked --target-dir ./target

# I'm creating a separate stage to strip and verify the binary
FROM debian:bookworm-slim as binary-prep

RUN apt-get update && apt-get install -y \
    binutils \
    file \
    && rm -rf /var/lib/apt/lists/*

COPY --from=builder /home/builder/target/release/dark-performance-backend /tmp/app

# I'm stripping debug symbols and verifying the binary
RUN strip /tmp/app && \
    file /tmp/app && \
    chmod +x /tmp/app

# Production runtime stage with minimal distroless image
FROM gcr.io/distroless/cc-debian12:latest

# I'm adding metadata for the production image
LABEL maintainer="your-email@example.com"
LABEL description="High-performance Rust backend for performance showcase"
LABEL version="1.0.0"
LABEL org.opencontainers.image.source="https://github.com/yourusername/dark-performance-showcase"

# I'm setting up the runtime environment
ENV RUST_LOG=info
ENV RUST_BACKTRACE=1
ENV ENVIRONMENT=production
ENV PORT=3001

# I'm creating necessary directories with proper permissions
USER 65532:65532
WORKDIR /app

# I'm copying only the essential files for runtime
COPY --from=binary-prep --chown=65532:65532 /tmp/app /app/backend
COPY --from=builder --chown=65532:65532 /home/builder/database/migrations /app/database/migrations

# I'm exposing the application port
EXPOSE 3001

# I'm setting up health check for container orchestration
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD ["/app/backend", "--health-check"] || exit 1

# I'm using exec form for proper signal handling
ENTRYPOINT ["/app/backend"]

# Build arguments for customization
ARG BUILD_DATE
ARG GIT_COMMIT
ARG VERSION

# I'm adding build information as labels
LABEL org.opencontainers.image.created=${BUILD_DATE}
LABEL org.opencontainers.image.revision=${GIT_COMMIT}
LABEL org.opencontainers.image.version=${VERSION}

# I'm setting resource limits recommendations
LABEL resource.cpu.min="0.5"
LABEL resource.cpu.max="2.0"
LABEL resource.memory.min="512Mi"
LABEL resource.memory.max="2Gi"

# I'm configuring security settings
LABEL security.non-root=true
LABEL security.readonly-rootfs=true
LABEL security.capabilities.drop=ALL
</file>

</files>
